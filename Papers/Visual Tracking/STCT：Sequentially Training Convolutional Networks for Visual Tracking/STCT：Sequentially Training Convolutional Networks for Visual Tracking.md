### STCT: Sequentially Training Convolutional Networks for Visual Tracking

#### Abstract

由于训练样本的数量有限，在线fine-tuning预训练的深度模型容易过拟合。在本文，我们提出一种卷积神经网络（CNNs）顺序训练方法以有效的将预训练深度特征转移到在线应用。我们将CNN看作是一个集合，每个输出特征图的通道作为单独的 base learner。每个 base learner 使用不同的损失策略训练以减少相关性并避免过拟合。为了达到最好的在线集成，所有的 base learners 铜鼓重要性采样被顺序的采样到ensemble中。为了进一步极高每个base learner的鲁棒性，我们提出使用随机二进制mask训练卷积层，作为正则化来是的每个base learner关注与不同的输入特征。

通过转移在大量标注视觉数据上训练的深度特征，我们将提出的在线训练方法应用到视觉跟踪问题上并展示了重大的性能提升。我们在两个挑战性 benchmark 数据集上进行了大量的实验并展示了我们的跟踪算法相较state-of-the-art方法有较大提升。

#### 1. Introduction

视觉跟踪是计算机视觉中基本问题，一直以来受到越来越多的关注。它有许多子领域，从单目标跟踪到多目标跟踪。这里考虑单目标，model-free在线跟踪，在第一帧使用边界框指示一个未知类别的目标，跟踪器目的在于在接下来的每一帧定位目标。由于突然运动，变形，遮挡以及光照变化导致的外观变化，视觉跟踪依然是挑战性的问题。

之前的方法依赖于手工特征来描述目标并在一定成都上解决了上述挑战性因素。但是，这些手工特征被设计用于特定的场景。因此，他们泛化能力不强并且不能补货目标的语义信息，使得在挑战性的条件下很容易跟踪失败。

最近，在大型图像分类数据集上训练的深度卷积神经网络在许多视觉任务上展示了巨大的成功。在学习过程中发现的语义表示对于区分不同类别的物体十分有效。但是，有监督的训练几百万个参数的CNN需要大量的标注训练样本。为了将深度CNN应用于有限训练样本数量的任务，先前的方法应用了迁移学习，首先在源任务上使用大型训练数据集预训练一个CNN，接着在目标任务上fine-tuning学到的参数。由于CNN特征在不同数据集之间出色的泛化能力，这种迁移学习方法很有效并达到了state-of-the-art性能。

但是，对于在线视觉跟踪，训练样本的缺少十分严重，因为唯一的训练样本只在第一帧提供，并且用于更新跟踪器的跟踪结果也以顺序的方式获得。因此，直接在线fine-tuning预训练的CNN容易过拟合，使得跟踪器性能下降，逐渐导致跟踪漂移（见图1）。

为了解决上述问题，我们提出了一种CNNs的顺序训练方法来有效的将预训练的深度特征转移到在线视觉跟踪上。特别的，CNN被看作是一个集合而卷积特征图的每个通道被当作是一个base learner并使用不同的损失策略更新，如此它们并不高度相关。在线fine-tuning CNN则变为集成学习问题。为了构建更好的集成，我们通过重要性采样顺序的选择base learner并将其就加入到ensemble中。通过顺序训练的ensemble，在线跟踪被构造为前景/背景分离问题。为了进一步减少过拟合，我们提出使用随机二进制mask来训练巻积层，使得不同的卷积核关注于目标不同的位置。

本文的贡献可总结为三个层面：i）我们提出了一种CNN顺序训练方法，可以有效的将预训练的深度特征转移到在线应用中并减少过拟合；ii）我们基于提出的顺序学习方法设计了一个有效的视觉跟踪算法，其中在ImageNet图像分类任务上训练的深度特征被用于同时预测目标的位置和尺度。iii）在两个流行benchmark数据集上大量的实验展示了我们提出的跟踪算法比state-of-the-art方法表现要好。

#### 2. Related Work

一个典型的跟踪方法主要包含两个重要部分：一个外观模型，估计目标候选的可能性；一个搜索策略，寻找最可能的目标位置。本文中，我们主要关注于鲁棒外观模型的设计。之前的一些方法中，目标外观由生成式模型表示，具有最大可能性的候选被预测为目标。“EigenTrcking”算法利用了预训练的固有basis来描述目标外观。之后，Ross等提出增量的更新固有basis和mean来适应目标外观变化。稀疏表示也被应用于跟踪，目标通过目标模板的稀疏组合被重建。

同时，一些方法将视觉跟踪看作前景背景分离问题，使用判别式方法。基于boosting，结构化SVM，多示例学习以及相关滤波的在线学习算法被应用于跟踪并达到了很好的性能。此外，Danelljan等提出使用从HOG特征中学到的相关滤波来估计目标尺度变化。我们的方法在预测目标尺度变化上与[4]具有相似的思想。但是不同的是，我们利用了一个在深度特征上训练的尺度预测网络，对于严重外观改变更具鲁棒性。

近些年，深度卷积神经网络在许多计算机视觉应用中展示了state-of-the-art性能。现有的方法也探究了CNN在在线跟踪上的应用。[21]中，在线训练了一个3层CNN。没有预训练以及在线可获得的有限的训练样本，CNN不能捕获目标语义并对形变不鲁棒。[36]中，首先离线预训练一个自动编码器，接着以在线跟踪二分类finetuned。由于预训练通过重建低分辨率的灰度图像以一种非监督的方式执行，学到的深度特征具有有限的判别能力。[21]和[36]都使用有限的训练样本在线训练深度网络，不可避免会过拟合。因此，它们比state-of-the-art方法表现不佳。更多最近的方法应用在大型图像分类任务上训练的深度卷积网络来提高跟踪性能。[14]使用深度特征预测显著图。[35]和[22]提出通过使用多个巻积层的特征图来训练CNN或相关滤波器，以估计前景热图。相反的，我们提供了一个新范例，将预训练深度CNN的富特征转移到在线跟踪。相比于直接finetuning深度特征，我们将在线训练CNN看作是学习集成，以有效的去除特征相关性并避免过拟合。

#### 3. CNN Training as Ensemble Learning

在阐述我们提出的CNN顺序训练方法之前，我们首先介绍一些集成学习的背景以将我们的方法置于合适的上下文。

##### 3.1 Sequential Sampling for Ensemble Learning

给定数据点$\ x\ $，监督学习的目标是预测与$\ x\ $相关的ground truth $y$ 的预测值$\ \hat{y}\ $。预测规则通常定义为$\ \hat{y}=F(x)\ $，可以通过最小化训练数据$\{z_i=(x_i,y_i)\}^N_i$的期望损失来学习。
$$
F^*(x)=\arg\min_{F(x)}{\frac{1}{N}}\sum^N_{i=1}L(y_i,F(x_i))\ \ \ \ \ \ \ \ \ \ \ \ (1)
$$
其中$\ L(y,\hat{y})\ $表示预测值为$\ \hat{y}\ $，真实值为$\ y\ $时的损失。预测函数可以根据要解决的问题有多种的形式。在[7]中，Friedman和Popescu制定预测函数为积分
$$
F(x)=\pi_0+\int_\Gamma\pi(\gamma)f(x;\gamma)d\gamma\ \ \ \ \ \ \ \ \ \ \ \ (2)
$$
其中$\ f(x;\gamma)\ $表示由$\ \gamma\in\Gamma\ $参数化的base learner，而$\ \pi(\gamma)\ $为系数方程。利用数值积分来近似(2)，通过在$\ M\ $个评估点$\ \gamma_m\in\Gamma\ $的base learners的线性组合，$F(x)\simeq a_0+\sum^M_{m=1}a_mf(x;\gamma_m)$。(1)中的学习问题则相当于选择一个评估点$\ \{\gamma_m\}^M_1\ $以及它们对应系数$\ \{a_m\}^M_0\ $的良好集成。

对于一个base learner $f(x;\gamma)$，其与当前问题的不相关性定义为
$$
Q(\gamma)=\min_{\alpha0,\alpha}\frac{1}{N}\sum^N_{i=1}L(y_i,\alpha_0+\alpha f(x;\gamma))\ \ \ (3)
$$
最佳的点可通过最小化不相关性,$\ \gamma^*=\arg\min Q(\gamma)\ $，获得。对于base learners的集成$\ \{f(x;\gamma_m)\}^M_1\ $，characteristic scale 可以用来衡量其质量
$$
\sigma=\frac{1}{M}\sum^M_{m=1}[Q(\gamma_m)-Q(\gamma^*)]\ \ \ \ \ \ \ \ \ \ (4)
$$
$\ \sigma\ $的小值表明许多集成的base learners与最优base learner$\ f(x;\gamma^*)\ $十分相似。由于它们彼此高度相关，base learners的集成不能提供超出单个最优base learner$\ f(x;\gamma^*)$ 的附加信息。相反的，如果$\ \sigma\ $值太大，大部分base learners与问题不相关，这会导致降低集成的性能。

基于上述观察，Friedman和Popescu提出一种顺序采样方法来生成评估点的集成，其中对每个连续点$\ \gamma_m\ $的不相关性评估取决于前一个采样点$\ \{\gamma_l\}^{m-1}_1\ $。
$$
Qm(\gamma|\{\gamma_l\}^{m-1}_1)=\min_{\alpha0,\alpha_m}\frac{1}{N}\sum^N_{i=1}L(y_i,\alpha_0+\alpha_mf(x_i;\gamma)+\eta\sum^{m-1}_{l=1}\alpha_lf(xi;\gamma_l))\ \ \ \ (5)
$$
其中，参数$\ \eta\ $控制前一个采样点对当前相关性测量的影响。接着每个顺序选择的参数点$\ \gamma_m\ $由下式决定
$$
\gamma_m=\arg\min_{\gamma\in\Gamma}Q_m(\gamma|\{\gamma_l\}^{m-1}_1)\ \ \ \ \ \ \ \ (6)
$$
随着采样进行，由(5)定义的不相关性会与单个参数点的不相关性更加不同。因此，采样的参数点彼此不会高度相关。

##### 3.2 Online Training CNNs as Sequential Ensemble Learning

对于在线应用，一个将离线预训练的CNN特征转移的简单方法就是在预训练CNN模型之上添加一个或多个随机初始化的CNN层，称为适应层。接着保持预训练CNN参数固定（即，卷积核和偏执），只在线学习适应层的参数以适应当前任务。但是根据我们的经验发现，这一迁移学习方法会遭受过拟合。在线学习的参数主要关注于最近的训练样本而不能很好的泛化到历史或未来的样本。这一现象对于目标经常发生严重外观变化或严重遮挡时的在线视觉追踪来说很致命。

为了处理上述问题，我们提出顺序学习集成来在线训练CNN模型以更好的转移预训练深度特征。记预训练CNN为$\ CNN-E\ $，接收RGB图像为输入并输出卷积特征图$\ X\ $。一个在线自适应的CNN，称为$\ CNN-A\ $，被随机初始化并包含两个巻积层 交叉着ReLU层作为非线性激活单元。它接收特征图$\ X\ $作为输入并生成最终特征图$\ \{F^c_2(X)|c=1,2,...,C_2\}\ $，其中$\ F^c_2(X)\in\mathbb{R}^{m\times n}\ $表示由第二层生成的特征图的第$\ c\ $个通道，空间尺寸为$\ m\times n\ $。

第二层的特征图通过将卷积核与第一层特征图进行卷积获得的
$$
F^c_2(X)=\sum^{C_1}_{k=1}w^c_k\ *\ F^k_1(X)+b_c\ \ \ \ \ \ \ \ \ \ (7)
$$
其中$\ C_1\ $表示第一层输出特征图的通道数量；$\ w^c_k\ $表示连接第一层特征图的第$\ k\ $个通道与第二层特征图的第$\ c\ $个通道的卷积核；$\ b_c\ $ 为偏置，$\ *\ $表示卷机操作；求和是element-wisely的。为了将随机性引入参数学习过程，我们将输出特征图看作是base learners的集成$\ F^c_2(X)=\sum^{C_1}_{k=1}f(X;\gamma^c_k)\ $，其中每个base learner定义为$\ f(X;\gamma^c_k)=w^c_k*F^k_1(X)+b^k_c\ $，参数$\ \gamma^c_k\ $表示CNN-A第一层和第二层对应的核权重及偏置（第一层为$\ F^k_1(X)\ $的权重和偏置，第二成为$\ w^c_k\ $和$\ b^k_c\ $）。在线训练CNN-A网络则等价于在线更新每个base learner并顺序的采样base learners的最优集到ensemble中。由于我们提出的在线训练方法独立的在每个输出特征图通道上执行，在接下来的讨论中我们将以一个输出通道为例来描述训练方法。为了符号便利，我们忽略上标通道数量并使用$\ \{\gamma_k|k=1,2,...,C_1\}\ $来表示任何一个输出特征图通道的参数。

在在线训练进程开始时，每个base learner的参数$\ \gamma_k\ $被随机初始化并根据第一个训练样本通过sgd独立训练。具有最小训练误差的参数$\ \gamma^*\ $被选作单个最优参数并加入到ensemble集$\ \varepsilon\ $中，而剩下的$\ C_1-1\ $个参数构成候选集$\ C\ $。

在之后的训练进程中，候选集中的参数被顺序的加入ensemble集中。所有ensemble集中的参数被用来形成集成，输出为$\ F(X;\varepsilon)=\frac{1}{|\varepsilon|}\sum_{\gamma_i\in\varepsilon}f(X;\gamma_i)\ $用于在线测试。

在第$\ t\ $个时间步骤，会获得一个新的训练样本$\ X_t\ $，以及目标输出$\ Y_t\ $。ensemble集$\ \varepsilon\ $中的参数通过sgd，损失方程为$\ L_\varepsilon=L(Y_t,F(X_t;\varepsilon))\ $而共同更新。同时，每个参数$\ \gamma_j\in C\ $使用sgd，损失方程如下，来独立的更新。
$$
L_C(Y_t,f(X_t;\gamma_j))=L(Y_t,f(X_t;\gamma_j))+\eta F(X_t;\varepsilon)\ \ \ \ \ \ \ \ \ (8)
$$
其中$\ F(X_t;\varepsilon)\ $固定，参数$\ \eta\ $用来平衡ensemble对候选base learners的影响，如此base learner参数$\ \gamma_j\in C\ $的更新考虑目标输出$\ Y_t\ $和ensemble$\ F(X_t;\varepsilon)\ $的输出。如果训练误差$\ L_\varepsilon\ $比预设的阈值高并且候选集$\ C\ $不为空，则新的base learner 参数根据如下采样概率密度来从候选集$\ C\ $中采样
$$
p(\gamma)=q(L_c(Y_t,f(X_t;\gamma))),\ \gamma\in C\ \ \ \ \ \ \ \ \ \ (9)
$$
其中$\ q(\cdot)\ $为一个单调递减函数。然后采样的参数从候选集$\ C\ $中移除并加入到ensemble集$\ \varepsilon\ $中。

上述在线训练方法在每个时间步骤顺序执行，如图2(b)所示。当所有base learner参数从候选集采样到ensemble集，集合$\ F(X;\varepsilon)\ $演化成一个完整CNN模型（图2(b)，t = T）。该CNN模型的参数使用不同损失策略训练，因此展示了适度的多样性，以我们实验经验来说可以提升性能以及减少过拟合。

#### 3.3 Convolutional with Mask Layer

Dropout常用来正则化深度神经网络，通过随机设置全连接层中一部分激活为0。但是，这种正则化不适用于巻积层。另一种可选择的，SpatialDropout，可以提高巻积层的泛化性能，其将随机选择的特征图通道的所有值设为0。这种正则化对于离线训练很有效。但是，我们发现在最初的实验中，随机 “dropping-out” 一部分特征图通道的所有激活有时会导致在线训练CNN（有限数量的训练样本）发散。

我们提出一种使用mask的巻积层，目的在于进一步减少学到特征之间的相关性并避免过拟合。特别的，每个输出特征图通道与一个单独的二进制mask（空间尺寸与输入特征图一样）相关联。所有的mask被随机初始化并在在线训练过程中保持固定。训练阶段的巻积层前向传播则可构造为
$$
F^c=\sum^K_{k=1}w^c_k*(M^c\odot X^k)+b_c\ \ \ \ \ \ \ \ \ \ (10)
$$
其中$\ X^k\ $表示输入特征图的第$\ k\ $个通道；$\ M^c\ $表示与输出特征图$\ F^c\ $第$\ c\ $个通道相关联的二进制mask$\ M^c\ $。$\ \odot\ $为Hadamard积。据此，反向传播也考虑二进制mask。以这种方式训练，学到的卷积核通过二进制mask被强制关注输入特征图的不同部分。对于inference，巻积层不使用mask，这样学到的核在整个输入特征图上搜索特定的输入模式。

二进制mask的初始化方式可以根据特定问题定制。在我们的方法中，我们把每个mask分成2$\ \times\ $2的块。每个块中的所有值以一个随机变量初始化，该随机变量服从Bernoulli分布。通过重初始化来避免所有4个块都为0的情况。

#### 4. Tracking Algorithm

**Overview**  整体的跟踪程序如算法1。特征提取网络 CNN-E 包含16层VGG网络（在ImageNet分类任务上训练，接收RGB图像为输入，输出512通道的特征图$\ X\ $）的前10个巻积层。适应适应网络 CNN-A 的第一层应用我们提出的使用mask的巻积层，卷积核为5$\ \times\ $5，生成100个通道的特征图（对应100个base learners）。CNN-A的第二层为巻积层，核大小为3$\ \times\ $3，产生一个通道的特征图用于目标定位。为了解决尺度变换，一个尺度预测网络 SPN 构建在预训练CNN-E之上。SPN网络接收CNN-E的输出特征图$\ X\ $为输入，首先应用一系列预定义的尺度变换$\ S = \{s_l|l=1,2,...n_s\}\ $以获得对应的尺度变换特征图$\ \{\tau(X,s_l)\}^{n_s}_1\ $,其中$\ s_l\ $表示第$\ l\ $个尺度变化参数（尺度因子）。接着所有变换的特征图通过一个全连接层来预测当前目标最优的尺度$\ s^*\ $。

**Initialization** 给定第一帧目标位置ground truth，我们在目标位置以两倍的大小裁剪一个矩形图像区域$\ I_1\ $。对应的特征图$\ X_1\ $由CNN-E提取。如3.2节中描述的，base learners$\ \{f(X_1;\gamma_k)\}^{100}_1\ $单独初始化，使用Euclidean 损失预测目标得分图$\ M_1\ $
$$
L(M_1,f(X_1;\gamma_k))=\parallel M_1-f(X_1;\gamma_k)\parallel^2_2\ \ \ \ \ \ \ \ \ \ \ \ (11)
$$
其中$\ M_1\ $以小尺度在ground truth目标位置为中心的高斯分布。具有最小训练误差的base learner最优的参数$\ \gamma^*\in\{\gamma_k\}^100_1\ $被用来初始化ensemble集$\ \varepsilon\ $，而剩下的组成候选集$\ C\ $。同时，SPN使用hinge损失来训练，预测当前目标的尺寸
$$
L_S=\mathbb{max}(0,1+\max_{s_l\neq s^*,s_l\in S}F_S(\tau(X,s_l))-F_S(\tau(X,s^*)))+R_S\ \ \ \ \ \ \ \ (12)
$$
其中$\ s^*\ $表示目标的ground truth 尺度；$\ F_S\ $为SPN预测的得分，$\ R_S\ $为权值衰减。

**Online Tracking** 在$\ t\ $帧，从输入图像上一个位置裁剪一个矩形图像区域$\ I_t\ $并传递通过CNN-E网络获得$\ X_t\ $。base learners的ensemble接收对应的特征图$\ X_t\ $作为输入并预测一个热图$\ \hat{M}_t=\frac{1}{|\varepsilon|}\sum_{\gamma_i\in\varepsilon}f(X_t;\gamma_i)\ $。接着目标的中心位置由热图中具有最大值的位置确定。最大的热图值则作为预测的置信度$\ conf_t\ $。为了预测当前的尺寸，我们裁剪另一个图像区域$\ \hat{I}_t\ $，以预测目标位置为中心并比上一帧的目标边界框大两倍。当前目标尺寸由SPN网络预测$\ \hat{s}=\arg\max_{s_l\in S}F_S(\tau(\hat{X}_t,s_l))\ $，其中$\ \hat{X}_t\ $表示CNN-E从区域$\ \hat{I}_t\ $提取的特征。

**Online Update** 为了避免使用污染的训练样本更新，更新只在位置预测的置信度高于预定义的阈值$\ \theta\ $时才执行。ensemble集$\ \varepsilon\ $以及候选集$\ C\ $中的base learner本别使用如下损失函数，以sgd更新
$$
L_\varepsilon(M_t,\varepsilon)=\parallel M_t-\frac{1}{|\varepsilon|}\sum_{\gamma_i\in\varepsilon}f(\hat{X}_t;\gamma_i)\parallel^2_2\\
L_c(M_t,\gamma_j\in C)=\parallel M_t-f(\hat{X}_t;\gamma)-\eta\frac{1}{|\varepsilon|}\sum_{\gamma_i\in\varepsilon}f(\hat{X}_t;\gamma_i)\parallel^2_2\ \ \ \ (13)
$$
其中$\ \gamma_i\in\varepsilon\ $在更新$\ \gamma_j\in C\ $时固定；$\ M_t\ $表示在以估计位置为中心的高斯分布热图。如果当前ensemble的训练误差$\ L_\varepsilon\ $比阈值$\ \varepsilon\ $高并且候选集$\ C\ $不为空，我们就从候选集采样而不替换base learner的参数，并将其加入ensemble集$\ \varepsilon\ $。在我们的实验中，我们应用了如下的采样概率密度
$$
p(\gamma_j)=\delta(\hat{\gamma}^*-\gamma_j),\ \ \ \ \ \gamma\in C\ \ \ \ \ \ \ \ \ \ \ \ (14)
$$
其中$\ \delta(\cdot)\ $为Dirac delta函数；$\ \hat{\gamma}^*\ $表示具有最小训练误差$\ L_C\ $的最优参数。同时，SPN网络通过（12）来更新，使用$\ \hat{X}_t\ $以及预测尺度$\ \hat{s}\ $为ground truth，训练样本$\ \hat{X}_t\ $被resize到固定尺寸（实验中是256$\ \times\ $256）以适应SPN的输入尺寸。