### Modeling and Propagating CNNs in a Tree Structure for Visual Tracking

 #### Abstract

我们提出一个在线视觉跟踪算法，以树结构管理多个目标外观模型。我们提出的算法应用卷积神经网络（CNNs）来表示目标外观，其中多个CNNs协作估计目标状态并决定需要的路径用于树中在线模型更新。通过维护树结构不同分支的多个CNNs，可以很容易的处理目标外观的多种形式并在沿树路径的平滑更新中保持模型的可靠性。由于多个CNNs在巻积层共享所有参数，因此节省了内存空间并避免了冗余的网络评估，以很少的代价来利用多个模型。通过在前一帧目标状态附近采集候选，并以一系列激活CNNs中加权平均得分最好的样本作为最终目标状态。我们的算法相比于state-of-the-art方法展示了接触的性能。

#### Introduction

1. 视觉跟踪子问题中，目标外观建模是至关重要的一部分。大部分现有跟踪算法假设目标外观平滑改变，并据此来更新目标模型。这种策略对于遮挡、光照变化、突然运动和形变不合适。一些算法应用了多模型，多模式表示或非线性分类器来解决该问题。但是，这些构建的模型依然不够好，并且在线模型更新受限于按照时间顺序的连续学习，使得模型不够discriminative以及diverse。

2. 使用CNNs在线学习不简单，因为在学到新信息时神经网络趋向于忘记之前学到的信息。这一性质会导致漂移问题，特别是当背景信息污染了目标外观模型、目标完全被其他物体遮挡或跟踪临时失败时。这一问题可以通过维护多个在不同时间构建的目标外观模型版本，并有选择性的更新一部分模型来缓和。[22]中探究了这一想法，其中使用了一堆CNNs来建模目标外观，但其没有考虑每个CNN估计目标状态和更新模型的可靠性。

3. 我们提出的在线视觉跟踪算法使用从多个CNNs中获得的可能性来估计目标状态。CNNs以树结构来维持，在线更新时沿着树中的路径。由于每条路径跟踪关于目标外观改变的单独历史记录，该算法可以有效的解决多模式目标外观以及其他异常，如短期遮挡或跟踪失败。另外，由于跟当前帧相关的新模型是通过fine-tuning产生最高目标状态估计可能性的CNN构建的，因此通过在线学习生成一致可靠的模型只需要很少的训练样本。

4. 本文贡献：1）提出一个视觉跟踪算法，以树结构管理一系列基于CNNs的外观模型，其中模型在线更新沿着树中的路径。这一策略使得我们通过平缓的更新来学到更稳固的模型。2）我们的跟踪算法利用多个模型来捕获多样的目标外观，并在外观改变、遮挡、暂时跟踪失败时表现的更加鲁棒。3）该算法展示了杰出的准确度，比state-of-the-art方法要好。

#### Related Work

主要介绍了一些基于tracking-by-detection的判别式跟踪算法，讨论了多目标外观模型的跟踪以及基于CNNs表示学习的跟踪。

#### Algorithm Overview

1. 我们的算法以树形结构维护了多个基于CNN的目标外观模型，保护了模型的一致性并处理了外观多模式的有效性。该算法包含两个主要部分——状态估计以及模型更新。如图1。

2. 来新的一帧，我们在前一帧估计的目标状态附近采集候选样本，并基于每个样本在多个CNNs中的加权平均得分，计算其可能性。每个CNN的权重由路径的可靠性来决定，沿着该条路径CNN被更新。通过寻找最大可能性的候选来估计当前帧的目标状态。在跟踪预定帧数之后，CNNs中具有最高权重的会导出一个新的CNN。这一策略在实践中有助于保证平滑模型更新以及保持模型可靠。

3. 我们的的算法提出了一个新的以树形结构的模型维护技术，更关心 如何保持多个CNNs的multimodality以及最大化它们的可靠性。

#### Proposed Algorithm

##### CNN Architecture

我们的网络包含3个巻积层以及3个全连接层。巻积层参数与在ImageNet上预训练的VGG-M网络一样。最后的巻积层有两个单元用于二分类，之前的两个全连接层由512个单元组成。这三层的参数随即初始化。网络的输入为75x75 RGB图像，其尺寸与最后一个巻积层的感知野相同。输入图像x的输出为归一化向量$\ [\phi(x),\ 1-\phi(x)]^T\ $,分别代表目标和背景的分数。CNN整体结构如图2。

##### Tree Construction

我们维护一个树结构来管理分层的多个基于CNNs的目标外观模型。在树结构$\ \tau = \{\nu, \varepsilon\}\ $中，一个顶点$\ v\in\nu\ $对应于一个CNN，一个有向边$(u,v)\in\varepsilon$定义了CNNs之间的关系。一条边$(u,v)$的分数为两个顶点的亲和度
$$
s(u,v) = \frac{1}{|F_v|}\sum_{t\in F_v}\phi_u(x^*_t)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (1)
$$
其中$F_v$为一系列连续帧用于训练与$v$相关联的CNN，$x^*_t$为第t帧估计的目标状态，$\ \phi_u(\cdot)\ $为$u$上CNN预测的正得分。注意到边得分在估计目标状态以及提供可靠模型更新路径中起到重要作用。

##### Target State Estimation using Multiple CNNs

我们的算法通过聚集多个CNNs的得分来估计目标状态。设$\ x^1_t,...,x^N_t\ $为当前帧$\ t\ $的$\ N\ $个候选，在前一帧目标状态附近采样获得，$\ \nu_+\subseteq \nu\ $为一系列激活的CNNs，用于估计目标状态。样本$\ x^i_t\ $的目标得分$\ H(x^i_t)\ $由CNN得分的加权平均计算
$$
H(x^i_t) = \sum_{v\in\nu_+}w_{v\to t}\phi_v(x^i_t)\ \ \ \ \ \ \ \ \ \ \ \ (2)
$$
其中$\ w_{v\to t}\ $表示跟踪第$\ t\ $帧目标，与顶点$\ v\ $对应的CNN的权重。最优的目标状态$\ x^*_t\ $为具有最大目标得分的候选样本
$$
x^*_t = \arg\max_{x^i_t}H(x^i_t)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (3)
$$
权重由以下两个因素决定：与当前帧的亲和力以及CNN的可靠性。亲和力$\ \alpha_{v\to t}\ $表示顶点$\ v\ $的CNN影响第$\ t\ $帧跟踪结果的置信度，由整体候选的最大正得分决定
$$
\alpha_{v\to t} = \max_{x^i_t}\phi_v(x^i_t)\ \ \ \ \ \ \ \ \ \ \ \ \ \ (4)
$$
但是，只基于此的权重估计可能有问题，因为它忽略了每个CNN的可靠性。例如，如果CNN在完全错误的帧上fine-tuned，CNN很有可能会在背景上产生高得分，这样虽然样本存在高亲和度，但应该被惩罚。

为了解决该问题，我们也使用CNN被更新的路径来利用每个CNN对于目标状态估计的可靠性。注意到路径上可以有不可靠的CNN，可能是由跟踪错误的帧更新的。我们估计与顶点$\ v\ $相关联的CNN的可靠性，记为$\ \beta_v\ $，使用瓶颈边的得分。特别的，CNN的可靠性可以以递归的方式高效的计算而不用遍历整个路径
$$
\beta_v = \min(s(p_v,v),\beta_{p_v})\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (5)
$$
其中$\ p_v\ $为顶点$\ v\ $CNN的父节点，具有向外的边$\ (p_v,v)\ $。

基于这两个标准，与顶点$\ v\ $相关联的CNN的权重$\ w_{v\to t}\ $为
$$
w_{v\to t} = \frac{\min(\alpha_{v\to t}, \beta_v)}{\sum_{v\in\nu_+}\min(\alpha_{v\to t}, \beta_v)}\ \ (6)
$$
$\ \alpha_{v\to t}\ $和$\ \beta_v\ $都是在CNN上评估的得分，取两个瓶颈相似性的最小值来决定与第$\ t\ $帧相关联的新CNN的权重。

##### Bounding Box Regression

##### Model Update

我们以树结构维护多个CNN，其中每个结点存储一个CNN。该方法通过在多个分支保存CNN来提高外观模型的多模态同时通过沿着树中路径平滑更新CNN来保护模型可靠性。现在的问题是如何选择合适的路径用于fine-tuning CNN。在跟踪$\ \Delta(=10)\ $个连续的帧没有模型更新（$F_z$中的元素）后，我们为新的CNN构造一个结点$\ z\ $。父节点CNN为最大化新CNN可靠性的一个，与父CNN相关的顶点$\ p_z\ $定义为
$$
p_z = \arg\max_{v\in\nu_+}\min(\tilde{s}(v,z),\beta_v)\ \ \ \ \ \ \ \ (7)
$$
其中$\ \tilde{s}(v,z)\ $表示假定边$\ (v,z)\ $的得分，顶点$\ z\ $的CNN从$\ p_z\ $的CNN fine-tuned，使用两个帧集$\ F_z\ $和$\ F_{p_z}\ $收集的训练样本。加入新的顶点$\ z\ $及对应边$\ (p_z,z)\ $扩展了树结构。激活的CNN集$\ \nu_+\ $也进行更新以包含$\ K(=10)\ $个CNNs（最近加入到树结构的）。

##### Implementation Details

我们以前一帧目标状态为中心，在一个服从独立多元正态分布的$\ (x,y,s)\ $空间采集256个样本。三个变量的标准差值为$\ \sigma_x=\sigma_y=0.3l\ $以及$\ \sigma_s=0.5\ $;$\ l\ $为之前目标边界框宽度和高度的平均值，样本边界框的尺度通过将$\ 1.05^s\ $与初始目标的宽和高相乘来决定。

我们只更新全连接层，巻积层的参数与预训练网络的一致。尽管我们以树结构存储多个CNNs，所有巻积层的参数是共享的，共享层的输出可以重复利用。因此，维护和评估多个CNNs只需要很少代价。

每帧跟踪完毕后会收集训练数据，50个正样本（与估计目标框大于0.7IoU）和200个负样本（小于0.5IoU）。实践中，我们不存储图像块为训练样本二商保存其conv3特征，因为其特征不会改变。

CNNs使用SGD方法以及softmax 交叉熵损失。训练10个迭代，学习率为0.003，而最初的CNN训练50个迭代，学习率为0.001。weight decay 为0.0005，momentum为0.9。

#### Experiment

The trackers based on low-level features generally fail to track targets in challenging situations such as rotation, deformation, motion blur and low resolution, which require highlevel understanding about targets.