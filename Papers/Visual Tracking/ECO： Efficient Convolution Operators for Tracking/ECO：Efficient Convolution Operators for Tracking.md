###ECO：Efficient Convolution Operators for Tracking

#### Abstract

近些年，基于判别式相关滤波（DCF）的方法大幅提高了跟踪领域的state-of-the-art。但是，在追求提高跟踪性能上，它们的速度以及实时能力会逐渐的降低。而且，更加复杂的模型以及大量的可训练参数，会引入过拟合的风险。在本文中，我们解决计算复杂度及过拟合问题背后的关键问题，专注于同时提高速度与性能。

我们重新审视了DCF核心构想与介绍：（1）一个分解卷积算子(factorized convolution operator)，大幅较少了模型的参数数量；（2）一个训练样本分布的紧凑生成式模型，大幅减少了空间和时间复杂度，同时提供了更好的样本多样性；（3）一个保守模型更新策略，具有更好的鲁棒性以及更少的复杂度。我们在四个基准数据集上进行了广泛的实验：VOT2016,UAV123,OTB-2015以及Temple-Color。当使用expensive 深度特征时，我们的跟踪器加速了20倍并达到了相对13%的Expected Average Overlap（平均重叠期望），相比于VOT2016挑战中排名前几的方法。而且，我们的快速变体，使用手工制作特征，在60Hz的单CPU上运行，在OTB-2015上获得了65%的AUC。

#### 1. Introduction

通用视觉跟踪是计算机视觉中的基础问题之一。该任务是只给定初始状态，估计目标在图像序列中的轨迹。在线视觉跟踪在许多实时视觉应用中扮演着重要角色，如智能监控系统，自动驾驶，无人机检测，智能交通管制以及人机界面等。由于在线跟踪的特性，一个理想的跟踪器应该在实时视觉系统的困难计算约束下保持准确与鲁棒。

近些年，基于判别式相关滤波（DCF）的方法在跟踪benchmarks上展示了持续的准确度与鲁棒性提升。近期，使用多维特征，鲁棒尺度估计，非线性核，长期存储组件（long-term memory components），复杂学习模型以及减少边界效应驱动了基于DCF的跟踪性能发展。但是，这些准确度的提升是以大幅降低跟踪速度为代价的。例如，Bolme等的MOSSE跟踪器比最近排名第一的DCF跟踪器，C-COT，快1000倍，但准确度只有一半。

如上面所提到的，DCF跟踪性能的提升主要是归功于强大的特征以及复杂的学习形式（formulations）。这也导致了更大的模型，需要成百上千的可训练参数。另一方面，如此大型复杂的模型引入了严重过拟合的风险。本文中，我们解决最近DCF跟踪器的过拟合问题，同时恢复它们的实施能力。

##### 1.1 Motivation

我们认为有三个关键因素导致了计算复杂度的增加与state-of-the-art DCF跟踪器的过拟合。

**Model Size : **对高维特征图的集成，如深度特征，导致了外观模型参数数量的大幅增加，通常高出输入图像的维度。例如，C-COT在线更新模型时需要持续更新大约800000个参数。由于跟踪中，训练数据固有的缺失，如此高维的参数空间用以导致过拟合。并且，高维度会导致计算复杂度的增加，跟踪速度下降。

**Training set size : **State-of-the-art DCF跟踪器，包括C-COT，由于它们依赖于迭代优化算法，需要存储大型的训练样本集。但是在实践中，内存空间有限，特别是使用高维特征时。一个维持可用内存消耗的典型策略就是舍弃最久的样本。但这有可能导致对近期的外观变化过拟合，导致模型漂移（如图1）。而且，大型训练集增加了计算负担。

**Model update : **大多数DCF跟踪器使用持续学习策略，模型每一帧都会严格的更新。相反的，近期的研究表示没有模型更新也可以获得不错的性能，如使用Siamese networks。受到这些发现的启发，我们认为state-of-the-art DCF中的持续模型更新是过度的并且对于如尺度变换，变形以及面外旋转等导致的突然改变很敏感。如此过度的更新策略会由于最近几帧的过拟合而导致低帧率以及鲁棒性降低。

##### 1.2 Contributions

我们提出一个新的formulation来解决之前提到的state-of-the-art DCF跟踪器的问题。我们的第一个贡献是提出了一个分解卷积算子可以大幅减少DCF模型中参数数量。我们第二个贡献是提出训练样本空间的紧凑生成式模型可以有效的减少学习是样本的数量，同时保持多样性。我们最后一个贡献是提出一个高效模型更新策略可以同时提高跟踪速度与鲁棒性。

大量的实验证明了我们的方法同时提高了跟踪性能与速度，因此在四个benchmarks（VOT2016,UAV123,OTB-2015,Temple-Color）上达到了state-of-the-art。我们的方法相比于baseline方法减少了80%的模型参数，90%的样本以及训练时80%的迭代优化。在VOT2016上，我们的方法比排名第一的跟踪器C-COT表现要好，且达到了更高的帧率。而且，我们提出一个跟踪器的快速版本，不仅维持了良好的性能，并且在单CPU上以60帧每秒的速度运行，因此十分适合有计算限制的机器人平台。

#### 2. Baseline Approach : C-COT

本文中，我们同时解决state-of-the-art DCF跟踪器中计算复杂度和过拟合的问题。我们采用近期的C-COT跟踪器作为我们的baseline。C-COT在最近的VOT2016挑战中获得了第一名，并且在其他benchmarks上获得了杰出的结果。不像标准的DCF formulation，Danelljan等提出了对在连续空间域上学习过滤器问题的讨论。C-COT中一般的formulation产生了与我们研究想关的两个优点。

C-COT的第一个优点是通过在连续域上执行卷积操作达到对多分辨率特征图的自然集成。这提供了对每个视觉特征独立选择cell尺寸（即，分辨率）的灵活性，而不需要明确的重采样。第二个优点是预测的目标检测分数是直接以连续函数的形式获取，使得子网格定位准确。

在此，我们简单的表述C-COT formulation，并使用与[12]中相同的符号。C-COT 在M个训练样本$\{x_j\}_1^M\subset \mathcal{X}$上discriminatively 学习卷积过滤器。 不像标准的DCF，每个特征层$c^d_j\in \mathbb{R}^{N_d}$具有单独的分辨率$N_d$。特征图通过引入插值模型，跟定运算子$J_d$，被转移到一个连续空间域$t\in[0,T)$。
$$
J_d\{x^d\}(t)=\sum^{N_d-1}_{n=0}x^d[n]b_d\left(t-\frac{T}{N_d}n\right)\ \ \ \ \ \ \ \ \ \ \ \ (1)
$$
式中，$b_d$为差值核，周期为$T>0$。因此结果$J_d\{x^d\}$为插值后的特征层，可以看作是周期为T的连续函数。$J\{x\}$表示整个插值后的特征图，$J\{x\}\in \mathbb{R}^D$。

在C-COT formulation中，训练一个周期为T的多通道卷积过滤器$f=(f^1...f^D)$来预测目标检测分数$S_f\{x\}(t)$
$$
S_f\{x\}=f*J\{x\}=\sum^D_{d=1}f^d*J_d\{x^d\}\ \ \ \ \ \ \ \ \ \ \ \ (2)
$$
分数被定义在特征图$x\in\mathcal{X}$相应的图像区域$t\in[0,T)$。在(2)式中，周期为T的单通道函数的卷积定义为$f*g(t)=\frac{1}{T}\int^T_0f(t-\tau)g(\tau)d\tau$。多通道卷积$f*J\{x\}$通过将所有通道的结果加起来获得，如式(2)。过滤器通过最小化如下目标来获取
$$
E(f)=\sum^M_{j=1}\alpha_j\parallel S_f\{x_j\}-y_j\parallel^2_{L^2}+\sum^D_{d=1}\parallel wf^d\parallel^2_{L^2}\ \ \ \ \ \ \ \ \ \ \ \ (3)
$$
样本$x_j$的标注检测分数$y_j(t)$设置为周期重复的高斯函数。数据项由$L^2$范式$\parallel g\parallel^2_{L^2}=\frac{1}{T}\int^T_0|g(t)|^2dt$给出的加权分类误差组成，$\alpha_j\geq0$是样本$x_j$的权重。正则化集成了空间惩罚项$w(t)$以减轻周期假设的不足，同时enabling an extended spatial support。

如之前的DCF方法一样，通过改变到傅立叶基可以获得易于处理的优化问题。Parseval的公式指示了等价的损失
$$
E(f)=\sum^M_{j=1}\alpha_j\parallel\widehat{S_f\{x_j\}}-\hat{y}_j\parallel^2_{\ell^2}+\sum^D_{d=1}\parallel\hat{w}*\hat{f^d}\parallel^2_{\ell^2}\ \ \ \ \ \ (4)
$$
周期为T的函数$g$中的$\hat{g}$表示傅里叶级数系数$\hat{g}[k]=\frac{1}{T}\int^T_0g(t)e^{-i\frac{2\pi}{T}kt}dt$，$\ell^2$范式定义为$\parallel\hat{g}\parallel^2_{\ell^2}=\sum^{\infty}_{-\infty}|\hat{g}[k]|^2$。检测得分的傅里叶系数由公式$\widehat{S_f\{x\}}=\sum^D_{d=1}\hat{f^d}X^d\hat{b}_d$给出，其中$X^d$为$x^d$的离散傅里叶变换。

在实践中，假设过滤器$f^d$具有有限个傅里叶系数$\{\hat{f^d}[k]\}^{K_d}_{-K_d}$，$K_d=\lfloor\frac{N_d}{2}\rfloor$。公式(4)则变为quadratic 问题，通过解如下等式以优化。
$$
(A^H\Gamma A+W^HW)\hat{\mathrm{f}}=A^H\Gamma\hat{y}\ \ \ \ \ \ \ \ \ \ \ \ \ (5)
$$
$\hat{\mathrm{f}}$和$\hat{y}$分别是$f^d$和$y_j$中傅里叶系数的向量化。矩阵$\ A\ $展示了稀疏结构，对角块包含$X^d_j[k]\hat{b}_d[k]$形式的元素。此外，$\Gamma\ $是权重$\ \alpha_j\ $的对角矩阵而$\ W\ $是以$\hat{w}[k]$为核的卷积矩阵。C-COT使用了Conjugate Gradient方法来迭代的解决公式(5)，由于其可以高效的利用问题中的稀疏结构。

#### 3. Our Approach

如之前讨论的，DCF学习中的过拟合以及计算瓶颈来源于公共因子。因此我们一起处理这些问题，以提高性能和速度。

**Robust learning :  **如之前提到的，由于训练数据有限，公式(3)中大量的优化参数可能会导致过拟合。在3.1节中，我们将通过引入分解卷积formulation来减轻该问题。该策略在使用深度特征时减少了80%的模型参数，同时提高了跟踪性能。此外，我们在3.2节中提出了一个样本分布的紧凑生成式模型，以提升多样性并避免存储大量样本集带来的问题。最后在3.3节中我们介绍了更新模型的策略并得出了“对过滤器不频繁的更新使得学习更稳定，也使得跟踪更鲁棒”的结论。

**Computational complexity : **学习步骤是给予优化的DCF跟踪器的计算瓶颈。C-COT中外观模型优化的计算复杂度可以通过分析应用于公式(5)的Conjugate Gradient算法获得。复杂度可以表示为$\mathcal{O}(N_{CG}DM\bar{K})$，$N_{CG}$为CG迭代次数，$\bar{K}=\frac{1}{D}\sum_dK_d$为每个过滤器通道的傅里叶系数的平均数量。受到该学习复杂度的分析，我们分别在3.1，3.2，3.3节中提出方法来减少$D$,$N$以及$N_{CG}$。

#####3.1 Factorized Convolution Operator

我们首先介绍分解卷积方法，以减少模型的参数数量。我们观察到C-COT中学到的许多过滤器$f^d$具有很少的能量。这对于高维深度特征来说尤其明显，如图2所示。这些过滤器对于目标定位没什么贡献，但却影响训练时间。相比于每个特征通道$d$学习一个单独的过滤器，我们使用一个更小的基过滤器集$f^1,...,f^C,C<D$。特征层$d$的过滤器则通过使用一系列学到的参数$p_{d,c}$对过滤器$f^c$进行线性组合$\sum^C_{c=1}p_{d,c}f^c$来构建。系数可以简单的表示为一个$D\times C$的矩阵$P=(p_{d,c})$。新的多通道过滤器可以写成矩阵向量乘积$Pf$。我们获得分解卷积算子，
$$
S_{Pf}\{x\}=Pf*J\{x\}=\sum_{c,d}p_{d,c}f^c*J_d\{x^d\}=f*P^TJ\{x\}\ \ \ \ \ \ (6)
$$
最后一个等式服从卷积的线性。因此可以将分解卷积(6)视为两步操作，首先就是将每个位置$t$的特征向量$J\{x\}(t)$与矩阵$P^T$相乘。结果的C维特征图接着使用过滤器$f$进行卷积。矩阵$P^T$类似于一个线性降维算子。关键的不同是我们共同的学习过滤器$f$以及矩阵$P$，以一种判别的方式，通过最小化分解算子(6)的分类误差(3)。

为了简便，我们考虑从单个训练样本$x$中学习分解算子(6)。为了简化表示，我们使用$\hat{z}^d[k]=X^d[k]\hat{b}_d[k]$来表示插值后特征图$z=J\{x\}$的傅里叶系数。相应的傅里叶域损失可以推导为
$$
E(f,P)=\parallel\hat{z}^TP\hat{f}-\hat{y}\parallel^2_{\ell^2}+\sum^C_{c=1}\parallel\hat{w}*\hat{f^c}\parallel^2_{\ell^2}+\lambda\parallel P\parallel^2_F\ \ \ \ \ \ \ \ \ \ \ \ (7)
$$
在这里我们添加了Frobenius 范式P作为正则化，由权重参数$\lambda$控制。

不像原本的公式(4)，我们的损失(7)是一个非线性最小二乘问题。由于$\hat{z}^TP\hat{f}$的双线性，损失(7)类似于一个矩阵因子分解问题。这些应用的著名优化策略，包括交替最小二乘，由于我们问题中参数的数量以及在线的特性，在这里是不可行的。我们应用了Gauss-Newton以及Conjugate Gradient方法来优化二次子问题。Gauss-Newton方法可使用第一集泰勒展开系数通过对(7)中的残差线性化推导出。这对应于在当前估计$(\hat{f}_i,P_i)$周围近似双线性项$\hat{z}^TP\hat{f}$。
$$
\begin{align*}\hat{z}^T(P_i+\Delta P)(\hat{f}_i+\Delta\hat{f})&\approx\hat{z}^TP_i\hat{f}_{i,\Delta}+\hat{z}^T\Delta P\hat{f}_i\ \ \ \ \ \ \ \ \ \ \ \ (8)\\&=\hat{z}^TP_i\hat{f}_{i,\Delta}+(\hat{f}_i\otimes\hat{z})^T\mathrm{vec}(\Delta P)\end{align*}
$$
这里我们设置$\hat{f}_{i,\Delta}=\hat{f}_i+\Delta\hat{f}$。最后一个等式中，Kronecker乘积$\otimes$用来获得矩阵步骤$\Delta P$的向量化。

在第$i$次迭代，Gauss-Newton子问题可以通过将第一级近似(8)替换到(7)推倒得出
$$
\begin{align*}\tilde{E}(\hat{f}_{i,\Delta},\Delta P)&=\parallel\hat{z}^TP_i\hat{f}_{i,\Delta}+(\hat{f}_i\otimes\hat{z})^T\mathrm{vec(\Delta P)}-\hat{y}\parallel^2_{\ell^2}\\&+\sum^C_{c=1}\parallel\hat{w}*\hat{f}^c_{i,\Delta}\parallel^2_{\ell^2}+\mu\parallel P_i+\Delta P\parallel^2_F\ \ \ \ \ \ \ \ \ \ \ \ (9)\end{align*}
$$
由于过滤器$\ f\ $受到约束，只能有有限个非零傅里叶系数，公式(9)是一个线性最小二乘问题。对应的正规方程与(5)部分结构相似，附加的组件对应于矩阵增量$\Delta P$变量。我们使用了Conjugate Gradient方法来优化每个Gauss-Newton子问题来获取新的过滤器$\hat{f^*_{i,\Delta}}$以及矩阵增量$\Delta P^*$。过滤器和矩阵估计接着通过$\hat{f}_{i+1}=\hat{f}^*_{i,\Delta}$以及$P_{i+1}=P_i+\Delta P^*$来更新。

我们分解卷机操作的主要目的是减少跟踪器的计算和空间复杂度。由于过滤器的适应性，矩阵$\ P\ $可以只从第一帧学习到。这有两点重要暗示。首先，只有投射的特征图$P^TJ\{x_j\}$需要存储，节省了大部分空间。其次，过滤器可以使用投射的特征图$P^TJ\{x_j\}$作为第二节中描述的方法的输入以在后续帧中更新。这将线性复杂度从特征维度D减少到了过滤器维度C。

##### 3.2 Generative Sample Space Model

我们提出一个样本集的紧凑生成式模型以避免之前讨论过的对最近训练样本的存储问题。大多数DCF跟踪器，如SRDCF以及C-COT，在美意帧$\ j\ $上添加训练样本$\ x_j\ $。权重通常设置为衰减指数$\alpha_j\sim(r-\gamma)^{M-j}$,受到学习率$\gamma$控制。如果样本数量达到了最大限制$M_{\mathrm{max}}$，具有最小权重$\alpha_j$的样本就会被替换。这一策略需要很大的样本限制$M_{\mathrm{max}}$来代表样本集。

我们观察到在每一帧收集新的样本会导致样本集的冗余，如图3所示。标准的采样策略(底部一行)使用相似的样本$x_j$填充了整个训练集，而不管包含了大部分相同的信息。我们提出使用一个样本集的概率生成式模型，通过消除冗余并增强多样性(top)而达到对样本简洁的表示。

我们的方法基于样本特征图$\ x\ $以及对应渴望输出得分$\ y\ $的联合概率分布$p(x,y)$。给定$\ p(x,y)\ $，直观的目标是寻找一个过滤器可以最小化相关误差期望。这可以通过下式替换(3)获得
$$
E(f)=\mathbb{E}\lbrace\parallel S_f\lbrace x\rbrace-y\parallel^2_{L^2}\rbrace+\sum^D_{d=1}\parallel wf^d\parallel^2_{L^2}\ \ \ \ \ \ \ \ \ \ \ \ (10)
$$
期望$\ \mathbb{E}\ $在联合样本分布$\ p(x,y)\ $上估计。注意到原始损失(3)是估计样本分布为$\ p(x,y)=\sum^M_{j=1}\alpha_j\delta_{x_j,y_j}(x,y)\ $的一种特殊情况，$\ \delta_{x_j,y_j}\ $表示在训练样本$\ (x_j,y_j)\ $的Dirac脉冲。不同的是，我们提出估计一个样本分布$\ p(x,y)\ $的简洁模型可以更有效的近似期望损失(10)。

我们观察到样本$\ x\ $的期望相关输出$\ y\ $的形状是预设的，这里是高斯函数。公式(3)中的标注函数$\ y_j\ $仅仅因通过将峰值与目标中心对齐的平移而不同。对齐相当于是对特征图$\ x\ $移位。因此我们可以假设目标在图像区域中心并且所有$\ y=y_0\ $都是相同的。如此，样本分布可以分解为$\ p(x,y)=p(x)\delta_{y_0}(y)\ $而我们只需要估计$\ p(x)\ $。为此我们应用Gaussian Mixture Model 则$\ p(x)=\sum^L_{l=1}\pi_l\mathcal{N}(x;\mu_l;I)\ $。$L$为高斯组件$\ \mathcal{N}(x;\mu_l;I)\ $的数量，$\ \pi_l\ $为组件$\ l\ $的先验权重，$\ \mu_l\in\mathcal{X}\ $是其均值。协方差矩阵设置为单位矩阵$\ I\ $以避免高维样本空间开销大的推理。

为了更新GMM，我们使用Declercq and Piater在线更新算法的简化版本。给定一个新样本$\ x_j\ $，我们首先使用$\ \pi_m=\gamma\ $以及$\ \mu_m=x_j\ $初始化一个新组件$\ m\ $。如果组件数量超过了限制$\ L\ $,我们简化GMM。我们舍弃权重$\ \pi_l\ $低于阈值的组件。除此之外，我们合并两个最接近的组件$\ k\ $和$\ l\ $到一个共同组件$\ n\ $
$$
\pi_n=\pi_k+\pi_l\ \ \ \ \ \ ,\ \ \ \ \ \ \mu_n=\frac{\pi_k\mu_k+\pi_l\mu_l}{\pi_k+\pi_l}\ \ \ \ \ \ \ \ (11)
$$
需要的距离比较$\ \parallel\mu_k-\mu_l\parallel\ $可以通过Parseval公式在傅里叶域很高效的计算。

最终，期望损失(10)近似为
$$
E(f)=\sum^L_{l=1}\pi_l\parallel S_f\{\mu_l\}-y_0\parallel^2_{L^2}+\sum^D_{d=1}\parallel wf^d\parallel^2_{L^2}\ \ \ \ \ \ \ \ (12)
$$
注意到在公式(3)中高斯平均$\ \mu_l\ $以及先验权重$\ \pi_l\ $分别直接替换了$\ x_j\ $以及$\ \alpha_j\ $。所以可以使用第二节中描述的相同训练策略。

相比于(3)复杂度上关键的不同是样本的数量从$\ M\ $降到了$\ L\ $。在实验中，我们展示了组件数量$\ L\ $可以设置为$\ M/8\ $，同时获得提升的跟踪性能。我们的样本分布模型$\ p(x,y)\ $通过将样本$\ x\ $替换为投射样本$\ P^TJx\ $可以与3.1节中的分解卷积相结合。投射并不会影响我们的公式，因为矩阵$\ P\ $在第一帧后是常量。

##### 3.3 Model Update Strategy

DCF跟踪中标准的方法是在每一帧更新模型。在C-COT中，这意味着在每个新样本添加后优化(3)，通过迭代的解决正规方程(5)。基于迭代优化的DCF方法利用损失函数在帧之间逐渐的变化。因此当前的过滤器估计提供了迭代搜索很好的初始化。然而，在每一帧更新过滤器依然对计算负载上影响很大。

相比于以连续的方式在每一帧更新模型，我们使用一种在非DCF跟踪器中常见的稀疏更新方案。直观的，优化过程应在目标发生了足够多改变时才启动。但是，寻找该条件很重要并可能导致不必要的复杂启发式。而且，基于损失(3)梯度的最优化条件，给定(5)的残差，在实践中估计的开销很大。因此我们避免明确的检测目标的改变并简单的在每个第$\ N_s\ $帧时启动优化过程以更新过滤器。参数$\ N_s\ $决定了多久更新一次过滤器，$\ N_s=1\ $时对应于在每一帧更新过滤器，和标准DCF方法一样。在第每$\ N_s\ $帧，我们执行固定数量$\ N_{CG}\ $的Conjugate Gradient迭代来改进模型。这使得每帧平均的CG迭代次数减少到了$\ N_{CG}/N_S\ $，对于学习的计算复杂度有着可观的影响。注意到$\ N_s\ $不影响3.2节中提到的每帧更新的样本空间模型的更新。

令我们吃惊的是，对模型适度频率的更新($\ N_s\approx 5\ $)会使得跟踪结果提升。我们将该影响归功于减少了对近期训练样本过拟合。推迟更新模型几帧，则损失通过在训练样本中增加新的mini-batch来更新。这可能会使得学习更稳定，特别是新样本受到突然变化的影响场景时，如面外旋转，变形，杂乱以及遮挡（见图1）。

虽然增加$\ N_s\ $使得计算减少，它也会减缓优化的收敛速度，导致模型判别性下降。通过增加CG迭代次数的天真补偿会抵消收获的计算增益。相比于此，我们目的在于通过更好的使CG算法适应损失动态变化的在线跟踪已达到更快的收敛。我们通过将Fletcher-Reeves 公式替换为 Polak-Ribiere公式以寻找动力因子来达到该目的，因为这已经被证明会提升对于不准确以及灵活的预处理的收敛速率，这与我们的方案相似。

#### 4. Experiments

我们通过在四个benchmarks上进行大量的实验以验证我们提出的公式。

##### 4.1 Implementation Details

我们的跟踪器使用Matlab实现。我们应用了与C-COT相同的特征表示，即VGG-m网络的第一层(Conv-1)与最后一层(Conv-5)的结合，以及HOG和Color Name(CN)。对于3.1节中的分解卷积，每个特征类型学习一个系数矩阵$\ P\ $。每个特征的设置见表1。公式(7)中的正则化参数$\ \lambda\ $设置为$2\cdot10^{-7}$。损失(7)在第一帧被优化，使用10次Gauss-Newton迭代以及20次CG迭代（子问题(9)）。在第一次迭代$\ i=0\ $中，过滤器$\ \hat{f_0}\ $被初始化为0。为了保证跟踪器的确定性，我们使用PCA初始化系数矩阵$P_0$，尽管我们发现随即初始化也一样鲁棒。

对于3.2节中的样本空间模型，我们设置学习率$\ \gamma=0.012\ $。组件数量设置为$\ L=50\ $,相比于C-COT中使用的样本数量($\ M=400\ $)减少了八倍。我们每$\ N_s=6\ $帧更新过滤器。我们使用与C-COT相同的$\ N_{CG}=5\ $Conjugate Gradient 迭代次数。注意所有的参数设置在所有数据集的视频中保持固定。

##### 4.2 Baseline Comparison

在这里我们通过展示逐步整合我们贡献的影响已在VOT2016 benchmark上分析我们的方法。VOT2016数据集包含了由一组300多个视频编辑而成的60个视频组成。性能在准确度(成功跟踪中的平均重叠)以及鲁棒性(失败率)上被评估。整体性能以平均重叠期望（EAP）来评估，包括了准确度和鲁棒性。详情可参见[24]。

表2展示了对我们贡献的分析。将我们的分解卷积集成到baseline使得性能提高并且复杂度下降。样本空间模型进一步提高了2.9%EAO的相对增益，同时学习复杂度降低了8倍。此外合并我们提出的模型更新将EAO得分提升到了0.374，使得最终相比于baseline 13.0%的相对增益。表2中我们也展示了我们贡献对于跟踪器速度的影响。为了公平比较，我们报告了表中所有条目在单CPU上的FPS，不考了特征提取的时间。我们每一个贡献系统的提高了跟踪器的速度，组合起来最终获得了相比于baseline 20倍的增益。当包括所有步骤时(包括特征提取)，跟踪器的GPU版本以8FPS运行。

我们发现表1中的设置对小变化很敏感。可以通过减少过滤器数量$\ C\ $可以获得较高的速度增益，以性能轻微下降为代价。为了更进一步分析我们联合学习的分解卷积方法，我们与第一帧使用PCA获得矩阵$\ P\ $进行比较。PCA将EAO从0.331降到了0.319,而我们的基于判别式学习的方法达到了0.342。

我们发现，在使用相同数量组件与样本时($\ L=M\ $)，相比于C-COT中的训练样本集管理，我们的样本模型提供了一致更好的结果。这对于小数量的组件/样本尤为明显：当将标准方法中的样本数量$\ M=400\ $减少到$\ M=50\ $时，EAO从0.342下降到了0.338(-1.2%)。而当使用我们的方法$\ L=50\ $时，EAO提升了2.9%，到达0.351。在模型更新时，我们发现当$N_s$从1升至6时，性能有上升趋势。当进一步提升$N_s$，性能会逐渐下降。因此我们在整个实验中设置$N_s=6$。

##### 4.3 State-of-the-art Comparison

我们在四个跟踪benchmark上将我们的方法与state-of-the-art进行了比较。

**VOT2016 Dataset : **表3中，我们将我们的方法与VOT2016挑战中排名前几的方法在EAO，鲁棒性，准确度以及速度等方面进行了比较。VOT2016挑战中排名第一的方法，C-COT，提供了0.331的EAO得分。我们的方法相比于C-COT获得了13.0%的相对增益。此外，我们的ECO跟踪器达到了最好的失败率0.72，同时保持了不错的真确度。我们也报告了EFO上的整体速度，该指标对硬件性能进行了标准化。注意到EFO也将特征提取时间计算在内，这是与我们的DCF提高独立的主要附加复杂度。在比较中，我们的跟踪器ECO-HC只使用手工特征(HOG和Color Names)可以达到最好的速度。在前三的跟踪器中，都是基于深度特征的，TCNN获得了最快的速度，EFO=1.05。我们的深度特征版本(ECO)提速了五倍EFO并相比于TCNN有15.1的相对EAO增益。图4展示了前10跟踪器的EAO曲线。

**UAV123 Dataset : **使用无人机的空中跟踪在最近备受关注，包括许多视觉应用如野生动物监控，搜索和救援，导航以及人群检测。在这些应用中，都需要持续的UAV导航，因此实时跟踪输出很重要。在这样的情况下，所需的跟踪器应该实时的运行在有效的硬件能力下，如CPU或移动CPU平台下，并保持准确与鲁棒。因此我们介绍一个我们方法的实时版本(ECO-HC)，基于手工特征(HOG和Color Names)，在单i7CPU上可以以60FPS运行(包括特征提取)。

我们在最近提出的空中视频benchmark,UAV123(用于低海拔UAV目标跟踪)上评估我们的方法。该数据包括123个空中视频，超过110K帧。使用成功图来评估跟踪器，计算为超过阈值IOU的帧数百分比。跟踪器通过AUC得分来排名。图5a展示了整体123个视频的成功图。我们比较了[29]中报告的所有跟踪结果并增加了Staple\[1\](由于其具有高帧率)，以及C-COT。在比较中前五的跟踪器，只有Staple实时运行，AUC得分为45.3%。我们的ECO-HC跟踪器也实时运行，AUC得分为51.7%，比Staple表现好很多。C-COT的AUC得分为51.7%。我们的ECO比C-COT表现要好，AUC得分为53.7%，使用相同的特征。

**OTB2015 Dataset : **我们将我们的方法与20种state-of-the-art方法进行了比较:TLD,Struck,CFLB,ACT,TGPR,KCF,DSST,SAMF,MEEM,DAT,LCT,HCF,SRDCF,SRDCFad,DeepSRDCF,Staple,MDNet,SiameseFC,TCNN以及C-COT。

图5b展示了OTB-2015数据集中100视频的整体成功图。在相比较的使用手工特征的跟踪器中，SRDCFadAUC得分最高，为63.4%。我们的方法ECO-HC，也使用手工特征，比SRDCFad表现好，AUC得分为65%，同时在CPU上运行速度为60FPS。在比较的深度特征跟踪器中，C-COT，MDNet以及TCNN分别达到了最好的AUC得分结果，分别为69%，68.5%以及66.1%。我们的方法ECO，达到了最好的AUC得分70.0%。

**TempleColor Dataset : **在图5c中我们展示了TempleColor数据集上的结果。我们的方法依然在C-COT上达到了大量的性能提升，AUC上获得了0.8%的增益。

#### 5. Conclusions

我们回顾了核心DCF formulation以解决过拟合和计算复杂度的问题。我们提出了一个分解卷积算子来减少模型中参数的数量。我们也提出了一个训练样本分布的简洁生成式模型以大幅的减少学习的存储和时间复杂度，同时增加样本多样性。最后，我们提出了一个简单而有效的模型更新策略以减少最近样本的过拟合。四个数据集上的实验证明了我们的方法有state-of-the-art的性能，同时帧率也有所提高。