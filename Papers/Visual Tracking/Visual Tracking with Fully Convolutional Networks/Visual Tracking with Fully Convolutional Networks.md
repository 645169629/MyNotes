### Visual Tracking with Fully Convolutional Networks

#### Abstract

我们提出了一种新的使用全卷积神经网络的通用目标跟踪方法。相比于将卷积神经网络（CNN）看作一个黑箱特征提取器，我们对CNN特征属性（在大量图像数据以及ImageNet分类任务上离线预训练）进行了深入研究。我们的发现启发了跟踪系统的设计。我们发现不同层次的卷积层从不同方面表征了目标。顶层编码了更多语义特征并作为类别检测器，而低层携带更多判别信息可以更好的将目标与相似外观的干扰物分开。在跟踪时，使用一种轮换机制来共同使用这两层。我们也发现对于跟踪目标，只有一部分的神经元是相关的。我们开发了一种特征图选择方法以移除噪声和不相关的特征图，如此可以减少计算冗余并提高跟踪准确度。在跟踪benchmark上大量的评估表明我们提出的跟踪器比state-of-the-art方法表现要好。

#### 1. Introduction

视觉跟踪，作为计算机视觉的基本问题，有着广泛的应用。尽管在过去的几十年中有着许多发展，设计一个可以很好的解决严重外观改变，姿势变化，严重遮挡以及背景杂乱等问题的鲁棒跟踪器十分具有挑战性。

现存的基于外观的跟踪方法应用了生成式或判别式模型来将前背景分开以及辨别同时出现的目标。一个主要的缺点就是它们依赖于低层手工特征，这些特征不能捕获目标语义信息，对于严重遮挡不鲁棒并且只有有限的区分能力。

受到大型视觉数据集的出现以及计算能力的快速发展的驱使，深度神经网络（DNNs），特别是卷积神经网络（CNNs，具有很强的特征表示学习能力），在计算机视觉任务中展示了突破的性能，如图像分类，目标检测以及显著性检测。不同于手工特征，这些CNNs从大量标注视觉数据以及大量目标类别中学到的特征携带了丰富的高层语义信息并有利于区分不同类别的物体。这些特征具有很好的泛化能力。最近的研究表面这些特征对于数据受损也很鲁棒。它们的神经元响应在目标识别上有很强的选择性，即，对于特定的目标只有一部分的神经元响应而不同类别目标具有不同的响应神经元。

收到上述的启发，我们将CNNs应用于跟踪以解决上述的挑战。考虑到在线跟踪有限的训练样本以及深度模型的复杂度，不好直接在跟踪上应用CNNs，由于CNNs的能力依赖于大量的训练。先前的工作尝试将离线学习的DNN特征转移到在线跟踪并达到了state-of-the-art性能。但是，DNN在这些工作中被看作黑箱分类器。相反的，我们以在线视觉跟踪的角度对CNN特征的属性进行了深入研究以准确高效的使用这些特征。我们发现了两种属性并受其启发设计了跟踪系统。

![f1](E:\研究生\本科毕业设计\基于深度学习的运动目标跟踪实现\Visual Tracking with Fully Convolutional Networks\images\f1.png)

第一点，不同层/深度的CNN特征具有不同的属性以适应跟踪问题。顶层巻积层捕获更多抽象以及高层语义特征。它们有利于区分不同类别的目标并对变形和遮挡鲁棒，如图1(a)所示。但是，它们对于同类别的物体具有很少辨别性，如图1(b)所示。低层提供了更详细的局部特征，可以帮助将目标与相似外观的干扰物（如，相同类别的其他目标）分开，如图1(b)所示。但是，它们对外观的突然改变不鲁棒，如图1(a)所示。基于这些观察，我们提出根据干扰物的出现自动的选择这两层的使用。

第二点，在ImageNet上预训练的CNN特征用于分辨通用目标。但是，对于某个特定目标，不是所有特征对于鲁棒跟踪是有用的。一些特征响应可能噪声。如图1(c)所示，如果使用了全部特征图，很难区分目标与背景。相反的，通过合适的特征选择，与目标表示不相关的噪声特征图会被清除，而剩下的特征图会更准确的强调目标并抑制背景的响应。我们提出了一种规则方法来选择判别特征图并舍弃噪声或不相关的特征图以用于跟踪目标。

我们工作的贡献分为三层：

- 我们分析了从大型图像分类任务中学到的CNN特征并寻找对于在线跟踪重要的属性。这促进了对CNN特征的进一步理解并帮助更好的设计有效的基于CNN的跟踪器。

- 我们提出了一个新跟踪方法，共同的考虑了不同层次两个巻积层以使其互补的解决剧烈的外观改变并区分目标与其相似干扰物。如此设计显著的减轻了漂移。

- 我们设计了一个规则方法以自动的选择辨别特征图并舍弃噪声及不相关特征图，进一步提高跟踪准确度。

#### 2. Related Work

跟踪器包含两个组件：一个在线更新的外观模型和一个寻找最有可能目标位置的搜索策略。近期大部分工作专注于设计外观模型。在生成式模型中，搜索候选以最小化重建误差。例如，Ross等在线学习子空间来对目标外观建模。最近，稀疏编码被应用于跟踪，其中通过目标模板的稀疏线性组合来重建目标。在判别式模型中，跟踪被当作前景背景区分问题。基于CRFs，boosting，多示例学习的在线学习算法被应用于跟踪并达到了很好的性能。在[40]中，生成式和判别式模型被合并以更准确的在线跟踪。所有这些方法都基于手工特征。

在线跟踪中应用DNN正在被全面探索。在[35]中，一个堆叠的去噪声自动编码器（SDAE）在小型辅助图像数据及上离线学习以学习通用特征然后应用于在线跟踪。在[19]中，跟踪被作为使用在线训练CNN（没有离线预训练）的前-背景分类问题。Fan等使用了全卷积网络于人类跟踪。它使用整个帧作为输入并通过one-pass前向传播预测前景热图。省下了多余的计算。然而[35]和[19]以patch-by-by扫描方式运行。给定从帧只能挂裁剪的$\ N\ $个patches，DNNs必须估计$\ N\ $次。patches之间的重叠导致了很多重复计算。在[12]中，预训练CNN特征被用来构建特定类别的显著图用于在线跟踪。现有的工作将DNNs用作黑箱特征提取器。我们的贡献还没有在这些工作中使用过。

#### 3. Deep Feature Analysis for Visual Tracking

深度表示的分析对于理解深度学习的机制很重要。但是，对于视觉跟踪目标还很少。在本节中，我们提出一些CNN特征的重要属性依此促进视觉跟踪。我们的特征分析基于在ImageNet 图像分类任务上预训练的16层VGG网络，其中包含13个巻积层接着3个全连接层。我们主要专注于conv4-3层（第10个巻积层）以及conv5-3层（第13个巻积层），这些层都产生512个特征图。

![f2](E:\研究生\本科毕业设计\基于深度学习的运动目标跟踪实现\Visual Tracking with Fully Convolutional Networks\images\f2.png)

**Observation 1 ** *尽管CNN特征图的感知野很大，激活的特征图是稀疏和局部的。激活的区域与目标语义高度相关。*

由于池化和巻积层，conv4-3和conv5-3层的感知野非常大（92x92以及196x196）。图2展示了一些特征图，其中在目标区域具有最大激活值。可以看出特征图只有一小部分区域是非零值。这些非零值是局部的并对主要对应于前景物体的图像区域。我们也使用了[26]中的方法来获得CNN特征的显著图。图2中的显著图（底部行）展示了导致所选特征图最大增长的输入改变位于目标区域内部。因此，特征图捕获的是物体相关的视觉表示。这些证据表明从图像分类中学到的DNN特征是局部的并与目标视觉线索相关。因此，这些CNN特征可用来目标定位。

**Observation 2 **  *许多CNN特征图是噪声或与区分目标和背景的任务是不相关的。*

在ImageNet上预训练的CNN特征可以描述各种各样的通用目标因此它们被提出使用大量神经元来检测丰富的视觉模式。但是，当跟踪某个特定目标物体时，它应该专注于更小的可以将目标与背景分开的视觉模式子集。如图1(c)所示，所有特征图的平均值与背景噪声混杂。我们应该舍弃在目标区域以及背景区域都有高响应的特征图，这样跟踪器才能不漂移到背景区域。图3展示了所有位于目标区域内特征图激活值的直方图。特征图激活值定义为其在目标区域的响应值之和。如图3所示，大部分特征图在目标区域具有小或零值。因此，有许多特征图与目标物体无关。这一性质为我们提供了只选择一小部分特征图而不降低跟踪性能的可能性。

![f3](E:\研究生\本科毕业设计\基于深度学习的运动目标跟踪实现\Visual Tracking with Fully Convolutional Networks\images\f3.png)

**Obaservation 3 ** *不同层编码不同类型的特征。高层捕获目标类别的语义概念，而低层编码判别特征以捕获类别内部改变。*

由于特征图的冗余，我们提出了一个稀疏表示方案来促进更好的可视化。通过在VGG网络前向传播某物体的图像，我们在某巻积层（conv4-3或conv5-3）获得特征图$\ \mathrm{F}\ \in\ \mathbb{R}^{d\times n}\ $，其中每个特征图被变形为$\ d\ $-维向量，$\ n\ $表示特征图数量。我们进一步将图像与前景mask$\ \pi\ \in\ \mathbb{R}^{d\times 1}\ $联系起来，其中如果每个特征图的第$\ i\ $个神经元位于前景目标内部，则第$\ i\ $个元素$\ \pi_i=1\ $,否则$\ \pi_i=0\ $。我们通过解如下公式以使用特征图子集重建前景mask
$$
\begin{align*}\min_c\parallel\pi&-\mathrm{Fc}\parallel^2_2+\lambda\parallel\mathrm{c}\parallel_1\ \ \ \ \ \ \ \ \ (1)\\&s.t.\ \mathrm{c}\succeq0\end{align*}
$$
其中$\ \mathrm{c}\ \in\ \mathbb{R}^{n\times 1}\ $为稀疏系数向量，$\lambda$为平衡重建误差和稀疏度的参数。

![f4](E:\研究生\本科毕业设计\基于深度学习的运动目标跟踪实现\Visual Tracking with Fully Convolutional Networks\images\f4.png)

图4展示了使用conv5-3特征图重建的前景mask。在图4中两个例子（人脸以及摩托车），我们只在计算了第一列图像稀疏系数并使用该系数来重建剩余列的前景mask。图4(a)中选择的特征图捕获了人脸的语义信息并对外观改变甚至身份改变鲁棒。图4(b)中选择的特征图准确的将目标与杂乱的背景分开，并对姿势形变和旋转具有不变性。尽管在图像分类任务上训练，conv5-3层编码的目标类别高层语义表示可以用于物体定位。但是，特这特征不足以判别同类别的不同物体，因此我们不能直接将其应用于视觉跟踪。

相比于conv5-3特征图，conv4-3捕获的特征对类内外观变化更敏感。图2中，所选择的conv4-3特征图可以很好的将目标人和其他非目标人分开。除此之外，不同的特征图专注于不同目标的位置。

为了更进一步验证，我们进行了两个定量实验。我们从benchmark序列中收集了6个人的1800张脸部图像以及2000张不包含脸部的图像。每个图像关联一个前景mask以指示前景物体区域。在第一个实验中，我们评估了分别使用conv4-3和conv5-3层将图像分类为面部以及非面部的准确度。三个人的三张面部图像被选作正训练样本以计算出一个稀疏系数集$\{c_1,c_2,c_2\}$。在测试阶段，给定输入图像的特征图$\ \mathrm{F}\ $以及前景mask$\ \pi\ $，特征图的重建误差$\ e\ $为
$$
e=\min_i\parallel\pi-\mathrm{Fc}_i\parallel^2_2\ \ \ \ \ \ \ \ \ \ (2)
$$
如果图像的重建误差$\ e\ $低于预设阈值，则被分类为脸部图像。否则，被分类为非脸部图像。

在第二个实验中，我们的任务是将所有的脸部图像分类至不同的人。对于每个人，使用20张图像作为训练样本以学习稀疏系数$\ c_i,i=1,2,...6\ $。在测试阶段，计算每个人的前景mask重建误差，接着测试图像被分类到具有最小误差的人。
$$
id=\arg\min_i\parallel\pi-\mathrm{Fc}_i\parallel^2_2\ \ \ \ \ \ \ \ \ (3)
$$
使用conv4-3和conv5-3两个实验的分类准确度如表1所示。conv5-3的特征图编码了高层语义信息，可以更好区分面部及非面部目标。但他们在区分人时比conv4-3的特征图准确度要低。conv4-3的特征图保留了更多中层信息，使得相同类别的分类更准确。但它们在区分面部与非面部时不如conv5-4的特征图。这些结果启发了我们考虑共同使用这两层用于鲁棒跟踪。

![t1](E:\研究生\本科毕业设计\基于深度学习的运动目标跟踪实现\Visual Tracking with Fully Convolutional Networks\images\t1.png)

#### 4. Proposed Algorithm

![f5](E:\研究生\本科毕业设计\基于深度学习的运动目标跟踪实现\Visual Tracking with Fully Convolutional Networks\images\f5.png)

我们提出的基于全卷积网络的跟踪器概览（图5）如下：

1. 对于给定目标，在VGG网络conv4-3和conv5-3上执行特征图选择进程以选择最相关的特征图并避免在噪声特征图上过拟合。

2. 一个捕获目标类别信息的生成网络（GNet）构建在conv5-3层选择的特征图之上。

3. 一个区分具有相似外观的物体和背景的特定网络（SNet）构建在conv4-3层选择的特征图上。

4. GNet和SNet在第一帧初始化以形成目标前景热图回归并应用不同的在线更新策略。

5. 对于新的帧，ROI框住上一个包含目标和背景上下文的目标位置并传播通过全卷积网络。

6. 两个前景热图分别通过GNet和SNet生成。目标定位基于两个热图单独的执行。

7. 最后目标通过一个干扰项检测方案（决定第6步那些热图被使用）来决定最终目标。

##### 4.1 Feature Map Selection

我们提出的特征图选择方法是基于目标热图回归模型，称为sel-CNN,并在VGG网络的conv4-3和conv5-3上独立执行。sel-CNN模型包含一个dropout层接着一个巻积层，没有任何非线性变换。它接收待选择的特征图（conv4-3或conv5-3）作为输入来预测目标热图 M （一个2维高斯，以目标ground-truth位置为中心，与目标尺寸成比例，如图1(a)和(b)所示）。该模型通过最小化预测前景热图$\ \hat{\mathrm{M}}\ $与目标热图$\ \mathrm{M}\ $的平方损失来训练
$$
L_{sel}=\parallel\hat{\mathrm{M}}-\mathrm{M}\parallel^2\ \ \ \ \ \ \ \ \ \ (4)
$$
在通过反向传播的参数学习收敛后，我们固定模型参数并根据对损失函数的影响选择特征图。对特征图$\ \mathrm{F}\ $进行向量化，记作$\ vec(\mathrm{F})\ $。记$\ f_i\ $为$\ vec(\mathrm{F})\ $的第$\ i\ $个元素。由特征图$\ \delta\mathrm{F}\ $的扰动产生的损失函数变化可以通过两级泰勒展开来计算
$$
\delta L_{sel}=\sum_ig_i\delta f_i+\frac{1}{2}\sum_ih_{ii}(\delta f_i)^2+\frac{1}{2}\sum_{i\ne j}h_{ij}\delta f_i\delta f_j\ \ \ \ \ \ \ \ \ \ (5)
$$
其中$\ g_i=\frac{\partial L_{sel}}{\partial f_i}\ $,$\ h_{ij}=\frac{\partial^2 L_{sel}}{\partial f_i\partial f_j}\ $，分别为目标函数关于输入特征图的一阶，二阶导数。特征图中的元素数量很大（大于270000）。计算所有的二阶导数$\ h_{ij}\ $的复杂度为$\ O(270000^2)\ $,时间开销很大。我们以一个对角矩阵近似海塞矩阵，其中公式(5)右边的第三项被忽略。一阶导数$\ g_i\ $和二阶导数$\ h_{ii}\ $都可以由反向传播计算。

在设置$\ f_i\ $为0后，我们定义元素$\ f_i\ $的重要性为目标函数的改变，即，$\ \delta f_i=0-f_i\ $。根据公式(5)，$\ f_i\ $的重要性可以通过下式计算
$$
s_i=-g_if_i+\frac{1}{2}h_{ii}f^2_i\ \ \ \ \ \ \ \ \ \ \ \ (6)
$$
第$\ k\ $个特征图的重要性进一步定义为其所有元素的重要性和$\ S_k=\sum_{x,y}s(x,y,k)\ $，其中$\ s(x,y,k)\ $为在第$\ k\ $个特征图上位置$\ (x,y)\ $元素的重要性。所有特征图根据其重要性降序排列，选择前面$\ K\ $个特征图。这些特征图对目标函数有重要作用，因此与跟踪任务最相关。我们的特征图选择方法以在线的方式执行。在我们的实验中，我们只在第一帧执行特征选择并达到了很好的性能。这应该部分归功于CNN特征的鲁棒性。

使用损失函数的二次近似以移除网络中的连接，之前的目的在于减少参数数量并提高速度，而我们的目标在于移除噪声特征图并提高跟踪准确度。

##### 4.2 Target Localization

图5(c)和(d)展示了对于目标定位的CNN设计。在第一帧选择特征图之后，我们在conv4-3和conv5-3选择的特征图上分别构建SNet和GNet。这两个网络具有相同的结构，包含两个附加的巻积层。第一个附加巻积层卷积核为$\ 9\times9\ $，输出36个特征图作为下一层的输入。第二个附加巻积层卷积核为$\ 5\times 5\ $,输出输入图像的前景热图。这两层使用ReLU作为非线性函数。

SNet和GNet在第一帧初始化，通过最小化如下平方损失函数
$$
\begin{align*}&L=L_S+L_G,\\&L_U=\parallel\hat{M}_U-M\parallel^2_F+\beta\parallel W_U\parallel^2_F\ \ \ \ \ \ \ (7)\end{align*}
$$
其中下标$\ U\in\{S,G\}\ $表示SNet和GNet。$\ \hat{M}_U\ $表示网络预测的前景热图；$\ M\ $为目标热图，$W_U$为巻积层的权重参数；$\beta$为权重衰减的权衡。

注意到用于选择特征的sel-CNN和用于定位的SNet和GNet在CNN结构上不同。sel-CNN结构很简单以避免使用噪声特征图而过拟合，而SNet和GNet更复杂。因为噪声特征图被特征选择方法舍弃，更复杂的模型会崔津跟踪更准确。详细实验结果以及用于定位和特征图选择的不同模型选择在补充材料中。

在一个新帧，我们在上一个目标位置为中心取一个矩形ROI。通过在网络中前传ROI区域，GNet和SNet都预测前景热图。目标定位首先在GNet产生的热图上执行。记目标定位为$\ \hat{\mathrm{X}}=(x,y,\sigma)\ $，其中$x$，$y$以及$\sigma$分别表示中心坐标以及目标边界框尺度。给上一帧定目标位置$\ \hat{\mathrm{X}}^{t-1}\ $，我们假设当前帧的目标位置候选服从高斯分布
$$
p(\mathrm{X}^t|\hat{\mathrm{X}}^{t-1})=\mathcal{N}(\mathrm{X}^t;\hat{\mathrm{X}}^{t-1},\Sigma)\ \ \ \ \ \ \ \ \ \ \ (8)
$$
其中$\ \Sigma\ $为对角协方差矩阵，表示位置参数的方差。第$\ i\ $个候选的置信度为所有候选区域的热图值，$\ conf_i=\sum_{j\in R_i}\hat{M}_G(j)\ $，其中$\ \hat{M}_G\ $表示GNet产生的热图；$\ R_i\ $为第$\ i\ $个目标候选区域，根据其位置参数$\ \mathrm{X}^t_i\ $;$\ j\ $表示坐标索引。GNet预测置信度最高的候选为目标。

根据第三节的分析，GNet基于conv5-3层捕获语义特征并对类内变化具有不变性。因此，GNet生成的前景热图突出了目标和相似外观的背景干扰物。

为防止跟踪器漂移到背景，我们进一步提升干扰物检测方案以决定最终的目标位置。记GNet预测的目标位置为$\ \hat{X}_G\ $，对应的特征图中国的目标区域为$\ R_G\ $。背景出现干扰物的概率可以由目标区域外的置信度值与目标区域内的置信度值的比例计算。
$$
P_d=\frac{\sum_{j\in \hat{M}_G-R_G}\hat{M}_G(j)}{\sum_{k\in R_G}\hat{M}_G(k)}
$$
其中$\ \hat{M}_G-R_G\ $表示在热图$\ \hat{M}_G\ $上的背景区域。当$\ P_d\ $小于某阈值时（使用中为0.2），我们假设没有发现干扰物并使用GNet预测的目标位置作为最终结果。否则，同样的目标定位程序会在有SNet预测的热图$\ \hat{M}_S\ $上执行以确定最终目标位置。

##### 4.3 Online Update

为了避免由在线更新引入的背景噪声，我们固定GNet，只更新SNet。SNet的更新遵循如下两条规则：适应规则和判别规则，分别专注于使SNet适应目标外观变化和提高前景背景判别能力。根据适应规则，我们使用置信度最高的跟踪结果每20帧调整一次SNet。基于判别规则，当干扰物被检测到，使用第一帧的跟踪结果以及当前帧来更新SNet，通过最小化
$$
\begin{align*}\min&\beta\parallel\mathrm{W}_S\parallel^2_F+\sum_{x,y}\left\{ \left [\hat{M}^1_S(x,y)-M^1(x,y)\right]^2\\+\left[1-\Phi^t(x,y)][\hat{M}^t_M(x,y)-M^t(x,y)\right]^2\right\}\end{align*}\ \ \ \ \ \ \ \ \ \ (10)
$$
其中$\ \mathrm{W}_S\ $表示SNet的卷积权重；$\ (x,y)\ $为空间坐标；$\ \hat{M}^t_S\ $和$\ M^t\ $分别表示在第$\ t\ $帧SNet预测的热图以及根据预测目标位置生成的热图（以目标位置为中心的2维高斯）。前景mask$\ \Phi^t\ $表示预测的目标边界框，即，如果位置$\ (x,y)\ $属于目标区域，则$\ \Phi^t(x,y)=1\ $，否则$\ \Phi^t(x,y)=0\ $。

公式（10）的第二项对应于在第一帧定位目标的损失。在当前帧出现干扰物或目标被严重遮挡时，估计的目标区域对于学习目标外观不可靠。因此，我们选择了一种保守策略，通过添加第一帧来监督更新，依此学到的模型可以捕获第一帧的外观。同时，公式（10）中的第三项移除了不可靠目标区域的损失并只考虑当前帧在背景区域的损失。它使得模型将更多的努力分配在将出现的干扰物作为背景。公式（10）中第二项和第三项的组合可以帮助SNet更好的区分目标和背景并减少由遮挡和干扰物造成的模型衰减。

#### 5. Experiments

####6. Conclusion

本文中，我们经验的提出了一些CNN特征的重要属性。基于这些属性，我们提出了使用全卷积网络（在分类任务上预训练）的跟踪算法。我们发现不同层次的巻积层具有不同的属性。我们共同的考虑这些属性以捕获目标的语义信息以及判别目标和背景干扰物。我们进一步提出了规则特征图选择方法来选择判别特征并舍弃噪声或不相关的特征。我们的方法在挑战性的场景下展示出有效的提升。