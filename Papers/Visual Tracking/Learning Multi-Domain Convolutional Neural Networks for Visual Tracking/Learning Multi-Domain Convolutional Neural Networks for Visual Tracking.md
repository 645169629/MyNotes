### Learning Multi-Domain Convolutional Neural Networks for Visual Tracking

#### Abstract

我们提出了一种基于判别训练的卷积神经网络的表示的视觉跟踪算法。我们的算法使用大量具有跟踪ground truth的视频来预训练一个CNN，以此获得一般目标表示。我们的网络由共享层以及多个领域特定层的分支组成，其中领域对应于单个训练序列，而分支主要负责二分类以判别目标是否输入某个领域。我们对于每个领域迭代的训练网络以获得共享层中目标的一般表示。当在新序列中跟踪某个目标时，我们通过结合预训练CNN的共享层以及一个在线更新的新二分类层来构造一个新网络。通过评估前一个目标状态周围随机采样的候选框来进行在线跟踪。我们提出的方法与现有跟踪benchmarks中state-of-the-art方法相比表现出杰出的性能。

#### 1. Introduction

卷积神经网络最近被应用于许多计算机视觉任务上，如图像分类，语义分割，目标检测等等。CNNs如此的成功主要归功于他们在表示视觉数据时的杰出表现。视觉跟踪，却没有受到这一趋势的影响，因为对于视频处理应用，很难收集大量的训练数据，并且也没有特定的视觉跟踪训练算法可用，同时基于低级手工特征的方法实践中表现良好。一些最近的跟踪算法[20,39]通过使用在大型分类数据集（ImageNet）上预训练的CNNs解决了数据缺乏的问题。尽管这些方法足够获得一般的特征表示，但是它们在跟踪上的效果是有限的因为分类和跟踪问题根本上是不一致的，即预测目标类别标签 vs 定位任意类目标。

为了在视觉跟踪中充分利用CNNs的表示能力，需要在大量的特定跟踪数据（涵盖目标和组合的各种变化）上训练CNN。但是在具有完全不同特征的视频中学习一个统一的表示是很具挑战性的。注意到单个序列涉及不同类型的目标，其类别标注，移动模式以及外观是不同的，并且跟踪算法受到特定序列挑战的影响，包括遮挡，形变，光照条件改变，运动模糊等。同一类物体可以看作某序列中的目标或是其他序列的背景，因此训练CNNs更为困难。由于序列如此的变化与不一致，我们认为基于标准分类任务的学习算法不合适，需要合并其他捕获序列独立信息的方法以获得对跟踪更好的表示。

受到此原因的启发，我们提出了一种新的CNN结构，称为Multi-Domain Network（MDNet），来从多个标注的视频序列中学习共享的目标表示，其中每个视频看作是一个单独的域。我们提出的网络在领域特定层具有许多分支以在网络最后进行二分类，并且在前面各层共享从所有序列中捕获的共同信息以进行通用表示学习。MDNet中的每个域分别进行迭代训练，并且共享层在每次迭代中进行更新。通过使用该策略，我们将领域独立信息与领域特定信息分开并学习通用的特征表示用于视觉跟踪。我们的结构另一个有趣的方面是我们的网络相比于分类任务的网络（如AlexNet,VGG nets）具有很少的层数。

我们也基于MDNet学到的表示提出了一种有效的在线跟踪框架。当给定测试序列时，所有二分类层存在的分支（用于训练阶段）都被移除并且构造一个新的单独分支以计算测试序列中的目标得分。新的分类层以及共享层中的全连接层在跟踪期间在线调整以适应新域。在线更新被构造用来对目标长期和短期变化进行建模，分别用于鲁棒性以及适应性，并且学习进程还包含了高效的困难负样本挖掘技术。

我们的算法包含了多域表示学习以及在线视觉更新。我们工作的主要贡献如下：

- 我们提出了基于CNNs的多域学习框架，将领域独立信息与领域特定信息分开以有效的捕获共享表示。

- 我们的框架成功的应用于视觉跟踪，通过多域学习预训练的CNN在新序列的上下文中更新以自适应的学习领域特定信息。

- 大量的实验证明了，在OTB和VOT2014上，我们的跟踪算法相比于state-of-the-art算法表现杰出。

  本文结构如下。在第二节中我们首先回顾相关工作，并在第三节中讨论我们的多域学习方法。第四节表述了我们在线学习以及跟踪算法，第五节展示了在两个跟踪benchmark数据集上的实验结果。

#### 2. Related Work

  ##### 2.1 Visual Tracking Algorithms

  视觉跟踪是计算机视觉中的基本问题之一并已经被研究几十年了。大多数跟踪算法要么是生成式的要么是判别式的。生成式方法使用生成式模型描述目标外观并搜索最适合模型的目标区域。跟多生成式目标外观建模算法被提出包括稀疏表示，密度估计以及增量子空间学习。相比之下，判别式方法目的在于建立模型以区别目标与背景。这些跟踪算法一般基于多示例学习，P-N学习，在线提升，结构输出SVMs等来学习分类器。

  近些年来，相关滤波在视觉跟踪领域受到关注，因为其计算高效性以及具有竞争力的结果。Bolme等提出了一个最小输出平方误差和（MOSSE）滤波器的快速相关跟踪器，运行速度为每秒几百帧。Henriques等使用循环矩阵来构造核相关滤波（KCF），并有效的将多通道特征结合到傅里叶域。随后一些KCF跟踪器的变种被研究以提高跟踪性能。例如，DSST学习一个分离滤波器用于translation与scalling。MUSTer受到心理学记忆模型的启发应用了短期和长期的记忆存储。尽管这些方法在受限的环境下表现满意，但他们使用低级手工特征而具有固有限制，因为这些特征在动态情形（包括光照变化，遮挡，形变等）下是脆弱的。

  ##### 2.2 Convolutional Neural Networks

  CNNs在广泛的计算机视觉应用中展示了杰出的表示能力。Krizhevsky等使用大型数据集以及高效的GPU实现训练了一个深度CNN，在图像分类中获得了极大的性能提升。R-CNN在目标检测任务上使用了一个CNN，训练数据稀少，通过在大型辅助任务数据集上预训练并在目标数据集上调优。

  尽管CNNs取得了重大的成功，只有很少的使用CNNs表示的跟踪算法被提出。一个早期基于CNN的跟踪算法只能处理一种预定义的目标类别，如，人，因为CNN时离线训练的，之后就固定下来。尽管[28]提出了一个基于CNNs池的在线学习方法，但它受限于缺少训练数据来训练深度网络，并且其准确度相比于基于手工特征的方法并没有特别好。一些最近的方法转移了在大型数据集上预训练，用来图像分类的CNNs，但是表示并没那么有效由于分类与跟踪的根本差别。与现有方法相反的是，我们的算法利用了大量视觉跟踪数据的优点用来预训练一个CNNs并获得了有效的表示。

  ##### 2.3 Multi-Domain Learning

  我们预训练深度CNNs的方法属于多域学习，即在该学习方法中训练数据来源于多个域并且域信息被加入到了学习进程。多域学习在自然语言处理中很流行（如，使用多产品的情感分离以及多用户的垃圾邮件过滤），并且很多方法被提出。在计算机视觉领域，多域学习仅在一些域适应方法中会被讨论。如，Duan等提出了用于视频概念检测的SVMs的加权域组合，Hoffman等提出了一个混合形变模型用于目标分类。

####3. Multi-Domain Network(MDNet)

这一节中将描述我们CNN的结构以及获得领域独立表示的多域学习方法。

![f1](images\f1.png)

  ##### 3.1 Network Architecture

我们网络的结构如图1所示。接受107$\ \times\ $107 RGB输入，具有五个隐层包括三个巻积层（conv1-3）以及两个全连接层（fc4-5）。另外，最后的全连接层有$\ K\ $个分支对应于$\ K\ $个域（$\mathrm{fc6^1}-\mathrm{fc6}^K$），也就是训练序列。巻积层与VGG-M network响应的部分完全一样，除了特征图大小由于我们的输入大小而有所改变。接着了两个全连接层具有512个输出单元并结合了ReLUs以及dropouts。$\ K\ $个分支中的每个分支都包含一个二分类层，使用softmax 交叉熵损失，用于区别目标和背景。注意到我们称$\mathrm{fc6^1}-\mathrm{fc6}^K$为域特定层，而所有之前的层为共享层。

  我们的网络结构相比于典型识别任务中使用的AlexNet以及VGG-Nets等小得多。

我们任务如此简单的结构更适合视觉跟踪，原因如下。首先，视觉跟踪目标是区分两个类，目标和背景，因此相比于一般的视觉识别问题（如，ImageNet 1000类别分类）只需要很少的模型复杂度。第二点，深度CNN对于准确定位目标没那么有效，因为空间信息会随着网络深度而减弱。第三点，由于视觉跟踪中目标一般很小，因此需要使输入尺寸变小，自然减少了网络的深度。最后一点，更小的网络明显对于训练和测试都在线执行的视觉跟踪问题更有效。当我们测试更大的网络时，我们的算法准确度下降并且变得很慢。

#####3.2 Learning Algorithm

我们学习算法的目标是训练一个多域CNN以在任意域中区别目标和背景，由于不同域的训练数据具有不同的目标和背景概念因此这一任务是不简单的。但是，在所有域中依然存在目标表示的共同属性，如对光照变化，运动模糊，尺度变换等的鲁棒性。为了提取有用的特征来满足这些共同属性，我们通过加入多域学习框架将领域独立信息与领域特定信息分开。

我们的CNN通过随即梯度下降（SGD）法训练，其中每次迭代处理一个域。在第$\ k^{th}\ $次迭代时，基于包含第（$\ k\ $mod$\ K\ $）$^{th}$个序列中训练样本的minibatch来更新网络，其中只有一个分支fc6$^{（k\ \mathrm{mod}\ K）}$可用。重复该步骤直到网络收敛或达到了预定义的迭代次数。通过该学习进程，领域独立信息在共享层被建模以获得有用的一般特征表示。

#### 4. Online Tracking using MDNet

在完成多域学习之后，领域特定层的多个分支（$\ \mathrm{fc6}^1-\mathrm{fc6}^K\ $）会被替换为用于新测试序列的单个分支（fc6）。接着我们同时在线微调新域特定层以及共享层中的全连接层。

##### 4.1 Tracking Control and Network Update

我们考虑视觉跟踪中两个补足方面，鲁棒性和适应性，通过长期和短期的更新。长期更新通过使用长时间段收集的正样本来定期执行而短期更新在检测到可能的跟踪失败（当估计目标被分类为背景时）时使用短时间段中的正样本来执行。在这两种情况下我们都是用短期中观测到的负样本因为负样本通常对于当前帧是冗余的或无关的。注意到我们在跟踪时维持一个单一网络，其中上述两种更新取决于目标外观变化的速度而执行。

为了预测目标每一帧中的状态，我们使用网络来评估前一个目标状态周围的$\ N\ $个候选采样$\mathrm{x^1},...,\mathrm{x}^N$ ，并从网络中获取其正得分($f^+(\mathrm{x}^i)$)和负得分（$f^-(\mathrm{x}^i)$）。通过寻找具有最大正得分的样本作为最优目标状态$\mathrm{x}^*$
$$
\mathrm{x}^*=\arg\max_{\mathrm{x}^i}{f^+(\mathrm{x}^i)}\ \ \ \ \ \ \ \ (1)
$$

##### 4.2 Hard Minibatch Mining

大部分负样本在通过检测跟踪（tracking-by-detection）的方法中一般是不重要的或冗余的，只有一些分散的负样本在训练分类器时时有效的。因此，在普通SGD方法中，训练样本对学习等同贡献，由于干扰项不足而很容易受限于漂移问题。目标检测中解决该问题的常用方法为难负样本挖掘，其中训练和测试进程交替的确定出难负样本，通常来说是虚警。我们在在线学习进程中使用了该思想。

我们将难负样本挖掘步骤集成到了minibatch选择中。在学习进程每次的迭代中，一个minibatch包含$\ M^+\ $个正样本以及$\ M_h^-\ $个难负样本。通过测试$\ M^-\ $（$\gg\ M^-_h$）个负样本并选出具有最高$\ M^-_h\ $正得分的负样本作为难负样本。随着学习的进行网络变得越来越有区别性，minibatch中的分类变得越来越具挑战性，如图2所示。这一方法检查了预定义样本的数量并有效的选出重要的负样本而不需要单独运行一个检测器来提取负样本（标准难负样本挖掘做法）。

![f2](images\f2.png)

##### 4.3 Bounding Box Regression

由于基于CNN特征的高层抽象以及我们的数据增强策略（在目标周围采样多个正样本），我们的网络有时会找不到包围目标的紧边界框。我们应用了目标检测领域中常用的边界框回归技术来提升定位准确度。给定测试序列的第一帧，我们训练一个线性回归模型并使用目标位置周围样本的conv3特征来预测目标准确位置。在后面的帧中，我们使用回归模型来调整公式(1)估计（如果估计目标可靠，即$\ f^+(\mathrm{x}^*)>0.5\ $）的目标位置。边界框回归器只在第一帧训练因为它对于在线更新很耗时并且考虑到其风险，回归模型的增量学习可能不会非常有效。具体参见[13]。

##### 4.4 Implementation Details

![a1](images\a1.png)

我们跟踪器的整体流程如算法1。在CNN第$\ j^{th}\ $层的过滤器权重标记为$\ \ \mathrm{w}_j\ $,其中$\mathrm{w}_{1:5}\ $通过多域学习来预训练而$\ \mathrm{w}_6\ $会对新序列随机初始化。只有全连接层中的权重$\ \mathrm{w}_{4:6}\ $会在线更新而巻积层中的权重$\ \mathrm{w}_{1:3}\ $则固定；该策略不仅提高计算效率并且通过保留域独立信息而避免了过拟合。$\ \tau_s\ $和$\ \tau_l\ $分别是短期（$\ \tau_s=20\ $）和长期（$\ \tau_l=100\ $）时间段的帧索引集。

实现细节如下。

**Target candidate generation**  为了在每一帧生成目标候选，我们在平移和尺度维上画$\ N\ $（=256）个样本，$\mathrm{x}^i_{\mathrm{t}}=(x^i_t,y^i_t,s^i_t),i=1,...,N$，服从高斯分布，其平均值为前一个目标状态$\ \mathrm{x}^*_{\mathrm{t-1}}\ $，协方差为对角矩阵（0.09$r^2$,0.09$r^2$,0.25），其中$\ r\ $为前一帧目标的宽高平均值。每个候选边界框的尺寸通过将原始目标尺寸乘以1.05$^{S_i}$来计算。

**Training data**  对于离线多域学习，我们每一帧采集50个正样本以及200个负样本，其中正样本和负样本分别与ground-truth有$\ \geq\ $0.7和$\ \leq\ $0.5的IoU重叠率。类似的，对于在线学习，我们采集$\ S^+_t\ $（=50）个正样本以及$\S^-_t\ $（=200）个负样本，与估计目标边界框的IoU重叠率分别为$\ \geq\ $0.7和$\ \leq\ $0.3，除了$S^+_1$=500以及$S^-_1$=5000。对于边界框回归，我们使用与[13]中相同的1000个训练样本，相同的参数。

**Network learning**  对于$\ K\ $个训练序列的多域学习，我们使用100$\ K\ $次迭代，巻积层学习率为0.0001，全连接层学习率为0.001来训练网络。在测试序列的初始帧，我们训练全连接层30次迭代，fc4-5学习率为0.0001，fc6学习率为0.001。对于在线更新，我们训练全连接层10次迭代，学习率比初始帧使用的大三倍以快速适应。动量和权重衰减分别设置为0.9和0.0005。每个minibatch包含$M^+$（=32）个正样本以及从$M^-$（=1024）个负样本中选出的$M^-_h$（=96）个难负样本。

#### 5. Experiment

我们在两个benchmark数据集上评估了我们的跟踪算法，OTB以及VOT2014，并与state-of-the-art跟踪器进行了比较。我们的算法以MATLAB实现，使用了MatConvNet工具，在八核2.20GHz Intel Xeon E5-2660以及NVIDIA Tesla K20m GPU上运行速度为1fps。

##### 2.1 Evaluation on OTB

OTB是一个流行的跟踪benchmark，包含了100全标注的视频并具有大量变体。评估基于两个度量：中心位置误差（center location error）以及边界框重叠率（bounding box overlap ratio）。我们使用了one-pass evaluation(OPE)来比较我们的算法以及其它6个state-of-the-art跟踪器，包括MUSTer，CNN-SVM，MEEM，TGPR，DSST以及KCF，以及在SCM和Stuck benchmark中第一的两个跟踪器。注意到CNN-SVM是另一个基于CNN表示的跟踪算法，其提供了应用深度学习的baseline。除了在OTB100中100个序列中的结果，我们也给出了其早先版本OTB50上的结果。对于离线训练MDNet，我们使用了从VOT2013,VOT2014以及VOT2015中收集的58个训练序列，不包括OTB100中包含的视频。

![f3](images\f3.png)

图3分别展示了基于中心位置误差的精度以及成功图和边界框重叠率。明显可以看出我们的MDNet在两种度量下比state-of-the-art方法都表现要好。在轻微阈值下出色的结果意味着我们的跟踪器很少会丢失目标而在严格阈值下竞争力的结果表面我们的算法可以找到目标的紧边界框。为了进行详细的性能分析，我们也报告了OTB100中多个挑战属性的结果，包括遮挡，旋转，运动模糊等。图4展示了我们的跟踪器有效的解决了所有类型的挑战情形（通常需要高级语义理解）。特别的，我们的跟踪器在低分辨率下可以成功跟踪目标而基于低级特征的跟踪器却不行。

![f4](images\f4.png)

为了验证算法中每个组件的贡献，我们评估并实现了我们方法的几个变体。我们通过与单域学习方法（SDNet，使用多个序列的数据，以单一分支训练网络）进行比较来测试多域预训练技术的有效性。我们也探究了我们跟踪算法的两个附加版本——没有边界框回归的MDNet（MDNet-BB）以及没有边界框回归恶化难负样本挖掘的MDNet（MDNet-BB-HM）。变体的性能都没有MDNet的好，并且每个组件都有助于提高性能。详细结果如图5所示。

![f5](images\f5.png)

图6定性的展示了我们算法相比于state-of-the-art跟踪器的优势。图7展示了我们算法一些视频的案例；在*Coupon*序列中轻微的目标外观改变导致了漂移问题，在*Jump*序列中动态的外观改变使我们的跟踪器完全丢失了目标。

![f6-1](images\f6-1.png)

![f6-2](images\f6-2.png)

![f7](images\f7.png)

##### 5.2 Evaluation on VOT2014 Dataset

为了完整性，我们也给出了在VOT2014（包含25个序列并具有大量变体）数据集上的评估。在VOT 挑战协议中，跟踪失败时跟踪器会被重初始化，评估模型报告准确度和鲁棒性，分别对应于边界框重叠率以及失败数量。有两种实验设置类型；跟踪器要么使用ground-truth边界框(baseline)初始化，要么使用随机干扰边界框初始化（region_noise）。VOT评估也基于统计和实际意义两方面的跟踪器之间的性能差距提供了一个排名分析。详情参见[25]。我们比较了我们的算法以及VOT2014挑战前五的跟踪器——DSST,SAMF,KCF,DGT以及PLT_14，外加两个state-of-the-art跟踪器MUSTer以及MEEM。我们的网络使用OTB100中89个序列进行预训练，不包含与VOT2014数据集中相同的序列。

![t1](images\t1.png)

如表1和图8所示，MDNet整体排名第一——在准确度上排名第一，在鲁棒性上排名第一或第二；它展示了比所有其他方法更好的准确度，即使使用更少的重出始化。而且，MDNet使用不准确重出始化也可以变现很好，如region_noise实验结果所示，这表明了它可以有效的结合重检测模块并完成长期跟踪。我们也报告了关于baseline实验的一些视觉属性的结果，如图9，表明我们的跟踪器在多种挑战环境下是稳定的。

![f8](images\f8.png)

![f9-1](images\f9-1.png)

![f9-2](images\f9-2.png)

#### 6. Conclusion

我们提出了一种新的跟踪算法，该算法基于在多域学习框架下训练的CNN，称为MDNet。我们的跟踪算法从预训练中学习域独立表示，并在跟踪时通过在线学习捕获域特定信息。我们提出的网络相比于图像分类任务所使用的网络结构简单。整个网络离线训练，全连接层以及域特定层在线进行调整。相比于state-of-the-art跟踪算法，我们在OTB和VOT2014上达到了出色的性能。