### Online Object Tracking With Sparse Prototypes

####Abstract：

在线目标跟踪是一个挑战性的问题因为其需要学习一个有效模型来解释由于内在和外在因素导致的外观改变。本文中，我们提出了一个新的稀疏原型在线目标跟踪算法，该方法利用了经典的主成分分析（PCA）算法以及最近的稀疏表示学习有效外观模型的方案。我们在PCA重建中引入了$\ \ell1\ $正则化，并提出一个新算法来通过明确解释数据和噪声的稀疏原型来表示目标。对于跟踪，目标由在线更新的稀疏模型来表示。为了减少跟踪漂移，我们提出了一个考虑遮挡和运动模糊的方法而不是简单的包括图像观察来进行模型更新。在挑战性的图像序列上定性和定量的评估结果都证明了我们提出的跟踪算法与许多state-of-the-art方法相比表现良好。

#### 1. Introduction

作为计算机视觉中基本的问题之一，目标追踪在许多研究中扮演着重要的角色，如运动分析，图像压缩以及动作识别。尽管在过去几十年中有着很多发展，开发一个鲁棒的在线、追踪器依然是一个挑战性的问题，因为解释目标外观的变化是十分困难的，包括内在的（如，姿势变化以及形状变形）和外在的（如，照明的改变，摄像机运动以及遮挡）因素。

一个追踪方法通常包含三个部分：一个外观（观察）模型，该模型评估被观察图像块（与一个状态相关联）属于目标类别的可能性；一个动态模型（或运动模型），该模型目标在于随时间推移描述目标的状态；以及一个搜索策略来找到当前帧的可能状态。本文中，我们提出一个鲁棒的外观模型以考虑遮挡和运动模糊的影响。因此，我们只讨论有关外观模型的关键问题而不是提供一个所有组件的详细回顾。

为了开发一个对于鲁棒目标追踪高效的外观模型，需要考虑一些重要的因素。第一个就是目标如何被表示。任何表示方案都可以基于采用的特征（如，亮度，色彩，纹理，类哈尔特征，基于超像素的特征以及稀疏编码）及描述模型（如，全局直方图，基于部件直方图以及子空间表示）分类。相比于将目标看作低层特征的集合，子空间表示方法提供了一个被追踪事物的复杂概念，并促进了其他视觉任务（如，目标识别）。

第二点，表示方案可以是生成型或判别型 。对于目标追踪，生成式方法专注于对外观建模并将问题定为以最小重建误差寻找图像观察结果（如，试用模版以及子空间模型）。另一方面，判别式算法专注于找出一个决策边界以分辨目标和背景（如，试用提升算法以及支持向量机）。研究表明，判别式模型在训练集较大时表现较好而生成式模型在有限数据下回达到更高的泛化效果。另外的，一些利用生成式和判别式优点的算法也被提出。本文中，我们专注于提出一个试用生成式外观模型的鲁棒算法以考虑遮挡和运动模糊从而减少追踪漂移。

第三点，研究表明在线学习通过适应目标和背景的改变来促进追踪算法。大量的方法包括模版更新，增量子空间学习，以及在线分类器，已经被证明在目标追踪方面十分有效。**但是，由于使用跟踪结果对外观模型直接更新，轻微的误差就会导致不正确的标注训练样本并由于漂移逐渐的降低模型。**为了解决该问题，Avidan 等采用了一种简单的异常值剔除(outlier rejection)方案，而Babenko等提出了用于视觉追踪的多示例学习（MIL）。再者，Grabner等提出了一种半监督提升算法来解决在线更新问题，其中被标注的训练样本只来自于第一帧，后续的实例被认为是未标注数据。这种策略在[25]中进一步被扩展，它引入了正样本和负样本的约束来利用未标注数据的结构。

尽管在减少漂移方面取得了明显成功，但直接解决遮挡问题的的尝试相当少，该问题依然是导致跟踪失败的重要因素。为了解决这个挑战性问题，一些基于部件的方法被采用。Adam等提出了一个使用直方图，基于片段的跟踪方法。Yang等将分别级别的目标识别中的词袋模型应用到了视觉追踪上。在[21]中，Mei等提出了一个追踪算法，通过将问题转换为用模版的稀疏表示来决定最可能的patch。该方法可以通过琐碎模版(trivial templates)的稀疏表示来对局部遮挡建模。但是空间或时间的复杂度十分重要。最近，受到HOG-LBP行人检测器成功的启发，Dinh等提出了一种复杂协同训练方法，试用生成式和判别式追踪器来解决部分遮挡。尽管这些算法在解决部分遮挡时表现相对较好，但他们在外观改变剧烈以及背景杂乱的挑战性图像训练中通常会失败。

本文中，我们提出一种具有适应性外观模型的鲁棒生成式追踪算法以解决部分遮挡和其他挑战性因素。相比于基于部件的模型，我们的算法维持了整体外观信息因此提供了一种对目标的简洁表示。通用利用子空间表示的优点，我们的算法可以处理高分辨率的图像观察(observations)并与现有基于模版稀疏表示的方法相比表现的更高效，结果更有利。与基于子空间的追踪算法相比，我们的算法解决严重遮挡时更高效。与[29]不同的是，我们的算法不需要对生成式和判别式追踪器的复杂结合来解决部分遮挡。在挑战性图像序列上大量的实验和评估证明我们提出的方法对于鲁棒目标追踪时高效的。

#### 2. Related Work and Cotnext

目标追踪方面已经做了很多工作，该问题上更完全的回顾见[30]。在本节中，我们讨论最相关的算法并将本文工作置于适当的上下文。

##### A. Object Tracking With Incremental Subspace Learning

近些年，使用在线子空间学习来进行目标追踪收到了广泛关注。增量视觉追踪（IVT）方法引入了一种在线更新方法来学习和更新目标的低维PCA子空间表示。一些实验结果表明在线更新的PCA子空间表示在解决由于平面旋转，缩放，光照改变以及姿势改变导致的外观改变时很有效。但是，也有研究表明基于PCA子空间的表示方案对部分遮挡很敏感，该问题可以用Eq.1解释
$$
y = Uz\ +\ e\ \ \ \ \ \ \ \ \ \ \ \ \ \ (1)
$$
y表示观察(observation)向量，z表示响应的编码或系数向量，U表示列基向量的矩阵，e表示误差项（图1（a））。

在PCA中，基本的假设就是误差向量e服从高斯分布并具有较小方差（即，小密度噪声）。因此，编码向量z可以通过$\ z = U^Ty\  $来估计，而重建误差可以通过$\ \parallel y-UU^Ty\parallel^2_2\ $来估计。但是当有部分遮挡时，这种假设不适用于视觉追踪中的目标表示，因为噪声项不能以小方差建模。因此，IVT方法对部分遮挡敏感。此外，IVT方法不具备有效的更新机制因为其简单的使用新的观察(observations)来学习新的基向量而不检测部分遮挡并相应的处理这些样本。为了考虑目标追踪中的部分遮挡，我们试用任意但稀疏的噪声来对误差项e进行建模。

##### B. Object Tracking With Sparse Representation

稀疏表示最近被广泛研究并应用于模式识别和计算机视觉领域，如，人脸识别，超分辨率以及图像修复。受到[31的启发，Mei等提出了一种算法($\ \ell_1\ $跟踪器)通过使用稀疏表示来将跟踪问题转变为寻找最可能的patch并且通过下式，使用琐碎模版来解决部分遮挡
$$
y=Az+e=[A\ I]\left[\begin{matrix}z\\e\end{matrix}\right]=Bc\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2)
$$
y表示观测向量(observation)，A表示模板矩阵，z表示相应的系数，e是误差项，可以看作是琐碎模版的系数。图1（b）展示了用于目标追踪的使用琐碎模版的稀疏表示方案。

通过假设每个候选图像块(patch)被一系列目标和琐碎模版稀疏的表示，Eq.2可以通过$\ \ell_1\ $最小化来解决
$$
\min\frac{1}{2}\parallel y-Bc\parallel^2_2+\lambda\parallel c \parallel_1\ \ \ \ \ \ \ \ \ \ \ (3)
$$
$\parallel.\parallel_1$和$\parallel.\parallel_2$分别表示$\ \ell_1\ $和$\ \ell_2\ $标准化。

该方法的基本假设是误差e可以通过任意但稀疏噪声建模，因此它可以用来解决部分遮挡。但是$\ \ell_1\ $跟踪器有两个主要缺点。第一，计算复杂度限制了其性能。因为它需要解决一系列$\ \ell_1\ $最小化问题，所以经常需要处理低分辨率图像以权衡速度和准确度。低分辨率图像可能不足以捕捉到足够的视觉信息以表示目标。$\ \ell_1\ $跟踪器计算开销太大，即使通过[34]中更进一步的改进。第二，它没有利用可以被子空间表示简单捕获的丰富而冗余的图像属性。我们提出一种高效的表示以分离出描述目标外观的部分以及其他噪声的部分。

##### C. Motivation of This Work

在本文中，我们利用用于建模目标外观的子空间学习和稀疏表示两者的优点。它可以看作是使用PCA将$\ \ell_1\ $正则化引入子空间表示中。对于目标追踪，我们用PCA基向量来建模目标外观并通过下式，使用琐碎模版来解释遮挡
$$
y=Uz+e=[U\ I]\left[\begin{matrix}z\\e\end{matrix}\right]\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (4)
$$
y表示观测向量，U表示列基向量矩阵，z表示基向量的系数，e为误差项（可以看作是琐碎模版的系数）。在我们的公式中，原型包含了一小部分PCA基向量以及一系列琐碎模版（见图1（c））。因为假设e是任意但稀疏的噪声，我们通过下式解决Eq.4
$$
\min_{z,e}\frac{1}{2}\parallel y-Uz-e\parallel^2_2+\lambda\parallel e\parallel_1\ \ \ \ \ \ \ \ \ \ \ \ (5)
$$
我们将在下一节提出一个算法来解决该优化问题。在此，我们首先强调了Eq.5和Eq.3公式的不同。在公式Eq.3中，目标和琐碎模版的系数都应是稀疏的（如图1（b））因为目标模板是连贯的(coherent)而琐碎模版的系数是用来建模部分遮挡的。但是，在公式Eq.5中，琐碎模版的系数应该是稀疏的而基向量的系数因为PCA基向量不是连贯的而是正交的。因为琐碎模版的数量远比基向量的数量要多，一个观测(observation)可以通过原型稀疏的表示。因此，我们应开发一套算法来解决Eq.5而不是使用现有的。

我们的公式有以下几点好处。第一，相比于IVT追踪器中的增量子空间表示，我们的方法明确的对遮挡建模也因此可以有效的解决该问题。第二，相比于$\ \ell_1\ $追踪器，我们的算法可以处理高分辨率的图像块(patch)并利用子空间表示而具有较小的计算复杂度。

#### 3. Object Representation Via Orthogonal Basis Vectors and $\ \ell_1\ $Regularization

在本节中，我们提出了一个算法用来以稀疏原型表示目标，如公式Eq.5。使目标函数为$\ L(z,e)=\frac{1}{2}\parallel y-Uz-e\parallel^2_2+\lambda\parallel e\parallel_1\ $,优化问题为
$$
\begin{align*}&\min_{z,e}L(z,e)\\&s.t.\ U^TU=I\end{align*}\ \ \ \ \ \ \ \ \ \ \ (6)
$$
$y\ \in\ R^{d\times1}$表示观测向量，$U\ \in\ R^{d\times k}$表示正交基向量矩阵，$z\ \in\ R^{k\times1}$表示基向量系数，$e\ \in\ R^{d\times 1}$为误差项，$\lambda$为正则化系数，$I\ \in\ R^{d\times 1}$是单位矩阵（d是观测向量的维数，k为基向量的数量）。因为没有对于Eq.6的近似解决方案，我们提出了一个迭代算法来计算$z_{opt}\ $和$\ e_{opt}$。

**引理1**：给定$e_{opt}$，$z_{opt}$可以从$z_{opt}=U^T(y-e_{opt})$中计算得出。

证明：如果给定$e_{opt}$，Eq.6的问题等价于最小化$\ J(z)\ $，$J(z)=\frac{1}{2}\parallel(y-e_{opt})-U_z\parallel^2_2$。这是一个简单最小二乘问题，$z_{opt}=U^T(y-e_{opt})$作为结果很容易被找到。

**引理2：**给定$z_{opt}$，$e_{opt}$可以很容易从$S_\lambda(y-Uz_{opt})$中计算得到，$S_\tau(x)$是一个收缩操作，定义为$S_\tau(x)=sgn(x)\cdot(|x|-\tau)$。

证明：如果给定$z_{opt}$，最小化Eq.6就等价于最小化$G(e)=\frac{1}{2}\parallel e-(y-Uz_{opt})\parallel^2_2+\lambda\parallel e\parallel_1$。这是一个凸优化问题，全局最小值可以通过收缩操作获得，$e_{opt}=S_\lambda(y-Uz_{opt})$。

通过引理1和2，Eq5中的优化问题可以有效的得到解决。我们算法的步骤如表1。

我们注意到一些稀疏主成分分析方法已经被提出[37]-[39]。这些方法扩展了经典的PCA算法，通过非负矩阵分解，$\ell_1$惩罚以及通用数据集的LASSO方法来找出稀疏因子。我们的研究专注于使用原型来推导稀疏系数（PCA基向量和琐碎模版如图1（c）及Eq.4），然而稀疏PCA目的在于从给定训练集中学习稀疏基向量。由于我们所提出的方法利用了图像属性来表示稀疏原型的观测（observations），它似乎对于视觉应用更有效。在第五节中给出的实验结果证明了这种目标追踪构想的动机。

#### 4. Obejct Tracking Via Sparse Prototypes

目标追踪可以看作是具有隐藏状态变量的马尔科夫模型中的贝叶斯推理任务。给定在第t帧时一系列观测的图像$Y_t=\{y1,y2,...,yt\}$，我们递归的估计隐藏状态变量
$$
p(x_t|Yt)\ \propto\ p(y_t|x_t)\ \int\ p(x_t|x_{t-1})p(x_{t-1}|Y_{t-1})dX_{t-1}\ \ \ \ \ \ \ \ \ \ (7)
$$
$p(x_t|x_{t-1})$表示两个连续状态之间的动态（运动）模型，$p(y_t|x_t)$表示观测模型，估计了在$x_t$状态下观测到$y_t$的可能性。通过下式最大化N个样本上的后验估计来获得跟定到第t帧位置所有的观测时最佳被跟踪目标的状态。
$$
\hat{x_t}=\mathop{\arg\max}_{x^i_t}p(y^i_t|x^i_t)p(x^i_t|x_{t-1}),\ i=1,2,...,N\ \ \ \ \ \ \ \ (8)
$$
$x^i_t$表示$x_t$状态的第i个样本，$y^i_t$表示$x^i_t$所预测的图像块(patch)。图2展示了我们跟踪算法的主要步骤。开始时，目标的状态是手动初始化的。

##### A. Dynamic Model

本文中，我们应用了仿射图像变形（affine image warp）来对两个连续帧之间的目标运动建模。6个仿射变换的参数用来建模被追踪目标的$p(x_t|x_{t-1})$。设$x_t=\{x_t,y_t,\theta_t,s_t,\alpha_t,\phi_t\}$，$x_t,y_t,\theta_t,s_t,\alpha_t,\phi_t$分别表示x,y移位，旋转角度，尺度，宽高比以及倾斜。位移状态由随机walk表述，即，$p(x_t|x_{t-1})=N(x_t;x_t-1,\Psi)$,$\Psi$为对角协方差矩阵。

##### B. Observation Model

如果没有发生遮挡，图像观测$y_t$可以被认为是由U所跨越的目标子空间生成并以$\mu$为中心。但是解决部分遮挡在鲁棒目标跟踪中十分重要。我们假设一个被追踪目标的中心图像观测$\bar{y}_t(\bar{y}_t=y_t-\mu)$可以用PCA基向量U和单位向量中的一些元素（即，琐碎模版）的线性组合来表示（图1（c）），即，$\bar{y}_t=Uz_t+e_t$。我们注意到U包含很少基向量而$\ z_t\ $通常很密集。另一方面，$e_t$负责噪声或遮挡。我们动态模型所画的一些样本如图3所示。如果没有遮挡，最可能的图像块可以被PCA基向量有效的表示，而相应琐碎模版的系数（称为琐碎系数）趋于零（如图3（b）中的样本$y^1$）。另一方面，与真实目标位置不相关的候选块(patch)（如，未对准的样本）通常会导致密集的表示（如图3（b）的$y^2$、$y^3$样本）。如果发生了遮挡，最可能的图像块(patch)可以用PCA基向量和一些琐碎模版的线性组合来表示（如图3（c）$y^4$）。如图3（c）所示，对目标匹配最好的琐碎系数，$y^4$，比那些和真目标位置不相符的（$y^5$和$y^6$）更加稀疏。基于这些观测，我们注意到追踪目标的准确定位可以受益于琐碎系数稀疏度的惩罚。

对于每个预测状态的相应的观测，我们使用提出的算法（总结如表1）高效的解决如下等式
$$
L(z^i,e^i)=\min_{z^i,e^i}\frac{1}{2}\parallel\bar{y}^i-Uz^i-e^i\parallel^2_2+\lambda\parallel e^i\parallel_1\ \ \ \ \ \ \ (9)
$$
并算出$z^i$和$e^i$，i表示x状态的第i个样本（为了不失一般性，我们第t帧）。观测可能性可以通过每个观测图像块的重建误差来度量
$$
p(\bar{y}^i|x^i)=exp(-\parallel\bar{y}^i-Uz^i\parallel^2_2)\ \ \ \ \ \ \ \ \ \ \ \ (10)
$$
但是，Eq.10没有考虑遮挡。因此，我们使用mask来分离处非遮挡和遮挡部分
$$
p(\bar{y}^i|x^i)=exp[-(\parallel w^i\odot(\bar{y}^i-Uz^i)\parallel^2_2+\beta\sum(1-w^i))]\ \ \ \ (11)
$$
$w^i=[\omega^i_1,\omega^i_2,...,\omega^i_d]$为指示$e^i$中零元素的向量，$\odot$是Hadamard积，$\beta$为惩罚项（本研究中简单的设为$\lambda$）。如果$e^i$的第j个元素为0，则$\omega^i_j=1$,否则$\omega^i_j=0$。指数的第一部分负责目标未遮挡部分的重建误差，而第二项目标在于对任何像素标注遮挡的惩罚。第五节中的实验结果证明了我们公式的有效性。

##### C. Update of Observation Model

在视觉追踪中，更新用于解决目标外观改变的观测模型是最基本的。如果使用了一些不准确的样本来更新，则模型会下降从而因此追踪漂移。我们利用琐碎系数来进行遮挡检测因为响应的模版用于负责噪声。首先，每个琐碎系数向量对应于一个2D图（一个图像块（patch）反向光栅扫描的结果）。该图上的非零元素表示该像素被遮挡（称为遮挡图）。第二点，我们计算非零像素和遮挡图像素的比值$\eta$。我们使用两个阈值$tr_1$和$tr_2$来描述遮挡程度（如，本文中$tr_1=0.1$，$tr_2=0.6$）。第三点，基于遮挡比例$\eta$，我们应用三种操作中的一种：全，部分，以及不更新。如果$\eta<tr_1$，我们直接使用该样本更新模型。如果$tr_1\leq\eta\leq tr_2$,则表明目标被部分遮挡。则我们将遮挡像素替换为其相应部分的平均观测$\mu$，并使用该修复样本来更新。如果$\eta>tr_2$，表示目标大部分被遮挡，我们则抛弃该样本而不更新。图2（d）展示了三个更新场景的几个案例。在积累了足够的样本之后，我们使用增量主成分分析方法来更新我们的观测模型（即，PCA基向量和平均向量$\mu$）。

##### D. Discussion

注意到我们的跟踪器是鲁棒的，因为其可以使用所提出的观测模型以及更新方案来处理潜在的离群值问题（如，遮挡和不对准）。对于被追踪目标的准确位置，我们所提出的表示模型（Eq.9）和观测可能性（Eq.11）使得跟踪器可以解决明确的解决部分遮挡并促使其选择较好对准（well-aligned）的观测（如图3）。使用所提出观测模型的更新方案，我们的追踪器可以减少不准确样本所带来的问题（即，使用离群值更新模型）。

#### 5. Experiments

我们所提出的方法是用MATLAB实现的，在Pentium 2.0 GHz Dual Core 电脑上以每秒2帧的速度运行，使用3GB内存。对于每个序列，手工标注第一帧的目标位置。对于PCA表示，每个图像观测(observation)被归一化到32$\times$32像素，所有的实验中使用了16个特征向量。另外，我们使用1024个琐碎模版。在公式Eq.4中，$\ z\ $和$\ e\ $的纬度分别为16和1024。作为计算效率和有效性的权衡，我们使用了600个particles，并且每5帧增量更新我们的跟踪器。在所有实验中正则化常量$\lambda$设置为0.05。在本节中我们展示一些具有代表性的结果。所有的MATLAB源代码和数据集在我们的网站上（http://ice.dlut.edu.cn/lu/publications.html, http://faculty.ucmerced.edu/mhyang/pubs.html）。

在实验中我们使用了12个挑战性的图像序列。表I列出了所有被评估的图像序列，我们在实验中只使用了灰度信息。我们使用了提供ground truth的图像序列的相应信息（如，*Occlusion 1*,*Caviar 1*,*Caviar 2*）,而自己标注了其他视频。我们将我们的跟踪器与6个state-of-the-art算法进行评估，使用作者提供的源代码来进行公平比较，包括IVT，$\ell_1$，FragTrack，MILTrack，VTD以及PN。我们展示了定性和定量的结果，更多的结果可在在http://faculty.ucmerced.edu/mhyang/video/prototype1.avi中找到。

##### A. Qualitative Evaluation

**Heavy occlusion : **在*Occlusion 1*序列中，我们的算法，FragTrack以及$\ell_1$方法表现更好，如图4(a)所示，因为这些方法考虑了部分遮挡。FragTrack方法是通过使用直方图的基于部件表示来解决遮挡的。我们提出的和$\ell_1$跟踪器通过使用琐碎模版的稀疏表示来解决遮挡。在*Occlusion 2*序列中（图4(b)），我们的跟踪器表现的最好，特别是发生部分遮挡或面内旋转（in-plane rotation，如，#0150,#0500,#0700）时。在这些帧上，FragTrack方法表现糟糕因为它没有解决由于姿势和遮挡导致的外观改变。尽管MILTrack方法可以追踪到目标，它却因为设计原因不能估计面内旋转。我们注意到因为所采用的表示使用一般的Haar-like特征，所以通过简单的使用仿射运动模型来扩展该方法是不简单的。另一方面，$\ell_1$跟踪器在该序列上表现的不好。这是因为$\ell_1$跟踪器所使用的简单更新方法使用新图像观测来更新而没有分解出遮挡。

图4(c)-(d)展示了监控视频中不同算法的跟踪结果。该视频富有挑战性因为其包含尺度变换，部分遮挡以及相似目标。MILTrack方法在目标被某相似目标遮挡时表现的不好。由于MILTrack方法的目标表示中使用一般Haar-like特征，它们在相似目标互相遮挡时不太有效。$\ell_1$和IVT跟踪器在被相似目标遮挡时会偏离目标。相反的，我们的算法在位置和尺度上表现的很好即使目标被严重遮挡。

**Illumination change : **图5展示了4个具有严重光照改变，尺度改变以及姿势变化的图像序列的结果。在*Car 4*序列中，当机动车穿过天桥或树木时，会产生剧烈的光照改变。在*Car 11*视频中，目标对象很小，具有很低的对比度，并且光照改变剧烈。IVT和我们所提出的方法在追踪这些车辆时表现很好而其他方法在光照改变发生时（如，#0200）或场景中出现相似的目标（如，#0300）发生偏离。在*Singer 1*视频中，剧烈的光照改变以及制度变化使得其难一直跟踪。同样的，在*David Indoor*视频中，当人从黑暗的房间走到有聚光的地方时，会产生剧烈的外观改变。另外，由尺度，姿势以及摄像机运动造成的外观改变带来了巨大的挑战。我们注意到IVT和我们提出的方法比其他方法表现要好。这可以归功于目标外观改变可以由固定姿势的子空间很好的近似。我们也注意到一些跟踪器不能适应尺度（如，MILTrack）或面内旋转（如，MILTrack，PN以及FragTrack）。

**Fast motion : **图6展示了使用*Deer*和*Jumping*序列的跟踪结果。当目标突然运动时，很难预测它们的位置。另外，解决由于运动模糊导致的外观改变以及适当的更新这些外观模型更具挑战性。在*Deer*视频中，VTD和我们的跟踪器比其他算法表现的要好。在*Jumping*序列中，我们的跟踪器比其他的方法表现好而MILTrack和PN算法在一些帧中可以跟踪到目标。我们注意到PN算法具有重初始化（re-initialization）机制，这可以帮助目标追踪。由于在*Jumping*序列中重复的运动，一些跟踪器可能在失败后偶然的追踪到目标（如，$\ell_1$，MILTrack以及FragTrack方法，#0070，#0075）。类似的，在*Deer*视频中，一些跟踪器可能会由于摄像机面板而导致目标重出现在图像中的相同位置而被捕捉到（如VTD和PN方法，#0052，#0070）。

**Cluttered background : ** *Lemming*因为其中目标有尺寸和姿势的改变以及在杂乱背景下的严重遮挡所以对追踪来说富有挑战性。图7（a）展示了我们提出的方法和PN跟踪器比其他方法表现要好。值得注意的是我们的跟踪器可以适应尺度变化（如，#001，#0230，#0710以及#1336），面内旋转（如，#0230，#1000，#1060以及#1336）和遮挡（如#0330以及#0450）。*Cliffbar*剪辑中的目标（图7（b））经过了在杂乱背景下尺寸改变，面内旋转和突然的运动。另外，目标和周围的区域具有相似的纹理。$\ell_1$

和FragTrack方法变现很差因为周围背景与目标相似（图7（b）#0090）。IVT算法在突然运动发生时会失败（如#0328和#0329）。这些结果可以归于外观更新的问题。MILTrack和我们的方法都可以跟踪位置。但是，我们所提出的方法更好的适应了尺度改变（如#0001，#0090，#0280和#0471）和旋转（如#0001，#0140，#0155和#0471）。

**Discussion : **在第四节中，我们通过使用两个代表性的例子（图3(b)(c)）提出了一些为什么我们提出的方法可以有效的解决部分遮挡的理由。接着我们展示更多的结果来说明我们的算法如何解决其他挑战性因素。图8展示了3个在光照变化，姿势变化，背景杂乱以及运动模糊下的代表性跟踪结果。如图8（a）和（b）所示，最好的候选可以被PCA basis很好的表示因此误差项比那些未对准的候选要更稀疏。这可以归功于子空间表示的好处。如果被跟踪目标经过了光照变化以及轻微姿势改变，外观改变可以很好的被低维PCA子空间建模。因此，我们的跟踪器在目标经历光照改变和姿势改变时变现很好。另外，我们注意到被跟踪目标的准确位置可以通过对误差项的稀疏度惩罚获得。我们的跟踪器在目标出于杂乱背景（图8（b））或突然移动时可以准确的捕捉到目标。在图8（c）中，由于对准和未对准的候选未被很好的重建，为对准的误差项会更大而响应的表示也更密集。因此，我们的跟踪器可以区别出目标和其周围的背景。此外，我们注意到误差项促使外观更新更准确（使用对准的样本）。

##### B. Quantitative Evaluation

性能评估是一个重要的问题，需要健全的标准以公平的评价跟踪算法的优点。目标跟踪的量化评估一般涉及计算预测和ground truth中心位置的差距以及他们的平均值。表2总结了平均跟踪误差。我们的算法几乎在所有的序列中达到了最低的跟踪误差。另一方面，跟踪重叠率表明了每个算法的稳定性，由于其考虑了目标的大小和姿势。跟定每帧$R_T$的跟踪结果以及相应ground truth $R_G$,重叠率由PASCAL VOC标准定义，$score=\frac{area(R_T\cap R_G)}{area(R_T\cup R_G)}$。当score大于0.5时，则目标被成功追踪。图9展示了所有序列中每个跟踪算法的重叠率。表3展示了平均重叠率。总的来说，我们的跟踪器比其他算法表现要好。

尽管我们的工作与稀疏PCA不同（如第三节提到的），我们也在相同的Bayesian 框架下实现了一个基于SPCA的跟踪器。给定Gram矩阵G，SPCA方法目标在在于计算稀疏主成份，它只有有限数量的非零项同时捕获方差的最大值。
$$
\begin{align*}&\max u^TGu-\rho|u|^2\\&s.t.\ \parallel u\parallel_2=1\end{align*}
$$
$|u|$为u中非零项的数目，$\rho$控制$u$的稀疏程度。在我们的实验中，$\rho$根据经验设置为5，Gram矩阵G使用新的观测每五帧更新。表2和表3中我们展示了基于SPCA跟踪器的结果。结果表明我们使用Eq.11的算法那比基于SPCA的跟踪器表现要好，尤其对于一些挑战性的序列（如，*Occlusion 2*,*Singer 1*,*Deer*,*Lemming*）和监控视频（如*Caviar 1*和*Caviar 2*）来说。为了表达清晰，我们将我们的方法和基于SPCA的方法的跟踪结果放在http://faculty.ucmerced.edu/mhyang/video/prototype2.avi。我们注意到SPCA处理每帧大约需要5秒（使用d'Aspremont等提出的算法），因为解决Eq.12的优化问题是一个耗时的任务。

为了证明遮挡图是如何促进目标跟踪器和外观更新的，表2和表3中我们提供了只是用Eq.10没有遮挡图，以及Eq.11使用遮挡图的结果。结果表明我们的算法可以有效的估计遮挡图，因此进一步提高了跟踪结果，在重叠率和中心位置误差上。我们注意到遮挡掩码可以被提出的方法可靠的估计，无论目标是否被遮挡。图10展示了一些估计的遮挡图以及对模型更新的使用。

如果目标被很好的追踪并且遮挡率很小，跟踪结果就直接用来更新观测模型（图10(c)和(f)）。当被跟踪目标被部分遮挡（图10(a)以及(b)），遮挡图会反应该情况，遮挡率也因此更高。因此，部分更新使得跟踪器准确更新。当跟踪结果不准确时（图10(d)，(e)以及(i)），遮挡率也会相应更高。在这些情况下，执行部分更新来减少不准确更新的风险（特别是对于图10(d)和(i)，一些噪声区域，如蓝色圈内，以及背景被遮挡图分离出来在模型更新之前）。如果跟踪结果偏离目标则观测图像块就被丢弃不会进行更新。

##### C. Computational Complexity

#### 6. Conclusion

##### 本文提出了一个使用稀疏原型表示的鲁棒跟踪算法。在本研究中，我们明确的在外观更新和目标追踪中考虑部分遮挡和运动模糊，通过利用子空间模型的优点和稀疏表示。在挑战性图像序列上的实验证明了我们的追踪算法比一些state-of-the-art算法表现要好。由于我们的提出的算法设计解决模型中每个抽样的$\ell_1$最小化问题，我们计划使用更高效的算法利用于实时应用。我们将拓展我们的表示方法用于其他视觉问题包括目标识别，并使用提出的模型开发另一个在线正交子空间方法（如，在线NMF）。此外，我们计划集成多个视觉cues以在不同情景下更好的表述目标并利用在线学习的先验知识来更有效的跟踪目标。