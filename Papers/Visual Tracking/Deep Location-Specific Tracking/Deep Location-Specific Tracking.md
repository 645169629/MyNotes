### Deep Location-Specific Tracking

#### Abstract

最近几年，基于卷积神经网络的方法在视觉跟踪问题上获得了重大性能提升。由于在线目标存在许多不确定改变，如突然运动，背景杂乱以及较大形变，视觉跟踪依然是挑战性任务。我们提出一个新的算法，称为Deep Location-Specific Tracking，将跟踪问题分解为一个定位任务和一个分类任务，并为每个任务训练一个单独的网络。定位网络利用了当前帧的信息并提供一个具体的位置以提高成功跟踪的概率；分类网络在前一帧目标位置周围产生的样本以及定位网络在当前帧估计的样本中寻找目标。基于CNN的跟踪器通常有大量可训练的参数，导致了精度较低或跟踪漂移。我们通过学习一个基于1$\times$1卷积和全局平均池化的分类网络来解决该问题。在常用benchmark数据集上大量的实验结果表明我们提出的跟踪器在没有使用额外跟踪视频fine-tuning的情况下达到了不错的结果。

#### Introduction

视觉目标跟踪是多媒体理解以及计算机视觉中的一个核心问题。其在机器人、人机交互、视频分析等有大量应用。本文中，我们关注于单目标跟踪。单目标跟踪广受关注。一个典型的系统为在一个视频序列中跟踪任意目标，其中该目标在第一帧给出。尽管近些年来有着许多进展，它依然是一个挑战性任务，由于在线目标未知的改变，如形状改变，遮挡，快速运动以及姿势变换等。

![f1](images\f1.png)

视觉跟踪问题有许多方法被提出，如多示例学习，子空间学习，集成学习，压缩编码等。近些年，基于判别式相关滤波（DCF）的方法在准确度和速度上达到了不错的结果。近期，这些方法中使用的手工特征被替换为更强大的深度特征并获得了具有竞争力的跟踪结果。但是，大部分基于DCF的方法趋向于学习一个目标的刚性模板并在形状改变时表现不佳（见C-COT在“Singer2”上的结果，如图1）。最近，一些纯基于CNN的方法被提出并在公开benchmarks上达到了state-of-the-art的结果。

尽管达到了不错的性能，现存的CNN跟踪器依然有一些缺点。首先，为了预测当前帧的目标位置，大部分跟踪器搜索前一帧目标附近的位置，这在快速运动以及前一帧错误定位会倾向于漂移（见MDNet在“Biker”上的结果，如图1）。缓和该问题的一种方法是在更大的区域上采集更多样本并将其送入网络，但会导致跟踪速度很慢，因为CNN要在生成的样本上运行多次。第二，我们认为视觉跟踪的状态转换策略不是最优的，因为其没有利用当前帧的有用信息。第三，因为在线跟踪只能利用有限的数据，许多CNN跟踪器有大量的可训练参数，因此容易过拟合。为了提高跟踪准确度和鲁棒性，必须提供一个跟踪器来解决上述问题。

本文中，我们提出一个简单，灵活且有效的方法，*Deep Location-Specific Tracking(DLST)*，将单个跟踪任务分解为定位和分类，并为每个任务训练不同的网络。我们的结构与结合的方法大有不同，因为我们以不同的目的来训练网络：一个网络用于目标位置估计，另一个用于前背景分类。特别的，定位网络为一个在搜索区域（比目标尺寸大，并提供当前帧目标位置的猜想）上操作的小型网络。分类网络接收前一帧目标位置生成的样本以及当前帧估计的样本。另外，分类网络基于1$\times$1卷积以及全局平均池化来减少过拟合问题。最后，大量的实验结果表明我们提出的框架达到了与state-of-the-art具有竞争力的结果。

#### Related Works

跟踪社区近年来快速发展。对跟踪方法完整的回顾不在本文的范围，有兴趣的读者可以参考[26,38]。

近些年许多方法被提出[1,2,16,17,32,36,43,47,48]。子空间学习方法在一个低维空间上表示目标并在当时获得了不错的结果。Struck尝试最小化结构化输出目标来在线跟踪并达到了不错的结果。更近期的，基于DCF的方法在准确度和速度上展示了杰出的性能。最先由Bolme等提出的工作利用了DCF用于灰度图的自适应跟踪。许多拓展被提出来学习一个鲁棒检测器用于视觉跟踪。如，Henriques等集成了DCF和HOG特征并达到了很好的结果。一些现有的工作尝试从部分循环样本中学习并比DCF（只从循环移位中学习）获得了不错的性能提升。这些跟踪器的缺点之一是它们受限于手工特征，如HOG，图像颜色以及Haar-like特征等。

由于深度CNN在图像分类上的巨大成功，许多最近的工作寻求以深度CNN（在大型数据集上预训练的，如ImageNet）来表示目标。Danelljan等发现DCF跟踪器中，预训练CNN的浅层比深层表现更好，因为它们保留了更多空间信息。[30]中，Ma等在预训练CNN的不同层上训练了DCF并达到了很好的结果。Qi等扩展了Ma等的工作，提出了一个自适应权重方法来结合不同的跟踪器。最近，Danelljan等提出了利用隐式插值模型来使得滤波器在连续空间域上学习的方式。它们的方法使得多个特征的有效结合，包括CNNs不同层的特征、HOG、以及图像颜色等，并达到了state-of-the-art结果。但是大部分DCF跟踪器在目标形状改变或面外旋转时容易漂移。

基于纯CNN的方法也展示了不错的结果。在[27]中，Li等提出多个CNN流来学习目标的鲁棒表示。他们的CNN跟踪器在线从零训练，受到了缺少训练数据的影响。为了完全利用CNN的表示能力，Hong等 利用了预训练网络并提出一个结合生成式模型和判别式分类器的方法。其结果证明了使用预训练CNN的有效性。[44]中，Wang等在VGG模型的conv5-3和conv4-3之上分别附加了两个专门设计的网络。他们证明了他们的网络可以捕获补足的信息用于视觉跟踪。最近，Nam和Han提出了一个多域学习网络（MDNet）并达到了最好的结果。但是，他们的模型应用全连接层作为分类器，因此具有大量可训练参数。为了提高MDNet的性能，他们需要在一些列标注视频中学习这些层。本文中，我们提出具有更少可训练参数的结构并达到state-of-the-art性能。其可以直接应用于在线而不需要附加的跟踪视频训练，这大幅减少了人力标注。

#### Our Algorithm

我们的跟踪框架可以解耦成两个任务：**定位**和**分类**，如图2所示。首先在前一帧目标位置中心剪裁一个区域，并使用预训练的CNN提取剪裁区域的特征图。然后一个小型网络以滑窗的方式在特征图上运行并输出得分图，其中最高分表示目标位置。目标的边界框通过反射位置到未剪裁图像获取。这一步的目的在于提供另一个当前帧特定的猜想并提高跟踪器准确的检测目标的能力。这一阶段获取的位置是粗糙的因为CNN丢失了很多空间信息（因为卷积或池化层使用了非一致的步长）。这一步如图2所示。

![f2](images\f2.png)

给定前一帧的目标位置以及定位网络给出的当前帧特定位置，我们在这两个位置附近采集许多样本并将其送入分类网络寻找最好的一个作为跟踪结果。分类网络是一个3层的卷积神经网络，紧接着是全局平均池化以获得每个样本的得分。这一特殊的结构是受到[28]的启发，其中全局平均池化主要用来正则化。我们拓展了其想法用于了在线跟踪问题上，并证明了小型卷积神经网络很容易使用有限的标注数据训练。

##### 3.1 Localization

我们的跟踪器受到很多现有方法的启发[20,27,34,44]。我们首先简要的回顾这些跟踪器的模式。设$X_t$表示当前帧的许多候选状态。$S(X_t;\tilde{x}_{t-1})$表示一个状态转换模型，依靠前一帧的目标状态，其中$\tilde{x}$为跟踪器预测的位置或初始帧的ground truth。$S$的输出为目标$X_t=\{x,y,\delta\}^N_{i=1}$的采样样本，接着被送入决策模型以寻找最好的样本作为当前帧的目标位置，其中$[x,y],\delta ,N$分别表示中心边界框，目标的尺度以及采样数量。为了生成状态样本$X_t$，许多研究假设当前帧的目标状态服从正态分布$S_{norm}(X_t;\tilde{x}_{t-1})=\mathcal{N}(X_t;\tilde{x}_{t-1},\Sigma)$，其中$\ \Sigma\ $为一个对角协方差矩阵，表示当前帧采集样本位置的方差。正态分布对于前一帧目标位置中心附近具有更多权重。这些方法的哲学是物体在视频序列中区域平滑移动，并且前一个位置$\tilde{x}_{t-1}$为局部搜索提供了很强的提示。我们认为当1)目标移动迅速，2)前一帧预测结果出错时这一做法是有问题的。图3展示了突然运动。如我们所见，由$S_{norm}$生成的样本（图3(b)的红框）与ground truth十分遥远，使得之后跟踪失败。

![f3](images\f3.png)

为了解决上述问题，我们提出一个定位网络可以提供另一个特定的线索以提高跟踪准确度和鲁棒性。首先，我们在目标位置$\tilde{x}_{t-1}$周围剪裁一个大的搜索区域并以预训练的CNN特征表示剪裁的区域。第二步，一个小型卷积神经网络（图2）以滑窗的方式在特征图上运行并输出得分图，其中最大得分为当前帧的目标位置。最后，估计的位置$x^*_t$可以通过反射目标位置到原图像得到。注意到，定位网络只增加了一小部分计算开销，因为其只传递了一个单一图像块。因为我们的目标是提供一个目标的特定位置，为了简化，我们设定$x^*_t$的尺度和$\tilde{x}_{t-1}$一样。对于样本生成，我们不是使用单个估计位置$x^*_t$，而是将$S_{norm}$应用到两个中心：一个为$\tilde{x}_{t-1}$附近，另一个为$x^*_t$附近。这两个位置被用于采样，因为定位网络的输出不足以鲁棒跟踪。这是因为我们不能训练一个高级的网络来以在线有限的标注数据而准确的定位目标。4.2节中的实验证明了DLST在我们只将$Sorm$应用到估计位置时表现不好。我们提出的状态转换策略表示为$S_{comb}=\{S_{norm}(X_t;\tilde{x}_{t-1});S_{norm}(X_t;x^*_t)\}$。图3(c)展示了提出部分的有效性。可以看出$S_{comb}$可以提高样本覆盖ground truth的概率，相比于将$S_{norm}$应用于目标前一位置（图3(b)）。图3(d)也展示了采集样本数以及其与ground truth重叠率的关系。图中，更高的重叠率表示样本覆盖了目标更多的部分，反之亦然。在此，我们可以得出提出的$S_{comb}$比$S_{norm}$要好，因为1)一些$S_{comb}$生成的样本覆盖了目标更多的部分，2)在于$S_{norm}$相同的重叠率下，会有更多的样本覆盖了目标。

**Details of Localization Network.**搜索区域为目标尺寸的4倍，并resize到107$\times$107$\times$3，作为预训练VGG-M的输入。这里，我们采用VGG-M网络的低级特征（第一个ReLU层）因为其保留了更多空间信息。输出为一个51$\times$51$\times$96的特征图，接着被送入定位网络。我们的网络结构为两个1$\times$1巻积层，紧接着一个损失层。第一个巻积层卷积核通道为96并输出256个特征图，接着一个非线性ReLU单元以及一个dropout层。这一层的主要目的为使预训练VGG-M特征适应特定的视频，由于同类的目标在不同的序列中可以被当作目标或背景。第二层卷积核通道为256并输出剪裁区域的热图。为了训练网络，我们采用softmax 损失并定义特征图上的标注为：
$$
y_i=\left\{\begin{array}{ll}

2&\text{if $\parallel c_t-\tilde{c_t}\parallel\leq R$},\\

1&\text{otherwise}.

\end{array}\right.\ \ \ \ \ \ \ \ \ \ \ \ (1)
$$
其中$c_t$为目标边界框当前帧在特征图上的中心。等式(1)表示目标特征图上中心半径R内的样本为正样本。R由用户设置并在所有视频中固定。我们也通过正样本和负样本来衡量损失以消除类别不平衡为题。

##### 3.2 Classification

给定一系列$S_{comb}$生成的样本，我们算法的下一步就是通过分类网络找出目标。通常来说，分类网络运行在每个样本的特征图$F$上并产生一个得分。一个典型的分类方法要么使用传统决策模型如SVM，要么采用深度分类器如多层感知机。它们都是首先向量化特征$F$，接着将其送入到一个或多个全连接层，紧接着一个SVM或softmax logistic回归层。最近提出的MDNet结构证明了convention MLP可以被用作在线分类器并达到了state-of-the-art的跟踪结果。

但是，由于有大量可训练参数，全连接层很容易对视觉跟踪过拟合。图4展示了这种分类器过拟合的问题。MDNet-NH与MDNet结构相同。MDNet-NH有两点不同：1）没有在额外标注视频上fine-tuning;2)使用更大的学习率在没有额外学习时比原始设定表现要好。图4中可以看出MDNet-NH趋于跟踪一些特定区域，如“Singer2”视频中的右上角，以及“Shaking”序列中的"gitar"。详细的量化比较在第四节给出。

![f4](images\f4.png)

为了解决该问题一个可能的方法是在许多标注视频如OTB,VOT上训练这些层（见图4，MDNet绿色框结果）。本文的目的在于减轻过拟合的问题而不使用任何额外的视频，减少了大量人力标注。我们特别设计的跟踪器包含3个1$\times$1巻积层并输出一个得分图与$F$大小相同。全局平均池化已被采用，其输出直接被送入softmax层以产生最终每个样本的预测结果。图4展示了我们的跟踪器具有更少的训练参数，并可以成功跟踪目标，及时没有额外的预训练。注意到，在这一比较中，我们没有利用提出的定位阶段。因此，增益仅是由于我们特殊设计的结构。

**Details of Classification Network.**采样的样本被resize到107$\times$107$\times$3像素。本文中，预训练VGG-M模型的$relu_3$层被作为特征提取器，因为它比低层捕获更多语义部分或类别信息。对于每个样本，输出的3$\times$3$\times$512维特征图接着被送入到我们的分类网络用于最终预测。我们特殊设计的分类网络包含三个1$\times$1巻积层。前两个巻积层分别有512和128个卷积核。最后一个巻积层为目标和背景产生两个输出。对于网络学习，我们使用softmax logistic 回归。当前帧的目标状态由寻找最大正得分的样本给出，$\tilde{x_t}=argmax_{x_l\in X_t}f^+(x_i)$，其中$f^+$为分类网络输出的正得分。

##### 3.3 Online Tracking and Update

**Online Tracking.**我们算法的步骤如图2.对于每一帧，我们首先采用定位网络提供一个特定位置并使用$S_{comb}$来生成样本。接着分类网络中具有最大输出的样本被选作当前帧的目标状态$\tilde{x}$。使用两个网络的一些实际考虑事项见3.1和3.2节。

**Model Updates.**我们使用相同的策略来更新两个网络。具体的，我们采用短期和长期策略分别对于跟踪器的鲁棒性和适应性。长期更新使用$\tau_{long}$时间段内收集的正样本而短期更新在分类网络输出低于某个阈值（本文使用0.5）时执行。短期学习的正样本在$\tau_{short}$内收集。所有的负样本在$\tau_{short}$期间收集。注意到，我们在定位和分类阶段固定了特征提取器网络。

**Bounding Box Regression & Hard Negative Minning.**这两个策略在目标检测问题中经常使用。最近，Nam and Han证明了边界框回归和难负挖掘可以大幅提高跟踪准确度和鲁棒性。本文中，我们采用相同的方式。特别的，边界框回归器只使用第一帧采集的样本并应用在之后的每一帧，如果预测目标比给定阈值低（$f^+<$0.5）。对于分类网络，难负样本基于最高的正得分来选择以提高区分性。注意到，我们在定位网络不使用这些策略。