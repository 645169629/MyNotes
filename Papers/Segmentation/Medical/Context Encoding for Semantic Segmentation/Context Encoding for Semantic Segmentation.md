## Context Encoding for Semantic Segmentation

> CVPR 2018

### Abstract

​	最近的研究通过使用Dilated/Atrous（空洞） 卷积，利用多尺度特征以及精修边界，在提升FCN框架下逐像素标注的空间分辨率方面取得重大的进展。本文中，我们为利用语义分割中全局上下文信息的影响，引入上下文编码模块（Context Encoding Module），该模块捕获场景的语义上下文并有选择的高亮类别相关的特征图。提出的上下文编码模块大大提升了语义分割结果，同时相对于FCN只增加了很少的计算量。我们的方法达到了新的state-of-the-art结果，PASCAL-Context上mIoU为51.7%，PASCAL VOC 2012 上mIoU为85.9%。我们的单个模型在ADE20K测试集上达到了0.5567的得分，超过了COCO-Place 2017挑战的获胜结果。此外，我们也探索了上下文编码模块是如何提高浅层网络（CIFAR-10数据集上的图像分割网络）的特征表示。我们14层的网络错误率达到了3.45%，这与比其层数多10倍的网络的结果差不多。

### Introduction

​	语义分割对于给定图像的每像素预测目标类别，这提供了全面的场景描述，包括目标类别信息，位置信息以及形状信息。State-of-the-art语义分割方法通常是基于全卷积网络（FCN）框架。CNNs的适应得益于从多个图像集中学得的目标类别以及场景语义信息。CNNs通过堆叠巻积层，非线性单元以及降采样，可以以全局感受野捕获表示信息。为了克服空间分辨率随降采样损失的问题，最近的研究使用Dilated/Atrous卷积策略来从预训练网络中产生密集预测。但是，该策略还是孤立了像素与全局场景上下文，