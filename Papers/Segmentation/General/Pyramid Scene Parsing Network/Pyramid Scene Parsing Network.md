## Pyramid Scene Parsing Network

> CVPR 2017

### Abstract

本文提出金字塔场景解析网络（pyramid scene parsing network, PSPNet），其中的金字塔池化模块通过基于不同区域的上下文集成来利用全局信息的能力。我们的全局先验表示对于提升场景解析任务的性能很有效，PSPNet提供了一个优秀的框架用于像素级预测。

### 1. Introduction

​	场景解析基于语义分割，是计算机视觉的基础问题之一。我们发现基于FCN的模型的主要问题是缺少合适的策略运用全局场景类别线索。对于复杂的场景理解，首先获得全局的图像级特征，空间金字塔池化被广泛使用，其中的空间统计信息提供了对整个场景的描述。空间金字塔池化网络进一步增强了该能力。

​	与这些方法不同的是，为了包括合适的全局特征，我们提出了pyramid scene parsing network。除了传统的空洞FCN用于像素预测，我们拓展了像素级特征为特别设计的全局金字塔池化特征。局部和全局的信息使得最终的预测更可靠。我们也提出了一种深度监督损失的优化方法。

​	我们的主要贡献有三点：

​	1）我们提出了金字塔场景解析网络，将困难的场景上下文特征集成到基于FCN的框架中。

​	2）我们基于深度监督损失提出了一种对于深度ResNet有效的优化策略。

​	3）我们构建了一个实际的系统，在场景解析和语义分割中达到state-of-the-art。

### 3. Pyramid Scene Parsing Network

#### 3.1 Important Observations

![f2](images\f2.png)

总结FCN方法的结果如下：

**1. Mismatched Relationship** 上下文关系对于复杂场景理解很重要。有共同出现的视觉模式。如，飞机更可能在跑道或空中，而不是在道路上。如图2第一行，FCN基于外观，将船预测为车，但是常识是车不会在河中。缺乏收集上下文信息的能力会导致误分类。

**2. Confusion Categories** 在ADE20K数据集中有很多类别标签对在分类时容易混淆。如field和earth；mountain和hill；wall，house，building和skyscraper。他们具有相似的外观。专家标注者也有17.6%的像素误差。在图2的第二行，FCN将框中的物体预测为一部分skyscraper和一部分building。这种结果可以利用类别之间的关系来解决。

**3. Inconspicuous Classes** 一些尺寸小的东西，如路灯，信号板，很难找到但却比较重要。反之，大的物体可能会超出FCN的感知野，从而导致不连续的预测。如图2第三行，枕头和床单有相似的外观。过渡的关注全局场景类别可能会找不到枕头。为了提高对小/大目标的解析，我们应该更关注不同的子区域。

总结以上观察，许多误差部分或完全关于不同感受野的上下文关系和全局信息。因此具有合适的全局-场景级先验可以提高深度网络的性能。

#### 3.2 Pyramid Pooling Module

​	在深度神经网络中，感受野大小可以大致表明我们用了多少上下文信息。尽管理论上ResNet的感受野已经大于输入图像，Zhou等表明经验上CNN的感受野比理论的要小很多，特别是在高层。这使得许多网络不足以包含全局场景先验。

​	ADE20K中的图像标记了许多物体，直接将他们融合为一个向量可能会丢失空间关系（Global average pooling的做法）。带有子区域上下文的全局上下文信息可以识别多个类别。可以从不同的子区域融合信息。为了进一步减少不同区域之间上下文信息的损失，我们提出了一个层级全局先验，包含了不同尺度，在不同子区域下的信息。我们称之为*pyramid pooling module*。如图3c。

​	金字塔池化模块融合了四个金字塔尺度的特征。最粗级（红色）的为全局池化生成单一bin输出。下一层将特征图分为不同子区域，在不同位置形成池化表示。金字塔池化模块中不同层的输出包含了不同大小的特征图。为了保持全局特征的权重，我们在每个金字塔层后使用1x1卷积，将上下文表示减少到1/N维。然后使用双线性插值，把低维特征图上采样到原特征图大小。最后，concat 不同层的特征。我们的金字塔池化有四层，bin尺寸分别为1x1，2x2，3x3，6x6。

​	前面提取特征的网络为ResNet（使用dialted策略），特征图为原图的1/8。

#### 3.3 Network Architecture

![f3](images\f3.png)

### 4. Deep Supervision for ResNet-Based FCN

​	我们提出通过监督一个附加损失生成初始化结果，然后学习与最终损失的残差。

![f4](images\f4.png)

