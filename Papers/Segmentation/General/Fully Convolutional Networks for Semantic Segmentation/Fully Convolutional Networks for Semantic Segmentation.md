## Fully Convolutional Networks for Semantic Segmentation

> CVPR 2015

### Abstract

​	卷积神经网络是强大的视觉模型，可以产生层级的特征。我们展示了卷积神经网络自身，端到端，像素到像素训练，在语义分割中产生state-of-the-art性能。我们的主要思想是构建“全卷积”网络，通过有效的推理和学习，可以接受任意尺寸输入并产生对应尺寸的输出。我们定义并详细介绍全卷积网络的空间，解释它们在密集空间预测任务上的应用，并与先前的模型向关联。我们在全卷积网络中应用了当代的分类网络（AlexNet, VGG net, GoogLeNet），并通过fine-tuning将它们学到的表示迁移到分割任务中。我们接着定义了一个跳跃结构，结合深，粗糙层的语义信息以及浅，精细层的外观信息，以产生准确，精细的分割。我们的全卷积网络在PASCAL VOC，NYUDv2和SIFT Flow上达到了state-of-the-art分割结果，推理时间每幅图少于0.2s。

### 1. Introduction

​	卷积神经网络正推动着识别的发展。它不仅提高了整幅图像的分类[22,34,35]，还在结构化输出的局部任务中取得进展。这些包括边界框目标检测[32,12,19]，部分及关键点预测[42,26]，局部对应（local correspondence）[26,10]。

​	从粗到细的处理下一步很自然就是对每个像素预测。之前的方法使用卷积神经网络来做语义分割[30,3,9,31,17,15,11]，每个像素被标记为其包围物体或区域的类别，本文解决了它们的一些缺点。

![f1](images\f1.png)

​	我们展示了全卷积网络（FCN），端到端，像素到像素训练可以在语义分割中产生state-of-the-art结果。据我们所知，本文工作是第一个端到端训练FCNs，（1）用于逐像素预测；（2）运用了监督预训练。现有网络全卷积版本可以预测密集输出，输入为任意尺寸。学习和推理都以一次一张图的方式执行，通过密集前传以及反向传播。网络中的上采样层使用子样本（subsampled）池化来进行逐像素预测和学习。

​	本方法是有效的，渐进的和绝对的，排除了其他工作中的复杂项。逐块（patch）训练很常见[30,3,9,31,11]，但不如全卷积训练高效。我们的方法没有使用前处理和后处理，包括超像素[9,17]，提案[17,15]，或随机场，局部分类器的后增强[22,34, 35]。我们的模型通过将分类网络改为全卷积网络并fine-tuning它们学到的表示，迁移了分类[22,34,35]中的成功来进行密集预测。

​	语义分割在语义和位置之间存在固有的矛盾：`全局信息决定了what，而局部信息决定了where`。深度特征层级在一个非线性局部到全局金字塔中编码了位置和语义。我们定义了一个跳跃框架来利用结合深度，粗糙，语义信息以及浅层，精细，外观信息特征谱的优点（见图3）。

![f3](images\f3.png)

​	在下一节中，我们回归相关分类网络，FCNs的工作以及最近使用卷积网络的语义分割方法。后面的几节解释了FCN设计和密集预测的权衡，介绍我们网络中上采样和多层结合的结构，并描述我们的实验框架。最后我们在PASCAL VOC 2011-2，NYUDv2以及SIFT Flow上获得了state-of-art结果。

### 2. Related work

​	我们的方法利用了最近用于图像分类网络和迁移学习的成功。迁移首先在多个视觉识别任务上得到了证明，接着在检测以及实例、语义分割上，使用提案-分类模型得到了证明。我们现在重构，fine-tune分类网络到直接，密集的语义分割预测。我们绘制了FCNs的空间，并加入了之前和现在的模型。

**Fully convolutional networks**		最早将卷积网络拓展到任意尺寸输入的思想出现在Matan等，他们将经典的LeNet拓展来识别数字中的线条。因为他们的网络受限于一维输入线条，Matan等使用Viterbi解码来获得输出。Wolf and Platt将卷积网络输出拓展到2维检测邮政地址块四角的得分图。这些工作都是用全卷积网络来做检测。Ning等定义了一个卷积网络来对C.elegans 组织进行多类分割，使用全卷积推理。

​	在现在的多层网络中也利用了全卷积计算。Sermanet等的滑窗检测，Pinheiro and Collobert等的语义分割，以及Eigen等的图像恢复，都是用了全卷积推理。全卷积训练很少，但被Tompson等有效的利用来训练一个端到端的部分检测器以及空间模型用于姿势估计，但是他们没有对该方法进行推理和分析。

​	另外，He等舍弃了分类网络的非卷积部分，做了一个特征提取器。他们结合了提案和空间金字塔池化来产生局部的，固定长度的特征用于分类。虽然快速高效，但该模型不能端到端训练。

**Dense prediction with convnets**		近期的一些工作在密集预测问题上应用了卷积网络，包括Ning等，Farabet等，Pinheiro and Collobert的语义分割；Ciresan等的显微镜边界预测以及Ganin and Lempitsky等的混合卷积网络/最邻近模型用于自然图像；Eigen等的图像恢复和深度估计。这些方法共同点包括：

- 小模型限制了容量和感受野；

- 逐块训练；

- 超像素映射，随机场正则化，过滤或局部分类的后处理；

- 输入变换和输出交错用于密集输出；

- 多尺度金字塔处理；

- 饱和的tanh非线性；

- 集成

然而我们的方法没有这些机制。但是，我们从FCNs的观点研究了逐块训练和“移位-拼接”密集输出。我们也讨论了网络中的上采样，其中Eigen等的全连接预测为特殊情况。

​	不像现有的方法，我们采用并拓展了深度分类结构，使用图像分类预训练，并fine-tune全卷积，来从整幅图像输入和整幅图像ground truth简单有效的学习。

​	Hariharan等和Gupta等同样采用了深度分类网络来语义分割，但是使用了混合提案-分类器模型。这些方法fine-tune R-CNN系统，通过采样bounding boxes或区域提案来做检测，语义分割和实例分割。这些方法都不是端到端的。他们分别在PASCAL VOC 和 NYUDv2上达到了state-of-the-art，所以我们直接将我们单独的，端到端的FCN来和他们的语义分割结果来比较。

​	我们融合了不同层的特征以定义一个非线性的局部到全局的表示，并端到端调整。当代Hariharan等的工作也在他们的混合模型中应用了多层。

### 3. Fully convolutional networks

​	卷积网络每层的数据都是3维数组，$\ h\times w\times d\ $，其中$\ h\ $和$\ w\ $为空间维度，$\ d \ $为特征或通道维度。第一层为图像，像素尺寸$\ h\times w\ $，$\ d\ $个颜色通道。高层的位置对应于图像中它们连接路径中的位置，称为感知野。

​	Convnets建立在平移不变性上。它们基本的组件（卷积，池化，激活函数）在局部输入区域上操作，只依赖于相对的空间坐标。记$\ \mathbb{x}_{ij}\ $为某一层位置$\ (i,j)\ $的数据向量，$\ \mathbb{y}_{ij}\ $为后一层输出：
$$
\mathbb{y}_{ij}=f_{ks}(\{\mathbb{x}_{si+\delta_i,s_j+\delta_j}\}0\le\delta_i,\delta_j\le k)
$$
其中$\ k\ $称为核尺寸，$\ s\ $为步长或子采样因子，$\ f_{ks}\ $决定了层的类型：卷积或平均池化则为矩阵相乘，最大化池化则为空间最大，激活函数则为逐项非线性等等。

​	这一函数形式是在组合下维持的，核尺寸和步长遵从变换规则：
$$
f_{ks}\circ g_{k's'}=(f\circ g)_{k'+(k-1)s',ss'}
$$
通常的深度网络计算通常的非线性函数，具有这种形式的网络计算非线性过滤器，称为深度过滤器或全卷积网络。FCN通常操作任意尺寸输入，并产生对应空间维度的输出。

​	实数损失函数结合FCN定义了一个任务。如果损失函数是为最后一层空间维度的和，$\ \ell(\mathbb{x};\theta)=\sum_{ij}\ell '(\mathbb{x}_{ij};\theta)\ $，其梯度为每个空间组件的梯度和。因此在整幅图像上随机梯度下降计算的$\ \ell\ $和$\ \ell'\ $一样，将最后一层的感受野作为一个minibatch。

​	当这些感受野严重重叠时，在整幅图像一层一层的计算前传和反向传播比一块一块的计算更高效。

​	我们接着解释如何将分类网络转换为全卷积网络以产生粗略的输出图。对于逐像素预测，我们需要将这些粗略输出连接回像素。3.2节描述了一个trick，快速扫描，用于该目的。我们将其重译为一个等效的网络修改。作为有效的代替，我们在3.3节中介绍反卷积层用于上采样。3.4节中我们考虑逐块采样训练，并在4.3中给出证据，我们的整幅图训练更快，并且有效。

#### 3.1 Adapting classifiers for dense prediction

​	典型的识别网络，包括LeNet，AlexNet，及其更深的继承，表面上接收固定尺寸的输出并产生非空间输出。这些网络的全连接层具有固定维度并丢弃了空间坐标。但是，这些全连接层可以看作是卷积操作，卷积核覆盖了整个输入区域。这样做将他们转换为全卷积网络，接收任意尺寸输入，输出分类图。该变换如图2所示。

![f2](images\f2.png)

​	而且，虽然结果图与原始网络逐块评估一样，但块之间重叠的区域计算平摊了。如，AlexNet推断一张227x227的图像分类得分需要1.2ms，全卷积网络花费22ms来产生500x500图像的10x10网格输出，这比原始的方法快5倍。

​	这些卷积化的方法的空间输出图使得他们很自然应用于密集问题，如语义分割。ground truth在每个输出单元可用，前传和反向传播都很简单，都利用了卷积计算的计算效率。AlexNet样本对应的回传时间为一张图2.4ms，而全卷积10x10输出图为37ms，与前传有相似的加速。

​	虽然我们对分类网络改造为全卷积，对任意输出尺寸产生输出图，输出维度通常由二次采样来降低。分类网络二次采样以使得过滤器很小并且计算开销合理。这使得全卷积版本的网络输出变粗糙，使其从输入的尺寸降低一个因子，该因子等于输出单元感受野的步长。

#### 3.2 Shift-and-stitch is filter rarefaction

​	密集预测可以通过拼接不同移位版本输入的输出结果来获得。如果输出由因子$\ f\ $降采样，移动输入$\ x\ $像素到右边，$\ y\ $像素到下边，对每个$\ (x,y)\ s.t.\ 0\le x, y<f\ $。处理$\ f^2\ $个输入，并交错输出，使得预测对应于它们感受野的中心像素。

​	尽管执行该变换增加了开销$\ f^2\ $，有一个有效的trick来产生等同的结果，称为$\ \grave{a}\ trous\ $算法。考虑一个层（卷积或池化）输出步长$\ s\ $，后面的巻积层过滤器权值为$\ f_{ij}\ $。设低层的输入步长为1，以因子$\ s\ $上采样其输出。但是，将原始的过滤器和上采样输出做卷积并不能得到转移-拼接相同的结果，因为原始的过滤器只看到了输入的一小部分。为了实现trick，扩大过滤器来使其稀疏：
$$
f'_{ij}=\left\{
\begin{array}{rcl}
&f_{i/s,j/s}       &      & {if\ s\ divides\ both\ i\ and\ j;}\\
&0     &      & {otherwise}\\
\end{array} \right.
$$
(i和j从零开始)。重现全网络trick输出需要一层一层重复该过滤器扩大，知道移除了二次采样。（在实践中，这可以通过处理上采样输出的二次采样版本来进行。）

​	在网络中降低二次采样是一种权衡：过滤器看见更精细的信息，但感受野较小，计算时间更长。转换-拼接trick是另一种权衡：没有降低过滤器的感受野，输出更密集，但过滤器不能获得更精细尺度的信息。

​	尽管我们对该trick进行了初步的实验，我们在模型中并没有使用它。我们发现通过上采样学习，更有效，特别是结合了跳跃层融合时。

#### 3.3 Upsampling is backwards strided convolution

​	另一种连接粗输出到密集像素的方法是插值。例如，简单的双线性插值计算每个输出$\ y_{ij}\ $从其最邻近的四个输入，通过线性映射，只依赖于输入和输出单元的相对位置。

​	在某种意义上，以因子$\ f\ $的上采样就是输入步长为$\ 1/f\ $的卷积。只要$\ f\ $是可积分的，上采样一种自然的方法就是向后卷积（反卷积），输出步长为$\ f\ $。这种操作很好实现。因此上采样通过逐像素loss的反向传播来端到端学习。

​	反卷积过滤器不需要固定，但可以被学习。一些范巻积层和激活函数可以学到非线性上采样。

在我们的实验中，我们发现网络中的上采样可以快速有效的学习密集预测。我们最好的分割结构使用了这些层来学得精修的预测。

#### 3.4 Patchwise training is loss sampling

​	在随机优化中，梯度计算是由训练分布驱动的。逐块训练和全卷积训练都可以产生任意分布，尽管他们的相对计算效率取决于重叠和minibatch大小。全图的全卷积训练等同于逐块训练，每个batch包含一幅图损失下全部单元的感受野。虽然它比块均匀采样更有效，但减少了可能的batch数量。但是，图像中块的随机选择可以简单的重现。限制loss到一个其空间项（或，等价的应用一个DropConnect mask 在输出和loss之间）随机采样的子集，可以将块排除在梯度计算中。

​	如果保留的块依然有严重的重叠，全卷积计算依然会加速训练。如果梯度在多次回传中累计，batch可以包括多个图像的多个块。

​	逐块训练中的采样可以修正类别不平衡并减少密集块的空间相关性。在全卷积训练中，类别不平衡可以通过加权损失来达到，算是采样可以用来解决空间相关性。

​	我们利用了带采样的训练，并没有发现其对于密集预测产生更快或更好的收敛性。整幅图的训练很有效。

### 4. Segmentation Architecture

​	我们将ILSVRC分类器转换为FCNs，并增加了上采样以及逐像素loss，使其可以密集预测。我们通过fine-tuning来训练。接着，我们增加了层之间的跳跃以融合粗，语义的和局部，外观的信息。这一跳跃结构端到端训练来精修输出的语义和空间预测。

​	我们在PASCAL VOC 2011分割挑战上训练并验证。我们训练使用了一个每像素多项式logistic loss，验证使用标准的平均像素IoU度量（平均所有类别，包括背景）。训练忽略了ground truth掩盖的像素。

#### 4.1 From classifier to dense FCN

​	我们首先将验证过的分类结构卷积化。我们考虑了AlexNet，VGG16 net，以及GoogleNet。对于GoogleNet，我们只是用了最后损失层，并舍弃最后平均池化层以提高性能。我们去掉了所有网络最后的分类层，将全连接层转换为巻积层。我们附加一个1x1巻积层，通道数为21，在每个粗输出位置，接一个反巻积层，进行双线性上采样将粗输出转换为像素密集的输出，以此来预测每个PASCAL 类别（包括类别）的得分。表1比较了初步验证结果。我们报告了最好的结果，以固定学习率收敛后（最少175个epoch）。

![t1](images\t1.png)

​	每个网络fine-tune后都得到了可靠的分割预测。最差的模型也达到了state-of-the-art性能的75%。FCN-VGG16已经达到了state-of-the-art性能（val上56.0 mean IU，test上52.6）。在额外的数据上训练将FCN-VGG16提升到了59.4，FCN-AlexNet到48.0。尽管GoogleNet和VGG16有相似的分类准确度，但是我们实现的GoogLetNet没有达到VGG16的分割结果。

#### 4.2 Combining what and where

​	我们定义了一个新的全卷积网络（FCN），结合了层及特征并精修了输出的空间准确度。见图3。

​	全卷积分类器可以fine-tune到分割，尽管在标准度量两种得分很高，他们的输出还是不满意（见图4）。最后预测层的32步长限制了上采样输出细节的尺度。

![f4](images\f4.png)

​	我们通过增加连接最后预测层和低层的跳跃来解决该问题。这将线拓扑为一个DAG，它的边从较低层跳到了较高层（图3）。因为它们看见较少的像素，更精细的预测尺度应该需要较少的层。结合精细层及粗略层使得模型做出符合全局结构的局部预测。通过类比Koenderick and van Doorn等的jet，我们称我们的非线性特征层级为deep jet。

​	我们首先通过预测一个16像素步长的层，将输出步长分为一半。我们在pool4上加了一个1x1巻积层，以产生额外的类别预测。我们将该输出与conv7计算的预测，通过增加2x上采样层并叠加两个预测相融合。我们初始化2x上采样为双线性插值，但是运行参数被学习。最后，步长16的预测被上采样回原图。我们称该网络为FCN-16s。FCN-16s端到端训练，以上一个，更粗的网络FCN-32s的参数初始化。pool4层 上的新参数以0初始化，以使网络从未修改的预测开始。学习率以100为因子下降。

​	我们接着以这种方式，融合pool3的预测和pool4及conv7融合的2x上采样的预测，构建网络FCN-8s。我们获得了较小的提升，到62.7 mean IU，并在平滑度及输出细节上有所提升。在这里，我们的融合提升已经降低了，无论是在IU度量上海市可见性方面，如图4，所以我们没有继续融合更低层。

**Refinement by other means**	减少池化层的步长是最直接获得更精细预测的方法。但是，这样做对于我们基于VGG-16的网络是有问题的。设置pool5步长为1，需要我们卷积化的fc6，kernel尺寸为14x14，以保持其感受野尺寸。除了其计算开销外，学习如此大的过滤器也是有困难的。我们尝试使用更小的过滤器重新构建pool5之上的层，并没有达到类似的性能；一个可能的解释是ILSVRC对上层的初始化是重要的。

​	另一种方法来获得精细预测是使用转移-拼接trick。在有限的实验中，我们发现提升的比例不如层间融合。

#### 4.3 Experimental framework

**Optimization**	我们以SGD，momentum训练。minibatch尺寸为20张图，FCN-AlexNet，FCN-VGG16及FCN-GoogleNet的学习率分别为$\ 10^{-3}\ $，$\ 10^{-4}\ $和$\ 10^{-5}\ $。momentum为0.9，weight decay为$\ 5^{-4}\ $或$\ 2^{-4}\ $，对于biases的学习率为两倍。类别得分层0初始化，Dropout包括在之前分类网络使用的地方。

**Fine-tuning**	我们通过反向传播fine-tune整个网络。只fine-tune输出分类器产生全部fine-tune性能的70%，如表2。从0开始训练是不太可能的（注意VGG是以阶段训练的，我们从全VGG16版本开始）。FCN-32s版本Fine-tune在单个GPU上花了3天，在花一天升级到FCN-16s和FCN-8s。

![t2](images\t2.png)

**More Training Data**	PASCAL VOC 2011分割训练集标注了1112张图。Hariharan等收集了8498张PASCAL训练图像。该训练数据提高了VGG16验证的分3.4个百分点，到59.4 mean IU。

**Patch Sampling**	如3.4节中介绍的，我们的完整图像训练有效地将每个图像批量地放入一个大型的、重叠的块中。 相比之下，之前的工作在整个数据集上随机采集样本块，可能会得到高方差的batch，使得收敛加速。我们研究了这种权衡，以一定的概率$\ 1-p\ $做出独立选择忽略最后层单元，通过这种方式对loss空间采样。为了避免修改有效的batch size，我们同时增加每batch图像的数量$\ 1/p\ $。注意到由于卷积的有效性，这种形式的抑制采样依然比逐块训练要快，对于足够大的$\ p\ $值来说（如，最少$\ p>0.2\ $，根据3.1节中的数字）。图5展示了这种形式采样在收敛性上的影响。我们发现采样对于收敛率没有重大的影响，相比于整幅图训练，但需要花费更多时间，由于每个batch需要考虑大量的图像。因此我们选择了不采样，整幅图训练在我们的实验中。

![f5](images\f5.png)

**Class Balancing**	全卷积训练可以通过加权或对loss采样来平衡类别。尽管我们的标注轻微的不平衡（大约3/4为背景），我们发现类别平衡不是必须的。

**Dense Prediction**	得分通过反卷积层被上采样到输入维度。最后一层反卷积filters固定为双线性插值，而中间的上采样层被初始化为双线性上采样，接着学习。

**Augmentation**	我们尝试通过随机镜像以及“jittering”图像来增强训练数据。并没有产生显著的提升。

**Implementation**	所有的模型使用Caffe，在NVIDIA Tesla K40c上。

### 5. Results

​	我们测试了FCN在语义分割以及场景解析上，利用了PASCAL VOC ,NYUDv2以及SIFT Flow。尽管这些任务之前被区分为目标还是区域，我们统一为像素预测。我们在每个数据集上评估了我们FCN跳跃结构，瓶拓展多模态输入用于NYUDv2和SIFT Flow的语义和几何多任务预测。

**Metrics**	我们报告了四个常用语义分割和场景解析的度量，包括像素的准确度变化及区域IoU。设$n_{ij}$为类别$\ i\ $被预测为类别$\ j\ $的像素数量，其中有$\ n_{cl}\ $个不同的类别，设$\ t_i=\sum_jn_{ij}\ $为类别$\ i\ $的全部像素数。我们计算：

- 像素准确度：$\ \sum_in_{ii}/\sum_it_i\ $

- 平均准确度：$(1/n_{cl})\sum_in_{ii}/t_{i}$

- 平均IU：$(1/n_{cl})\sum_in_{ii}/(t_i+\sum_jn_{ji}-n_{ii})$

- 频率加权IU：$\ (\sum_kt_k)^{-1}\sum_it_in_{ii}/(t_i+\sum_jn_{ji}-n_{ii})\ $

**PASCAL VOC** 表3给出了FCN-8s在PASCAL VOC 2011和2012测试集上的结果，并于之前的state-of-the-art SDS，以及R-CNN相比较。我们在mean IU上达到了最好的结果，相对提升20%。推理时间降低了114x或286x。

![t3](images\t3.png)

**NYUDv2**是一个RGB-D数据集，由Microsoft Kinect收集。共有1449张RGB-D图像，逐像素的标注已经被Gupta等合并到了40个语义分割类别中。我们报告了标准分配，795张训练图像，654张测试图像上的结果。表4给出了我们模型在几个变种上的结果。首先我们在RGB图像上训练了未修改的粗模型（FCN-32s）。为了加入深度信息，我们在一个升级的接受4通道RGB-D输入的模型上进行训练。这提供了一些好处，有可能是由于传播有意义的梯度比较困难。根据Gupta等，我们尝试了三维HHA深度编码，只在这个信息，以及RGB和HHA的“后融合”来训练网络。最后我们将该后融合网络升级为16步长版本。

![t4](images\t4.png)

**SIFT Flow**数据集有2688张图像，像素标注有33个语义类别，以及3个几何类别（水平，垂直，天空）。FCN可以自然的学得联合的表示，可以同时预测两种类型的标注。我们学习了一个two-headed FCN-16s版本，使用语义和几何预测层以及损失。学得的模型的表现与两个单独训练的模型一样好，而学习和推理与其本来单独模型一样快。表5中的结果，在标准分配2488张训练200张测试，展示了state-of-the-art的结果。

![t5](images\t5.png)

![f6](images\f6.png)

### 6. Conclusion

全卷积网络是模型中较为丰富的一种类别，其中现代分类convents是特殊情况。认识到此，将这些分类网络拓展到分割，并使用多分辨率层的组合提升该结构，大幅提高了state-of-the-art的性能，同时简化并加速了学习和推理。