## Multi-Scale Context Aggregation by Dilated Convolutions

> ICLR 2016

### Abstract

​	本文提出专为密集预测设计的网络模块，该模块使用孔洞卷积，在不丢失分辨率的前提下系统的集成多尺度上下文信息。

### Introduction

​	问题：图像分类网络通过连续的池化和降采样层来集成多尺度上下文信息，这样会一直降低分辨率直到得到一个全局预测。相反的，密集预测需要多尺度上下文信息并且与全分辨率输出相结合。最近的研究主要有两种方法解决该冲突。1）通过重复的上卷积来恢复分辨率，从降采样层来获得全局的视角。2）将多个不同尺度的图像作为输入，结合这些图像的输出。

​	本文提出了一个网络模块，在不丢失分辨率和分析rescaled图像的情况下集成了多尺度上下文信息。该模块基于孔洞卷积，支持感受野指数扩展，而不丢失分辨率。

### Dilated Convolutions

设$\ F:\mathbb{Z}^2\rightarrow\mathbb{R}\ $为一个离散函数。设$\ \Omega_r = [-r,r]^2\cap\mathbb{Z}^2\\ $，$\ k:\Omega_r\rightarrow\mathbb{R}\ $为一个离散滤波器，尺寸为$\ (2r+1)^2\ $。离散卷积操作*可以定义为：
$$
（F*k）(p) = \sum_{s+t=p}F(s)k(t)
$$
设$\ l\ $为dilation factor 则$\ *_l\ $可定义为：
$$
（F*_lk）(p)=\sum_{s+lt=p}F(s)k(t)
$$
设$F_0,F_1,...,F_{n-1}:\mathbb{Z}^2\rightarrow\mathbb{R}$为离散函数，$k_0,k_1,...k_{n-2}:\Omega\rightarrow\mathbb{R}$为离散3x3滤波器。使用滤波器以及指数增长的dilation：
$$
F_{i+1}=F_i*_{2^i}k_i
$$
$F_{i+1}$中每个元素的感受野为$\ (2^{i+2}-1)\times(2^{i+2}-1)\ $

![f1](images\f1.png)

### Multi-Scale Context Aggregation

​	上下文模块接受$\ C\ $特征图作为输入，$C$特征途作为输出。输入和输出是相同的形式，因此该模块可以集成到现有的密集预测结构中。

​	基本形式中，每一层有$\ C\ $个通道，每层的表示是相同的，并可以用来直接获得密集的预测，尽管特征图没有归一化，模块内部也没有定义损失。直观上，模块可以通过传递特征图通过多个显示上下文信息的层来提高特征图的准确度。

​	基本的上下文模块有7层，使用3x3卷积，不同的dilation factor。dilation分别为1,1,2,4,8,16,1。每个卷积后面跟着一个逐点截断$\ \mathrm{max}(\cdot,0)\ $。最后一层是$\ 1\times1\times C\ $卷积，并产生输出。结构如表一所示。前端模块产生的特征图为64x64，因此我们在第6层后停止了感受野的指数拓展。

![t1](images\t1.png)

​	此外，我们的初始化为：
$$
k^b(t,a)=1_{t=0}1_{a=b}
$$
其中a为输入特征图中的索引，b为输出特征图的索引。

### Front End

我们实现并训练了前端预测模块（接受彩色图片作为输入，产生$\ C\ $=21的特征图用于输出，FCN和DeepLabv1）。我们采用VGG-16网络来密集预测，移除了最后两个池化层和striding层，后面所有层的卷积都加以2 factor的dilated。