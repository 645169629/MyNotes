## Efficient Ladder-style DenseNets for Semantic Segmentation of Large Images

### Abstract

​	最近深度图像分类模型的研究为相关视觉任务提供了提高性能的可能。但是转变到语义分割主要受到了GPU显存的限制。卷积回传需要的特征图caching范围对即使是中等大小的Pascal 图像都提出了挑战，当源分辨率在百万像素范围时，需要仔细考虑结构。为了解决这些问题，我们提出了一个新的基于DenseNet的梯形结构，具有很强的建模能力以及精简的上采样通路。我们还提出利用DenseNet特征提取器固有的空间效率来显著降低特征图caching的范围。我们的模型获得了高性能且参数更少，并且可以进行百万分辨率的训练。实验结果在预测准确度上超过了sota方法。

### Introduction

​	我们的研究基于DenseNets，其中卷积在当前分辨率下对所有之前特征的concatenations进行操作。我们基于DenseNet的模型超过了对应部分是ResNets的模型以及最近的双路网络。另一个使用DenseNets的动机是其大量的特征重用，具有节省内存的可能性。但是这种可能性不容易实现，由于直接的backprop实现需要多次缓存concatenated的特征。我们展示了这些问题可以通过积极梯度检查点有效的解决，并节省了五倍的内存而只增加了20%的训练时间。

​	无论什么结构，语义分割的深度卷积模型都必须降低深层的空间分辨率才能满足GPU内存的限制。随后，深度特征必须小心的上采样到图像分辨率来生成正确的语义边界和小物体的预测。一些方法解决该问题通过dilated filtering来降低下采样的范围。其他方法通过利用缓存max-pool的开关、或之前层的激活来逐步上采样深度特征。我们的方法属于后面一组，因为我们也混合了深度特征的语义以及之前层的位置准确性。然而之前的方法具有复杂的上采样路径，需要大量的计算资源。我们研究显示使用简单的上采样也能获得很好的模型，该模型很适合快速处理大图。

​	本文提出一个高效的轻量级结构，用于大型图像的语义分割，基于DenseNet特征以及梯形上采样。我们对我们之前的工作[34]提出了一些改进，获得了更高的准确度，更快的速度，更少的内存以及更少的参数。我们的贡献有三点：1）我们对密集连接特征提取器进行了详细的研究；2）我们提出一个精简的梯形上采样路径，需要更少的内存并达到了更好的$\ \bar{IoU}/FLOP\ $权衡。3）我们通过对卷积backprop中间激活进行积极的重计算，进一步减少了训练内存占用。提出的方法达到了一个很好的准确度和模型复杂度的平衡。

### Related Work

​	之前的语义分割模型具有很少pooling 层，并从0开始训练。之后模型基于预训练模型，通常执行5次下采样。由此造成的空间分辨率损失需要特殊的技术来对特征进行上采样，使其恢复到原图像分辨率。之前的上采样方法基于训练过的filter和缓存的max-pooling层switches。最近的方法使得一些strided 层来产生non-strided输出，同时将后续卷积层的dilation factor加倍。这减少了下采样的范围同时保证了感受野与预训练的一样。

​	理论上，膨胀卷积可以在不影响预训练参数的情况下完全恢复分辨率。但由于两个重要缺点，这种技术应该少用或者完全避免。第一，膨胀卷积大大增加了计算和GPU内存需求，不能实时inference，阻碍了单GPU系统训练。实际实现通过只恢复到最后两个下采样，使得在8x下采样分辨率上进行后续inference。第二，膨胀卷积将语义分割看作是ImageNet分类，尽管这两个任务在位置敏感性方面有所不同。语义分割模型的预测必须在语义边界的像素上发生突变。另一方面，图像分类预测需要在很大程度上对定义类的对象的位置不敏感。这显示了最优的语义分割性能可能不是从ImageNet分类结构中获得的。

​	因此，我们更倾向于通过混合深层特征的语义和早期层的定位精度来保持下采样和恢复分辨率。这就鼓励了深层去丢弃位置信息，而专注于抽象的图像属性。实际实现中通过梯形上采样来避免输出分辨率的高维特征。在对成的encoder-decoder方法中，上采样路径mirror下采样路径。由于上采样数据的容量过大，这些方法的执行速度相当低。Ghiasi等通过考虑深层来预测物体中间部分，浅层来预测物体边界。Pohlen等提出一个双流残差结构，一个stream一直保持full 分辨率，另一个stream首先下采样然后上采样与第一个stream混合。Lin等人通过一个子模型RefineNet进行混合，该子模型在每个上采样步骤中包含8个卷积层和其他几个层。Islam等人将上采样预测与下采样数据路径的两层混合起来。这导致在每个上采样步骤中有4个卷积和1个元素相乘。Peng等人通过使用非常大的内核进行卷积得到的混合预测。本文工作中，我们使用简单的上采样路径，只包含一个3x3卷积。与对称上采样相比，该方法大大减少了上采样路径3x3卷积的数量。此外我们的横向连接不同于[30，32，42]，它们混合了预测，我们混合特征。混合特征提高了建模能力，但也要求更高的计算能力。我们可以通过最小化上采样和梯度检查点来混合特征。类似的，我们在所有分辨率生成分割图，使用交叉熵损失来优化。

​	ImageNet分类特征的缺点不仅在于粗糙的空间分辨率，这些特征没有足够的感知域用于语义预测。这个问题出现在位于平滑图像区域的像素中，这在城市场景中很常见。这些像素中有许多是从相机附近的物体上投射出来的，这使得它们对于高级任务极其重要。一些方法通过使用3x3卷积和大的dilation factor来解决该问题。但是由于混叠，稀疏采样可能会产生不好的影响。感知野也可以通过扩大模型深度来提高。但是这增加了容量，容易过拟合。通过引入远程连接，可以直接模拟场景中遥远部分之间的关联。然而，由于容量大、计算复杂，这些方法往往不适合。利用空间金字塔池化（SPP），可以获得较好的接受范围与复杂度的比值，其在不同大小的矩形区域上增强了特征。我们的设计提出了一些改进，详见4.2。此外，我们通过在第三个卷积块的中间插入一个strided pooling 层，减轻了SPP无法对空间布局建模的问题。这在不增加模型容量的情况下，增加了接受范围并保留了空间布局。据我们所知，目前只有两个基于densenet的语义分割的工作。然而这些方法并不能有效的利用内存。这种潜力是由一种鼓励层间共享而不是跨层转发特性的特定设计造成的。不幸的是，由于concatenation、batchnorm和projection层，自动微分无法利用这种潜力。因此直接的DenseNet实现比对应的残差网络需要更多的内存。幸运的是，这个问题可以通过检查点得到缓解。以往对检查点分割模型的研究只考虑了residual模型，因此只实现了两倍的内存减少。我们展示了DenseNet可以从该技术中获得更多，相比于baseline可以节省六倍的内存。

### Comparison between ResNets and DenseNets

​	我们展示了ResNet和DenseNet之间的相似与不同，如图1所示。我们考虑最广泛使用的变体：DenseNet-BC和pre-activation ResNets with bottleneck。

![f1](images\f1.png)

![t1](images\t1.png)

### The Proposed Architecture

![f2](images\f2.png)

​	结构包含两个路径，如图2所示。下采样路径由修改的DenseNet特征提取器以及一个轻量级空间金字塔池化模块组成。特征提取器将输入图像变换为特征张量$\ F\ $，通过逐渐降低空间分辨率和增加特征图数量。SPP模块增强了DenseNet特征的上下文信息，并产生上下文感知特征$\ C\ $。上采样路径将低分辨率特征$\ C\ $转换为高分辨率语义预测，通过混合深度语义和浅层细节。

#### 4.1 Feature extraction

​	DenseNet特征提取器包含dense block(DB)和transition layers(TD)。每个dense block都是卷积单元的串联，而每个卷积单元都是在前面所有单元和块输入的concatenation上进行的。与原始DenseNet不同的是，我们将dense block DB3分为两块（DB3a和DB3b），并在其中间加了一个strided average-pooling层（D）。这增加了DB3a后所有卷积的感受野，并降低了计算复杂度。我们使用预训练权重来初始化DB3b，尽管新的池化层以一种在ImageNet预训练中没有看到的方式改变了特征。尽管存在这种差异，但微调成功地恢复并实现了不错的泛化。特征提取器将所有DB4单元concat到一起，生成一个64x下采样表示$\ F\ $。

#### 4.2 Spatial pyramid pooling

​	空间金字塔池化模块捕获上下文信息，通过不同的空间网格来增强$\ F\ $。我们的SPP模块首先将$\ F\ $映射到$\ D/2\ $，其中$\ D\ $表示DensetNet特征的维度。产生的张量接着使用1，2，4，8行的网格平均池化。网格列的数量是根据图像大小设置的，因此所有单元格都是正方形。我们将每个池化的张量到$\ D/8\ $然后进行双线性上采样。我们将所有结果与映射的$\ F\ $concat到一起，最后混合1x1xD/4卷积。得到的上下文感知特征张量$\ C\ $是$\ H/64\times W/64\times D/4\ $。$\ C\ $的维度比输入图像少了48倍（DenseNet-121，D=1024）。

​	我们的SPP模型有两个不同。第一，我们根据输入特征的宽高比特征网格：每个网格单元总是平均一个正方形区域，无论输入图像的形状。第二，我们在池化之前降低了输入特征的维度，以避免增加输出维度。

#### 4.3 Upsampling datapath

​	上采样路径的作用是恢复下采样丢失的细节。我们提出的设计基于最小化过渡块（TU）。TU块的目的是混合两个空间分辨率相差2倍的表示。小的表示来自上采样路径，大的表示来自下采样路径的skip connection。我们先使用双线性插值上采样小的表示，使得两个表示具有同样的分辨率。然后，我们将大的表示映射到一个地位空间，使得两个表示具有相同的特征图数。这平衡了两个数据路径的相对影响，并允许通过简单的求和混合这两个表示。然后，我们使用1x1卷积来降低维度（如果需要），使用3x3卷积来准备特征tensor用于后续混合。混合过程循环执行。最终的过渡块生成logits。然后使用4x双线性上采样获得最终预测。

​	我们提出的最小化设计保证了速度：由于在每个上采样阶段只用了一个3x3卷积；更小的内存占用：因为更少的卷积以及特征张量的维度更低。第五节中可以进一步降低内存占用。我们提出的上采样路径比降采样具有更少的参数，因此不容易过拟合。

### Gradient Checkpointing

​	语义分割在训练过程中需要大量的内存，特别是在大输入分辨率的情况下。由于GPU RAM的严格限制，这些要求可能会导致一些困难。例如，众所周知，小批量训练可能会导致不稳定的批处理规范统计和较差的学习性能。这个问题不能通过在更新之间积累向后传递来克服，因此它是实现高性能的一个严重障碍。

​	backprop缓存范围可以使用梯度检查点来减少。主要思想是指示前传只缓存所有activations的一部分。这些activations随后在backprop中用于重新计算未缓存的activations。我们将计算图中显式缓存结点称为梯度检查点。两个梯度检查点之间的子图称为检查点段。反向传播遍历所有的检查点并按如下方式处理它们。一，从存储的检查点开始重新计算正向传递activations。二、梯度通过标准反向传播计算。局部缓存在相应的段处理后就释放，即在传到下个段之前。

​	我们注意到段粒度影响空间和时间效率。扩大检查点段总是会减少正向传播的内存占用。但是，对反向传播的内存需求影响不小。较大的段单独需要更多的内存，因为它们需要重新计算所有必需的activations并将它们存储在本地缓存中。在某一时刻，我们开始失去在前向传播中获得的收益。我们最好的启发式是检查点设在3x3卷积输出，因为它们是计算量最大的操作。换句话说，我们提出在反向传播时重新计算stem，所有映射，所有batchnorms以及所有concatenations。实验表明，该方法在前向传播和反向传播的最大内存分配之间取得了很好的平衡。

​	我们提出的检查点策略与之前的方法[21]相关，该方法在显示管理共享存储方面投入了大量精力。但是，我们展示了通过标准PyTorch内存管理器也可以获得类似的结果。我们还展示了通过使用标准PyTorch模块（torch.utils.checkpoint）可以完全避免自定义backprop操作。最后，我们提出只缓存3x3卷积输出以及输入图像，以获得更多的内存增益。我们checkpointing stem，transition-down以及transition-up块，以及DenseNet单元。

### Experiments

#### 6.1 Training details and notation

1. cosine learning rate policy
2. 所有预训练weights学习除以4
3. 每个上采样步骤都计算loss，以及SPP模块中四个池化的张量。
4. 最终预测loss占比0.6，平均辅助损失占比0.4
5. 训练后，我们重新计算batchnorm统计量作为训练集上的精确平均值，而不是训练中使用的衰减移动平均。这一实践稍微改进了模型泛化性。

![t2](images\t2.png)

![t3](images\t3.png)

![t4](images\t4.png)

![t5](images\t5.png)

![t6](images\t6.png)

![t7](images\t7.png)

![t8](images\t8.png)

![t9](images\t9.png)

![t10](images\t10.png)

![t11](images\t11.png)

![t12](images\t12.png)

![t13](images\t13.png)