### Deformable Convolutional Networks

#### 摘要：

卷积神经网络（CNNs）对于建模几何变换有固有局限由于其构建模块中的固定几何结构。在本研究中，我们提出两个新模块来提高CNNs的变形(transformation)建模能力，称为，可变形卷积和可变性RoI pooling。这两个模块都是基于在模块中拓展空间采样位置的思想，使用附加的偏移量以及从目标任务中学习偏移量，没有额外的监督。新的模块可以很容易的替换他们的plain counterparts在现有的CNNs中并可以很容易的通过标准反向传播进行端到端训练，产生可变形卷积网络。大量的实验验证了我们方法的性能。我们首次展示了在深度CNNs中学习密集空间变形对于复杂视觉任务（如，目标检测以及语义分割）来说是有效的。

#### 1. Introduction

视觉识别中关键的挑战就是如何适应几何变形或对目标尺度，姿势，视点以及部件变形中的几何变形建模。通常来说，有两种方法。第一种是构建具有足够所需变形的训练数据集。通常通过拓展现有数据采样来实现，如，通过仿射变换。可以从数据中学习到鲁棒表示，但却以训练开销大和模型参数复杂为代价。第二种是使用变形不变性特征和算法。这一类方法包含了许多著名的技术，如，SIFT和基于滑窗的目标检测范例。

上述方法有两个弊端。首先，几何变形被假定为固定的和已知的。这一先验知识被用来拓展数据以及设计特征和算法。这一假设使得模型无法泛化到新的任务，以处理未知的几何变形。其次，手工设计制作不变性特征和算法十分困难甚至对于复杂形变来说是不可实现的，即使已知这些变形。

最近，卷积神经网络（CNNs）在视觉识别（如，图像分类，语义分割以及目标检测）上取得了重大的成功。然而，他们都具有上述两个弊端。他们对几何变形的建模能力大多来自于拓展的数据，高模型能力以及一些简单手工制作模块（如，小平移不变性的max-pooling）。

简而言之，CNNs在建模大型，未知的变形时具有固有限制。这种限制来源于CNN模块的固定几何结构：卷积单元在固定位置上对输入特征图进行采样；池化层以固定比例减少空间分辨率；RoI池化层将RoI分开至固定的空间bin中等。现在缺少一种解决几何变形的内在机制。这会导致显著的问题。例如，同一CNN层的激活单元的感知野大小都是相同的。这对于在所有空间位置上编码语义的高层CNN来说是不合适的。因为不同的位置可能对应于目标的不同尺度或形变，自适应的确定尺度或感知野大小对于视觉识别精细位置是重要的，如，语义分割使用全卷积网络。另一个例子，虽然目标检测近年来取得了重大快速的发展，但所有的方法依然依赖于基于简单边界框的特征提取。这显然不是最佳的，特别是对于一些非刚体目标。

本文中，我们提出了两个新模块可以极大的提高CNNs对于几何变形的建模能力。第一个模块是可变形卷积。它在标准卷积中的规则网络采样位置上增加了2维的偏移量。这使得采样网格可以自由形变。如图1所示。偏移量从先前的特征图中学习，通过附加的巻积层。因此，变形以局部，密集以及自适应的方式受到输入特征的限制。

![f1](images\f1.png)

第二个模块是可变性RoI池化。它在先前RoI池化中的规则bin分区中的每个bin位置增加了一个偏移量。相似的，偏移量从先前的特征图中学习，RoIs，为不同形状的目标提供了自适应的部件定位。

这两个模块都是轻量级的。它们只在偏移量学习中增加了少量参数和计算。它们可以很容易的替换深度CNNs中它们的plain counterparts，并可以使用标准反向传播端到端训练。产生的CNNs称为可变形卷积网络。

我们的方法与空间变形网络以及可变型部件模型有着相似的高层思想。他们都拥有内部的变形参数并完全中数据中学习这些参数。可变形卷积网络中关键不同是它以简单，高效，深度以及端到端的方式来解决密集空间变形。在3.1节中，我们将详细介绍我们和先前工作的关系并分析可变形卷积网络的优越性。

#### 2. Deformable Convolutional Networks

CNNs中的特征图和卷积是3维的。可变形卷积和RoI池化模块都处理的是2维空间域。在通道维度操作是相同的。在不失一般性的前提下，为了符号简便，这里使用2维来描述模块。拓展到3维也是很简单的。

##### 2.1 Deformable Convolution

2维的卷积包含两个步骤：1）使用规则网格$\ \mathcal{R}\ $在输入特征图 x 上采样；2）对采样值加权 w 求和。网格$\ \mathcal{R}\ $定义了感知野大小和dilation。例如，
$$
\mathcal{R}=\{(-1,-1),(-1,0),...,(0,1),(1,1)\}
$$
定义了3$\times$3核，dilation 1。

对于输出特征图 y 上每个位置$\ p_0\ $，我们有
$$
y(p_0)=\sum_{p_n\in\mathcal{R}}{w(p_n)\cdot x(p_o+p_n)},\ \ \ \ \ \ \ \ \ \ \ \ (1)
$$
$p_n$枚举了$\ \mathcal{R}\ $中的位置。

在可变形卷积中，规则网格$\ \mathcal{R}\ $增加了偏移量$\{\Delta p_n|n=1,...,N\}$,$N = |\mathcal{R}|$。等式1变为
$$
y(p_0)=\sum_{p_n\in\mathcal{R}}{w(p_n)\cdot x(p_0+p_n+\Delta p_n)}\ \ \ \ \ \ \ \ \ \ (2)
$$
现在，采样就是在非规则偏移位置$\ p_n+\Delta p_n\ $上进行。由于偏移量$\ \Delta p_n\ $通常是分式，等式2通过双线性插值实现
$$
x(p)=\sum_q{G(q,p)\cdot x(q)}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (3)
$$
p表示任意（分式）位置（对于等式2来说，$p=p_0+p_n+\Delta p_n$）, q 枚举了特征图 x 中所有的集成空间位置，$G(\cdot,\cdot)$为双线性插值的核。注意到$\ G\ $是2维的。它被分成两个1维核
$$
G(q,p)=g(q_x,p_x)\cdot g(q_y,p_y)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (4)
$$
$g(a,b)=max(0,1-|a-b|)$。等式3计算很快，因为$G(q,p)$只有一些$q_s$是非零的。

如图2所示，通过在相同输入特征图上应用一个巻积层来获得偏移量。卷积核与当前巻积层的卷积核具有相同的空间分辨率和dilation（如，3$\times$3,dilation 1）。输出偏移量区域具有和输入特征图相同的空间分辨率。通道维度2N对应于N2维偏移量。在训练时，生成输出特征的卷积核以及生成偏移量的卷积核同时学习到。为了学习偏移量，梯度通过双线性操作（Eq.3和Eq.4）进行回传。在附录A有详细介绍。

![f2](images\f2.png)

##### 2.2 Deformable RoI Pooling

RoI 池化被用于所有基于区域提案的目标检测方法。它将任意大小的输入矩形区域转换为固定大小的特征。

**RoI Pooling**  给定输入特征图 x 以及大小为$w\times h$的RoI以及左上角$p_0$，RoI pooling将RoI分成$\ k\times k\ $（k为自由变量）个bins并输出$\ k\times k\ $的特征图 y 。对于第(i,j)个bin($0\leq i,j<k$)，我们有
$$
y(i,j)=\sum_{p\in bin(i,j)}{x(p_0+p)/n_{ij}},\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (5)
$$
$n_ij$表示bin中像素数。第(i,j)个bin跨度为$[i\frac{w}{k}\leq p_x<[(i+1)\frac{w}{k}]]$以及$[j\frac{h}{k}\leq p_y<[(j+1)\frac{h}{k}]]$。

与Eq.2类似，在可变形 RoI 池化中，偏移量$\{\Delta p_ij|0\leq i,j<k\}$被加入到空间bining位置。Eq.5变为
$$
y(i,j)=\sum_{p\in bin(i,j)}{x(p_0+p+\Delta p_{ij})/n_{ij}}\ \ \ \ \ \ \ \ \ \ (6)
$$
通常的，$\Delta p_{ij}$是分式。Eq.6通过Eq.3和Eq.4的双线性插值来实现。

图3展示了如何获取偏移量。首先，RoI池化(Eq.5)生成池化特征图。从特征图中，全连接层生成归一化偏移量$\Delta \hat{p}_{ij}$，接着通过与RoI的宽和高按元素相乘（$\Delta p_{ij}=\gamma \cdot \Delta \hat{p}_{ij}\circ(w,h)$）被转换为Eq.6中的偏移量$\Delta p_{ij}$。这里$\gamma$是一个预先定义的标量用来调整偏移量的量级。一般设置$\gamma = 0.1$。偏移量归一化对于不同RoI尺寸学习到不变的偏移量很重要。全连接层通过反向传播学习，详情见附录A。

![f3](images\f3.png)

**Position-Senstive(PS)RoI Pooling**   不同于RoI pooling它是全卷积的。通过一个巻积层，所有的输入特征图首先被转换为每个目标类别(C个目标类别，总共C+1个)的$\ k^2\ score\ maps$，如图4底部分支所示。由于不需要分辨各个类别，该$score\ maps$标记为${X_{i,j}}$，(i,j)枚举了所有bins。池化在这些score maps上执行。第(i,j)个bin的输出值从与其对应的score map$X_{i,j}$求和获得。简而言之，与Eq.5中RoI池化不同的是，一般的特征图 x 被特定的位置敏感score map $x_{i,j}$所替代。

在可变形 PS RoI池化中，Eq.6中的唯一改变是 x 也被更改为$X_{i,j}$。但是，偏移量学习不同。它与"全卷积"思想相同，如图4所示。在最上的分支中，巻积层生成全空间分辨率偏移区域。对于每个RoI(也是对于每个类)来说，PS RoI pooling被应用于该区域上以获得归一化偏移量$\Delta \hat{p}_{i,j}$，接着被会以可变形RoI池化中同样的方法转换为真实偏移量$\Delta p_{ij}$。

![f4](images\f4.png)

##### 2.3 Deformable ConvNets

可变形卷积和可变形RoI池化模块具有与其普通版本相同的输入和输出。因此，他们可以简单的替换现有CNNs中他们的plain counterparts。在训练时，这些增加用于偏移学习的巻积层和全连接层会以0权重被初始化。学习率被设置$\beta$(默认$\beta=1$，在Faster R-CNN的全连接层中$\beta=0.01$)为现有层学习率的时间。他们通过Eq.3和Eq.4中的双线性差值以反向传播进行训练。产生的CNNs称为可变形卷积网络。

为了集成可变形卷积网络和state-of-the-art CNN结构，我们注意到这些结构包含两个阶段。首先，一个深度全卷积网络用来生成整幅输入图像的特征图。然后，一个浅层的特定任务网络用于生成特征图中的结果。以下我们将详细接着这两个步骤。

**Deformable Convolution for Feature Extraction**  我们应用了两个state-of-the-art结构用于特征提取：ResNet-101以及一个修改版本的Inception-ResNet。这两个都是在ImageNet分类数据集上预训练的。

原始的Inception-ResNet被设计用来图像识别。它有特征不对准问题并且在密集预测任务上有问题。它被修改以解决对准问题。修改的版本称为"Aligned-Inception-ResNet"。详情见附录B。

这两个模型都包含一些卷积块，一个平均池化以及一个用于ImageNet分类的1000-路全连接层。平均池化和全连接层被移除了。在最后增加了一个随机初始化的1$\ \times\ $1卷积以将通道维度降至1024。在常见的做法中，最后的卷积块有效的步长从32像素降低至16像素以提高特征图的分辨率。特别的，在最后一块的开始，步长从2变为1（ResNet-101和Aligned-Inception-ResNet中的"conv5"）。为了补偿，该块所有的卷积过滤器的dilation从1变为2。

可选的，可变形卷积应用于最后的几个巻积层。我们实验过不同的层数并发现3是对不同任务的较好权衡，如表1所示。

**Segmentation and Detection Networks**  特定任务网络构建在特称提取网络输出的特征图之上。

以下，$C$表示目标类别的数量。

*DeepLab*是一个语义分割的state-of-the-art方法。它在特征图之上增加了一个1$\times$1巻积层以生成($C$+1)个表示每个像素分类得分的图。接着softmax层输出每个像素的概率。

*Category-Aware RPN* 与[47]中的区域提案网络几乎相似，除了将2类卷积分类器替换为一个($C$+1)类卷积分类器。它可以看作是简化版本的SSD。

*Faster R-CNN* 是state-of-the-art检测器。在我们的实现中，RPN分支加在conv4块之上。在之前的实践中，ResNet-101将RoI池化层插入在conv4和conv5之间，剩下10层用于每个RoI。这一设计取得了很好的准确度但是每个RoI具有很大的计算量。相对的，我们应用了[38]中简化的设计。RoI池化层被加在最后。在池化RoI特征之上，增加了两个1024维的全连接层，紧接着是边界框回归以及分类分支。尽管这样的简化（从10层conv5块到2个全连接层）会轻微降低准确度，它依然是足够强的基准，在本文中不是一个问题。

可选的，RoI池化层可以变为可变形RoI池化层。

*R-FCN*是另一个state-of-the-art检测器。它每个RoI的计算代价可以忽略。我们跟从原始的实现。可选的，它的RoI池化层可以改为可变形位置敏感RoI池化。

#### 3. Understanding Deformable ConvNets

本文构建于在卷积和RoI池化之上附加偏移量以及从目标任务中学习偏移量以拓展空间采样位置的思想之上。

当可变形卷积堆叠时，复合变形的影响是深远的。如图5所示。标准卷积的感知野和采样位置在顶部特征图（左）上都是固定的。可变形卷积中他们是根据目标尺寸和形状自适应的。更多实例如图6所示。表2展示了这种自适应变形的定量证据。

![f5](images\f5.png)

![f6](images\f6.png)

可变形RoI池化的影响是相似的，如图7所示。标准RoI池化中的网格结构规则性不再具备。相对的，部分从RoI bins中偏移已经移动到邻近目标前景区域中。定位能力被提高了，特别是对非刚体目标。

![f7](images\f7.png)

##### 3.1 In Context of Reltaed Works

我们的研究与之前的研究在不同的方面有着关联。我们将详细的讨论区别于联系。

**Spatial Transform Networks(STN)**  它是第一个在深度学习框架下从数据中学习空间变形的工作。它通过全局参数变换（如仿射变换）来warps特征图。这种warping开销很大并且学习变形参数也十分困难。STN在小规模图像分类问题中取得了成功。反转STN方法通过高效的变形参数传播替代了开销大的特征warping。

可变形卷积中的偏移量学习可以看作是STN中一个特别轻量级的空间变换器。但是，可变形卷积没有采用全局参数变形以及特征warping。相对的，它以局部和密集的方式在特征图之上采样。为了生成新的特征图，它有一个加权和步骤，这在STN中是没有的。

可变形卷积很容易集成到任何CNN结构中。它的训练很简单。它展示了对于需要密集（如，语义分割）或半密集（如，目标检测）预测的复杂视觉任务的有效性。这些任务对于STN来说十分困难。

**Active Convolution**  这一工作是同期的工作。它也使用偏移量以及通过端到端反向传播学习的偏移量来拓展卷积中的采样位置。它展示了在图像分类任务上的有效性。

两个与可变形卷积关键的区别使得该工作具有更少的一般性和适应性。首先，它在所有不同空间位置上共享偏移量。其次，偏移量为从每个任务或每个训练中学到的静态模型参数。相对的 ，可变形卷积中的偏移量是动态模型输出，在每个图像位置都会改变。他们对图像中密集空间变形建模并对于（半）密集预测任务（如目标检测和语义分割）十分有效。

**Effective Receptive Field**  在感知野中不是所有的像素对于输出响应贡献是相同的。中心部分的像素具有更大的影响。有效的感知野只占据了理论感知野的一小部分并成高斯分布。尽管随着巻积层数量的增加，理论感知野大小线性递增，一个令人吃惊的结果是有效感知野的大小随着数量的平方根而线性增长，因此，比我们预期的要慢很多。

这一发现表明即使深度CNNs的最上层单元可能也没有足够大的感知野。这也部分解释了为什么atrous卷积在视觉任务中被广泛使用。它指示了自适应感知野学习的需求。

可变形卷积可以自适应的学习感知野，如图5，6和表2所示。

**Atrous convolution**  它增加了一般过滤器的步长大于1，并保持了空间抽样位置的原始权值。这增加了感知野的大小并维持了同样的参数复杂度和计算复杂度。这被广泛应用于语义分割（也被称为膨胀卷积 ），目标检测以及图像分类。

可变形卷积是atrous卷积的泛化，如图1（c）所示。更多与atrous卷积的比较见表3。

**Deformable Part Models(DPM)**  可变形RoI池化与DPM类似，因为这两个方法都是学习目标部件的空间变形以最大化分类 分数。可变形RoI池化更简单因为其没有考虑部件中间的空间关系。

DPM是一个浅层模型，对变形的建模能力有限。尽管它的推导算法可以转换为CNNs通过将距离变形视为空间池化操作，它的训练不是端到端的并且涉及启发式的选择例如组件和部件大小的选择。相反的，可变形卷积网络是深度的并且执行端到端训练。当多个可变形模块被堆叠，对变形的建模能力也会更强。

**DeepID-Net**  它提出了一个变形约束池化层，也考虑了部件变形用于目标检测。因此它与可变形RoI池化具有相似的思想，但是更复杂。该工作很工程化并基于RCNN。如何以端到端的方式将其适用于最近state-of-the-art目标检测方法还是不清楚的。

**Spatial manipulation in RoI pooling**  空间金字塔池化在各个尺度上使用手工制作池化区域。这是计算机视觉中主要的方法也在基于深度学习的目标检测中使用。

学习池化区域的空间布局很少有人研究。[28]中的工作从一个大型完整集合中学习了一个池化区域的稀疏子集。大型集合是手工制造的并且学习不是端到端的。

可变形RoI池化是第一个在CNNs中端到端学习池化区域的。虽然目前的区域都是同样大小，像空间金字塔池化中一样拓展到多尺寸是很简单的。

**Transformation invariant features and their learning**  在设计变形不变性特征上有大量的工作。值得注意的例子包括尺度不变特征变形（SIFT）以及ORB（O为方向）。在CNNs的背景下有大量同类型的工作。CNN对图像变形表示的不变性和等价性在[36]中被研究。一些工作学习了关于不同变形类型的CNN不变性表示，例如[50]，scattering networks[3],convolutional jungles[32]以及TI-pooling[33]。一些工作致力于特定的变形例如，对称，尺度以及旋转。

如第一节分析的，这些工作中变形作为已知的先验。知识（如参数化）被用来手工制作特征提取算法的结构，要么如SIFT固定的，或如基于CNNs的可学习参数。他们不能解决新任务中的未知变形。

相反的，我们的可变形模块泛化了多种变形（见图1）。变形不变性是从目标任务中学到的。

**Dynamic Filter**  与可变形卷积相似的是，动态过滤器也受输入特征约束并在样本之间改变。不同的是，其只学习过滤器权重，没有像我们一样的采样位置。该工作应用于视频和立体预测。

**Combination of low level filters**  高斯过滤器及其光滑导数在提取低级图像结构（如，角，边缘，T-junctions等）中被广泛使用。在特定条件下，该种过滤器形成一系列基，他们的线性组合形成了同种几何变形中的新过滤器，如Steerable Filters中的多个方向以及[45]中的多尺度。我们注意到尽管[45]中使用了*deformable kernels*的术语，它的意义与我们的不同。

![t1](images\t1.png)

大部分的CNNs从零开始学习其所有的过滤器。最近的研究表明这不是必要的。它使用低阶滤波器（）的加权组合来替换自由形式的过滤器，并学习权重系数。对过滤器函数空间的正则化可以在训练数据很少时提高泛化能力。

以上工作与我们的工作相关，因为当多个过滤器，特别是具有不同尺度的被组合时，产生的过滤器可能具有复杂的权重并与我们的可变形卷积过滤器相似。但是，可变形卷积学习采样位置而不是过滤器权重。

![t2](images\t2.png)

#### 4. Experiments

##### 4.1 Experiment Setup and Implementation

**Semantic Segmentation**  我们使用*PASCAL VOC*以及*CityScapes*。对于*PASCAL VOC* 来说，有20个语义类别。跟随[19,41,4]中的原则，我们使用VOC 2012数据集以及[18]中附加的mask标注。训练集包括10582张图像。评估在验证集的1449张图像上执行。对于CityScapes，跟随[5]中的原则，训练和评估分别在2975张图像的训练集以及500张图像的验证集上执行。一共有19个分割类别加一个背景类别。

对于评估来说，我们使用了在图像像素上定义的mIoU度量，跟随[10,6]中的标准原则。我们分别使用mIoU@V和mIoU@C对应PASCAL VOC 以及 Cityscapes。

在训练和推理中，PASCAL VOC 图像大小调整为360像素，Cityscapes调整为1024像素。在SGD训练中，在每个mini-batch中随机采样图像。分别有30k和45k次迭代被执行在PASCAL VOC以及Cityscapes中，使用8个GPU，每个mini-batch占据一个。学习率分别为$10^{-3}$和$10^{-4}$在前$\frac{2}{3}$次迭代以及后$\frac{1}{3}$次迭代。

**Object Detection**  我们使用PASCAL VOC 以及COCO数据集。对于PASCAL VOC ，跟随[15]的原则，训练在VOC 2007 trainval以及VOC 2012trainval上进行。评估在VOC 2007测试集上进行。对于COCO，跟随[39]中标准原则，训练和评估分别在120k图像的trainval上和20k图像的test-dev上。

对于评估，我们使用标准mAP分数。对于PASCAL VOC ，我们报告了使用IoU阈值维0.5和0.7下的mAP分数。对于COCO，我们使用标准的COCO度量mAP@[0.5:0.95]，以及mAP@0.5。

在训练和推理中，图像被调整为600像素。在SGD训练中，每个mini-batch随机采样图片。对于*class-aware RPN*，从图像中采样256个RoIs。对于*Faster R-CNN*和*R-FCN*，分别采样265和128个RoIs用于区域提案以及目标检测网络。在RoI池化中采用7$\times$7bins。为了崔津VOC上的消融实验，我们跟随[38]并利用了预训练过的固定RPN提案用于Faster R-CNN和R-FCN的训练，不使用区域提案间共享特征以及目标检测网络。RPN网络如[47]中第一阶段的程序一样分开训练。对于COCO，如[48]中的联合训练被执行并且特征共享在训练时可用。一共分别执行了30k和240k次迭代，在PASCAL VOC 和COCO，在8个GPU上。学习率在前$\frac{2}{3}$次迭代中使用$10^{-3}$在后$\frac{1}{3}$中使用$10^{-4}$。

![t3](images\t3.png)

##### 4.2 消融实验

执行了大量消融实验来验证我们方法的功效以及效率。

**Deformable Convolution**  表1评估了使用ResNet-101特征提取网络的可变形卷积的效果。当使用更多可变形卷积层是，准确度稳步提高，特别是对于*DeepLab*和*class-aware RPN*来说。提升在DeepLab中使用3个可变形层，其他使用6个时达到了饱和。在接下来的实验中，我们在特征提取网络中使用3。

我们通过经验观察到可变形卷积层学习到的偏移量高度适应于图像内容，如图5，6所示。为了更好的理解可变形卷积的机制，我们定义了一个度量称为*effective dilation*用于可变形卷积过滤器。它是所有过滤器中临近采样位置对之间距离的平均值。这是对于过滤器感知野的粗略度量。

我们在VOC 2007测试图像上应用了R-FCN网络以及3个 可变形层（如表1所示）。我们将可变形卷积过滤器分成四类：小型，中性，大型以及背景，根据ground truth边界框标注以及过滤器的中心位置。表2报告了有效dilation值的统计数据（平均值和标准差）。明显可以看出：1）可变形过滤器感知野的大小与目标大小相关，表明从图像内容中有效的学到了变形；2）背景区域上的过滤器大小介于中型和大型目标之间，表明识别背景区域需要相对大型的感知野区域。这些观察结果在不同层上是一致的。

默认的ResNet-101模型使用atrous 卷积，最后3个3$\times$3巻积层使用diation 2（见2.3节）。我们尝试了dilation 4,6,8并在表3中报告了结果。可以看出：1）当使用更大的dilation值时所有任务的准确度会上升，表明默认的网络具有太小的感知野；2）不同的任务具有不同最优的dilation选择，如，DeepLab为6而Faster R-CNN为4；3）可变形卷积具有最好的准确度。观察结果验证了过滤器变形的自适应学习是有效的和必要的。

**Deformable RoI Pooling**  它可应用于Faster R-CNN以及R-FCN。如表3所示，单独使用它已经会产生显著的性能提高，特别是在严格的mAP@0.7度量下。当同时使用可变形卷积和RoI Pooling时，会获得重大的准确度提升。

**Model Complexity and Runtime**  表4报告了可变形卷积网络以及它的普通版本的模型复杂度以及运行时间。可变形卷积网络只在模型参数和计算量上增加了小部分开销。这表明了性能提升源于对几何变形的建模能力，而不是增加的模型参数。

![t4](images\t4.png)

##### 4.3 Object Detection on COCO

表5中，我们展示了大量的可变形卷积网络与普通网络之间在COCOtest-dev集上目标检测的比较。我们先实验了使用ResNet-101模型。可变形版本的class-aware RPN,Faster R-CNN以及R-FCN达到了map@[0.5:0.95]分数分别为25.8%,33.1%以及34.5%，这比它们的普通版本分别高了相对11%,13%和12%。通过将Faster R-CNN和R-FCN中的ResNet-101替换为Aligned-Inception-ResNet，它们普通版本卷积网络基准都提高了，由于更强的特征表示。并且可变形卷积网络带来的有效性能提升也是成立的。通过进一步在不同尺度图像上测试并执行iterative bounding box average，R-FCN的可变形版本的mAP@[0.5:0.95]分数提升到了37.5%。注意到可变形卷积网络的性能提升由这些休息所补足。

![t5](images\t5.png)

#### 5. Conclusion

本文提出了可变形卷积网络，该网络是一个简单，高效，深度以及端到端的对于密集空间变形的解决方案。首次我们在CNNs中学习密集空间变形是可行有效的以用于复杂视觉任务，如目标检测和语义分割。